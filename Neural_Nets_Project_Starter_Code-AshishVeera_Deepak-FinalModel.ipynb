{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gesture Recognition\n",
    "In this group project, you are going to build a 3D Conv model that will be able to predict the 5 gestures correctly. Please import the following libraries to get started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from scipy.misc import imread, imresize\n",
    "import datetime\n",
    "import os\n",
    "from sys import getsizeof\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set the random seed so that the results don't vary drastically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(30)\n",
    "import random as rn\n",
    "rn.seed(30)\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "tf.set_random_seed(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this block, you read the folder names for training and validation. You also set the `batch_size` here. Note that you set the batch size in such a way that you are able to use the GPU in full capacity. You keep increasing the batch size until the machine throws an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "project_folder='Project_data'\n",
    "\n",
    "train_doc = np.random.permutation(open(project_folder + '/' + 'train.csv').readlines())\n",
    "val_doc = np.random.permutation(open(project_folder + '/' + 'val.csv').readlines())\n",
    "\n",
    "num_channels = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def set_hyper_parameters(batchSize, numFrames, numRows, numCols, numEpochs):\n",
    "    global batch_size, num_frames, num_rows, num_cols, num_epochs, input_shape\n",
    "    batch_size = batchSize\n",
    "    num_frames = numFrames\n",
    "    num_rows = numRows\n",
    "    num_cols = numCols\n",
    "    num_epochs =numEpochs\n",
    "    input_shape=(num_frames,num_rows,num_cols,num_channels)\n",
    "    print(\"batch_size=\", batch_size, \",num_frames=\", num_frames, \",num_rows=\", num_rows, \",num_cols=\", num_cols, \",num_epochs=\", num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_size= 10 ,num_frames= 30 ,num_rows= 60 ,num_cols= 60 ,num_epochs= 2\n"
     ]
    }
   ],
   "source": [
    "set_hyper_parameters(batchSize=10, numFrames=30, numRows=60, numCols=60, numEpochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 60, 60, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator\n",
    "This is one of the most important part of the code. The overall structure of the generator has been given. In the generator, you are going to preprocess the images as you have images of 2 different dimensions as well as create a batch of video frames. You have to experiment with `img_idx`, `y`,`z` and normalization such that you get high accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generator(source_path, folder_list, batch_size):\n",
    "    print( 'Source path = ', source_path, '; batch size =', batch_size)\n",
    "    img_idx = img_idx = np.round(np.linspace(0,29,num_frames)).astype(int)\n",
    "    while True:\n",
    "        num_batches = len(folder_list)//batch_size\n",
    "        t = np.random.permutation(folder_list)\n",
    "        for batch in range(num_batches): # we iterate over the number of batches\n",
    "            batch_data = np.zeros((batch_size,num_frames,num_rows,num_cols,num_channels)) # x is the number of images you use for each video, (y,z) is the final size of the input images and 3 is the number of channels RGB\n",
    "            batch_labels = np.zeros((batch_size,5)) # batch_labels is the one hot representation of the output\n",
    "            for folder in range(batch_size): # iterate over the batch_size\n",
    "                imgs = os.listdir(source_path+'/'+ t[folder + (batch*batch_size)].split(';')[0]) # read all the images in the folder\n",
    "                for idx,item in enumerate(img_idx): #  Iterate iver the frames/images of a folder to read them in\n",
    "                    image = imread(source_path+'/'+ t[folder + (batch*batch_size)].strip().split(';')[0]+'/'+imgs[item]).astype(np.float32)\n",
    "                    \n",
    "                    #crop the images and resize them. Note that the images are of 2 different shape \n",
    "                    #and the conv3D will throw error if the inputs in a batch have different shapes\n",
    "                    # Cropping non symmetric frames\n",
    "                    if image.shape[0] != image.shape[1]:\n",
    "                        image=image[0:120,20:140]\n",
    "                        \n",
    "                    image = imresize(image,(num_rows, num_cols)) #resize the image\n",
    "                    #image = image/255 #normalize the image\n",
    "                    \n",
    "                    batch_data[folder,idx,:,:,0] = image[:,:,0]/255 #normalise and feed in the image\n",
    "                    batch_data[folder,idx,:,:,1] = image[:,:,1]/255 #normalise and feed in the image\n",
    "                    batch_data[folder,idx,:,:,2] = image[:,:,2]/255 #normalise and feed in the image\n",
    "                    batch_labels[folder, int(t[folder + (batch*batch_size)].strip().split(';')[2])] = 1\n",
    "            yield batch_data, batch_labels #you yield the batch_data and the batch_labels, remember what does yield do\n",
    "\n",
    "        \n",
    "        # write the code for the remaining data points which are left after full batches\n",
    "        # batch_size = 20\n",
    "        # folder_list = 663\n",
    "        # num_batches = 33\n",
    "        # last batch size = 663 - 20* 33 = 3\n",
    "        \n",
    "        if (len(folder_list) > num_batches * batch_size):\n",
    "            batch_size = len(folder_list) - num_batches * batch_size\n",
    "            batch_data = np.zeros((batch_size,num_frames,num_rows,num_cols,num_channels)) # x is the number of images you use for each video, (y,z) is the final size of the input images and 3 is the number of channels RGB\n",
    "            batch_labels = np.zeros((batch_size,5)) # batch_labels is the one hot representation of the output\n",
    "            for folder in range(batch_size): # iterate over the batch_size\n",
    "                imgs = os.listdir(source_path+'/'+ t[folder + (batch*batch_size)].split(';')[0]) # read all the images in the folder\n",
    "                for idx,item in enumerate(img_idx): #  Iterate iver the frames/images of a folder to read them in\n",
    "                    image = imread(source_path+'/'+ t[folder + (batch*batch_size)].strip().split(';')[0]+'/'+imgs[item]).astype(np.float32)\n",
    "                    \n",
    "                    #crop the images and resize them. Note that the images are of 2 different shape \n",
    "                    #and the conv3D will throw error if the inputs in a batch have different shapes\n",
    "                    \n",
    "                    # Cropping non symmetric frames\n",
    "                    if image.shape[0] != image.shape[1]:\n",
    "                        image=image[0:120,20:140]\n",
    "                        \n",
    "                    image = imresize(image,(num_rows, num_cols)) #resize the image\n",
    "                    #image = image/255 #normalize the image\n",
    "                                        \n",
    "                    batch_data[folder,idx,:,:,0] = image[:,:,0]/255 #normalise and feed in the image\n",
    "                    batch_data[folder,idx,:,:,1] = image[:,:,1]/255 #normalise and feed in the image\n",
    "                    batch_data[folder,idx,:,:,2] = image[:,:,2]/255 #normalise and feed in the image\n",
    "                    batch_labels[folder, int(t[folder + (batch*batch_size)].strip().split(';')[2])] = 1\n",
    "            yield batch_data, batch_labels #you yield the batch_data and the batch_labels, remember what does yield do"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note here that a video is represented above in the generator as (number of images, height, width, number of channels). Take this into consideration while creating the model architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# training sequences = 663\n",
      "# validation sequences = 100\n",
      "# epochs = 2\n"
     ]
    }
   ],
   "source": [
    "curr_dt_time = datetime.datetime.now()\n",
    "train_path = project_folder + '/' + 'train'\n",
    "val_path = project_folder + '/' + 'val'\n",
    "num_train_sequences = len(train_doc)\n",
    "print('# training sequences =', num_train_sequences)\n",
    "num_val_sequences = len(val_doc)\n",
    "print('# validation sequences =', num_val_sequences)\n",
    "#num_epochs =  20# choose the number of epochs\n",
    "print ('# epochs =', num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "Here you make the model using different functionalities that Keras provides. Remember to use `Conv3D` and `MaxPooling3D` and not `Conv2D` and `Maxpooling2D` for a 3D convolution model. You would want to use `TimeDistributed` while building a Conv2D + RNN model. Also remember that the last layer is the softmax. Design the network in such a way that the model is able to give good accuracy on the least number of parameters so that it can fit in the memory of the webcam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, GRU, Flatten, TimeDistributed, Flatten, BatchNormalization, Activation, Dropout, GlobalAveragePooling2D\n",
    "from keras.layers.convolutional import Conv3D, MaxPooling3D, Convolution2D, MaxPooling2D \n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras import optimizers\n",
    "from keras.applications import ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_name = 'model_init' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
    "    \n",
    "if not os.path.exists(model_name):\n",
    "    os.mkdir(model_name)\n",
    "        \n",
    "filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "LR = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, cooldown=1, verbose=1)\n",
    "callbacks_list = [checkpoint, LR]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `steps_per_epoch` and `validation_steps` are used by `fit_generator` to decide the number of next() calls it need to make."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def set_train_validation_steps():\n",
    "    global steps_per_epoch, validation_steps\n",
    "    if (num_train_sequences%batch_size) == 0:\n",
    "        steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "    else:\n",
    "        steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "    if (num_val_sequences%batch_size) == 0:\n",
    "        validation_steps = int(num_val_sequences/batch_size)\n",
    "    else:\n",
    "        validation_steps = (num_val_sequences//batch_size) + 1\n",
    "    print(\"steps_per_epoch=\", steps_per_epoch, \"validation_steps=\",validation_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1: Experimenting with a large batch_size=60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# #write your model here\n",
    "# def get_conv3d_model():\n",
    "\n",
    "# # Define model\n",
    "#     model = Sequential()\n",
    "\n",
    "#     model.add(Conv3D(16, kernel_size=(3,3,3), input_shape=input_shape,padding='same'))\n",
    "#     model.add(Activation('relu'))\n",
    "#     model.add(BatchNormalization())\n",
    "#     model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "#     model.add(Conv3D(32, kernel_size=(3,3,3), padding='same'))\n",
    "#     model.add(Activation('relu'))\n",
    "#     model.add(BatchNormalization())\n",
    "#     model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "#     model.add(Conv3D(64, kernel_size=(3,3,3), padding='same'))\n",
    "#     model.add(Activation('relu'))\n",
    "#     model.add(BatchNormalization())\n",
    "#     model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "#     model.add(Conv3D(128, kernel_size=(3,3,3), padding='same'))\n",
    "#     model.add(Activation('relu'))\n",
    "#     model.add(BatchNormalization())\n",
    "#     model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "#     #Flatten Layers\n",
    "#     model.add(Flatten())\n",
    "#     model.add(Dense(256, activation='relu'))\n",
    "#     model.add(BatchNormalization())\n",
    "#     model.add(Dropout(0.25))\n",
    "\n",
    "#     model.add(Dense(128, activation='relu'))\n",
    "#     model.add(BatchNormalization())\n",
    "#     model.add(Dropout(0.25))\n",
    "\n",
    "#     #softmax layer\n",
    "#     model.add(Dense(5, activation='softmax'))\n",
    "\n",
    "#     optimiser = optimizers.Adam(lr=0.001)\n",
    "#     model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "#     print (model.summary())\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_size= 60 ,num_frames= 30 ,num_rows= 120 ,num_cols= 120 ,num_epochs= 2\n"
     ]
    }
   ],
   "source": [
    "# # Set Hyperparameters for the model by calling the set_hyper_parameters function\n",
    "# set_hyper_parameters(batchSize=60, numFrames=30, numRows=120, numCols=120, numEpochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steps_per_epoch= 12 validation_steps= 2\n"
     ]
    }
   ],
   "source": [
    "# # Deriving the steps_per_epoch and validation_steps which are used by fit_generator to decide the number of next() calls it need to make\n",
    "# set_train_validation_steps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_5 (Conv3D)            (None, 30, 120, 120, 16)  1312      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 30, 120, 120, 16)  0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 30, 120, 120, 16)  64        \n",
      "_________________________________________________________________\n",
      "max_pooling3d_5 (MaxPooling3 (None, 15, 60, 60, 16)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_6 (Conv3D)            (None, 15, 60, 60, 32)    13856     \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 15, 60, 60, 32)    0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 15, 60, 60, 32)    128       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_6 (MaxPooling3 (None, 7, 30, 30, 32)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_7 (Conv3D)            (None, 7, 30, 30, 64)     55360     \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 7, 30, 30, 64)     0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 7, 30, 30, 64)     256       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_7 (MaxPooling3 (None, 3, 15, 15, 64)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_8 (Conv3D)            (None, 3, 15, 15, 128)    221312    \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 3, 15, 15, 128)    0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 3, 15, 15, 128)    512       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_8 (MaxPooling3 (None, 1, 7, 7, 128)      0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 256)               1605888   \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 1,933,765\n",
      "Trainable params: 1,932,517\n",
      "Non-trainable params: 1,248\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# # Calling the base model\n",
    "# model1 = get_conv3d_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # create generators: Let us create the `train_generator` and the `val_generator` which will be used in `.fit_generator`.\n",
    "# train_generator = generator(train_path, train_doc, batch_size)\n",
    "# val_generator = generator(val_path, val_doc, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now fit the model. This will start training the model and with the help of the checkpoints, you'll be able to save the model at the end of each epoch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Commenting out this code section since this was used to identify the optimal batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source path =  Project_data/val ; batch size = 60\n",
      "Source path =  Project_data/train Epoch 1/2\n",
      "; batch size = 60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:13: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "  del sys.path[0]\n",
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:21: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n",
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:44: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:53: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[60,16,30,120,120] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: training_1/Adam/gradients/max_pooling3d_5/MaxPool3D_grad/MaxPool3DGrad = MaxPool3DGrad[T=DT_FLOAT, TInput=DT_FLOAT, _class=[\"loc:@training_1/Adam/gradients/batch_normalization_7/cond/Merge_grad/cond_grad\"], data_format=\"NDHWC\", ksize=[1, 2, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 2, 1], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](batch_normalization_7/cond/Merge, max_pooling3d_5/MaxPool3D, training_1/Adam/gradients/conv3d_6/convolution_grad/Conv3DBackpropInputV2)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-f9a4f4b6d746>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m model1.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n\u001b[1;32m      2\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m                     validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)\n\u001b[0m",
      "\u001b[0;32m/mnt/disks/user/anaconda3/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/disks/user/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1413\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1414\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1415\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/disks/user/anaconda3/lib/python3.6/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    211\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    212\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/disks/user/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1213\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1214\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1215\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1216\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/disks/user/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2664\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2666\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2667\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2668\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/disks/user/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2634\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2635\u001b[0m                                 session)\n\u001b[0;32m-> 2636\u001b[0;31m         \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2637\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/disks/user/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1380\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1381\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1382\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1384\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/disks/user/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    517\u001b[0m             \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 519\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    520\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[0;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[60,16,30,120,120] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: training_1/Adam/gradients/max_pooling3d_5/MaxPool3D_grad/MaxPool3DGrad = MaxPool3DGrad[T=DT_FLOAT, TInput=DT_FLOAT, _class=[\"loc:@training_1/Adam/gradients/batch_normalization_7/cond/Merge_grad/cond_grad\"], data_format=\"NDHWC\", ksize=[1, 2, 2, 2, 1], padding=\"VALID\", strides=[1, 2, 2, 2, 1], _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](batch_normalization_7/cond/Merge, max_pooling3d_5/MaxPool3D, training_1/Adam/gradients/conv3d_6/convolution_grad/Conv3DBackpropInputV2)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n"
     ]
    }
   ],
   "source": [
    "# model1.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "#                     callbacks=callbacks_list, validation_data=val_generator, \n",
    "#                     validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2: Reducing the batch size to 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_size= 40 ,num_frames= 30 ,num_rows= 120 ,num_cols= 120 ,num_epochs= 2\n"
     ]
    }
   ],
   "source": [
    "# # Set Hyperparameters for the model\n",
    "# set_hyper_parameters(batchSize=40, numFrames=30, numRows=120, numCols=120, numEpochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steps_per_epoch= 17 validation_steps= 3\n"
     ]
    }
   ],
   "source": [
    "# # Deriving the steps_per_epoch and validation_steps which are used by fit_generator to decide the number of next() calls it need to make\n",
    "# set_train_validation_steps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_9 (Conv3D)            (None, 30, 120, 120, 16)  1312      \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 30, 120, 120, 16)  0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 30, 120, 120, 16)  64        \n",
      "_________________________________________________________________\n",
      "max_pooling3d_9 (MaxPooling3 (None, 15, 60, 60, 16)    0         \n",
      "_________________________________________________________________\n",
      "conv3d_10 (Conv3D)           (None, 15, 60, 60, 32)    13856     \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 15, 60, 60, 32)    0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 15, 60, 60, 32)    128       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_10 (MaxPooling (None, 7, 30, 30, 32)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_11 (Conv3D)           (None, 7, 30, 30, 64)     55360     \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 7, 30, 30, 64)     0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 7, 30, 30, 64)     256       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_11 (MaxPooling (None, 3, 15, 15, 64)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_12 (Conv3D)           (None, 3, 15, 15, 128)    221312    \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 3, 15, 15, 128)    0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 3, 15, 15, 128)    512       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_12 (MaxPooling (None, 1, 7, 7, 128)      0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 256)               1605888   \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 1,933,765\n",
      "Trainable params: 1,932,517\n",
      "Non-trainable params: 1,248\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# # Calling the base model\n",
    "# model2 = get_conv3d_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # create generators: Let us create the `train_generator` and the `val_generator` which will be used in `.fit_generator`.\n",
    "# train_generator = generator(train_path, train_doc, batch_size)\n",
    "# val_generator = generator(val_path, val_doc, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source path =  Project_data/val ; batch size = 40\n",
      "Source path =  Project_data/train ; batch size = 40\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:13: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "  del sys.path[0]\n",
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:21: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n",
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:44: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:53: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 149s 9s/step - loss: 1.4106 - categorical_accuracy: 0.5174 - val_loss: 3.8075 - val_categorical_accuracy: 0.3400\n",
      "\n",
      "Epoch 00001: saving model to model_init_2019-12-2217_21_14.883121/model-00001-1.43628-0.50679-3.80752-0.34000.h5\n",
      "Epoch 2/2\n",
      "17/17 [==============================] - 45s 3s/step - loss: 0.9017 - categorical_accuracy: 0.6471 - val_loss: 1.7861 - val_categorical_accuracy: 0.4833\n",
      "\n",
      "Epoch 00002: saving model to model_init_2019-12-2217_21_14.883121/model-00002-0.90173-0.64706-1.78607-0.48333.h5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f6bee30e278>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model2.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "#                     callbacks=callbacks_list, validation_data=val_generator, \n",
    "#                     validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "40 seems to be a viable batch size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3: The strategy here is to start small and then increase the complexity of the model if required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# #write your model here\n",
    "# def get_conv3d_model_a():\n",
    "\n",
    "# # Define model\n",
    "#     model = Sequential()\n",
    "\n",
    "#     model.add(Conv3D(16, kernel_size=(3,3,3), input_shape=input_shape,padding='same'))\n",
    "#     model.add(Activation('relu'))\n",
    "#     model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "#     model.add(Conv3D(32, kernel_size=(3,3,3), padding='same'))\n",
    "#     model.add(Activation('relu'))\n",
    "#     model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "#     model.add(Conv3D(64, kernel_size=(3,3,3), padding='same'))\n",
    "#     model.add(Activation('relu'))\n",
    "#     model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "#     #Flatten Layers\n",
    "#     model.add(Flatten())\n",
    "#     model.add(Dense(256, activation='relu'))\n",
    "\n",
    "#     #softmax layer\n",
    "#     model.add(Dense(5, activation='softmax'))\n",
    "\n",
    "#     optimiser = optimizers.Adam(lr=0.001)\n",
    "#     model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "#     print (model.summary())\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_size= 40 ,num_frames= 16 ,num_rows= 60 ,num_cols= 60 ,num_epochs= 50\n"
     ]
    }
   ],
   "source": [
    "# # Set Hyperparameters for the model\n",
    "# set_hyper_parameters(batchSize=40, numFrames=16, numRows=60, numCols=60, numEpochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steps_per_epoch= 17 validation_steps= 3\n"
     ]
    }
   ],
   "source": [
    "# # Deriving the steps_per_epoch and validation_steps which are used by fit_generator to decide the number of next() calls it need to make\n",
    "# set_train_validation_steps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_22 (Conv3D)           (None, 16, 60, 60, 16)    1312      \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 16, 60, 60, 16)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_22 (MaxPooling (None, 8, 30, 30, 16)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_23 (Conv3D)           (None, 8, 30, 30, 32)     13856     \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 8, 30, 30, 32)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_23 (MaxPooling (None, 4, 15, 15, 32)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_24 (Conv3D)           (None, 4, 15, 15, 64)     55360     \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 4, 15, 15, 64)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_24 (MaxPooling (None, 2, 7, 7, 64)       0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 256)               1605888   \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 5)                 1285      \n",
      "=================================================================\n",
      "Total params: 1,677,701\n",
      "Trainable params: 1,677,701\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# model3 = get_conv3d_model_a()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # create generators: Let us create the `train_generator` and the `val_generator` which will be used in `.fit_generator`.\n",
    "# train_generator = generator(train_path, train_doc, batch_size)\n",
    "# val_generator = generator(val_path, val_doc, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:13: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "  del sys.path[0]\n",
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:21: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 18s 1s/step - loss: 0.8033 - categorical_accuracy: 0.6747 - val_loss: 0.9505 - val_categorical_accuracy: 0.6167\n",
      "\n",
      "Epoch 00001: saving model to model_init_2019-12-2217_21_14.883121/model-00001-0.80330-0.67474-0.95048-0.61667.h5\n",
      "Epoch 2/50\n",
      "17/17 [==============================] - 16s 937ms/step - loss: 0.7521 - categorical_accuracy: 0.6920 - val_loss: 0.7844 - val_categorical_accuracy: 0.6500\n",
      "\n",
      "Epoch 00002: saving model to model_init_2019-12-2217_21_14.883121/model-00002-0.75214-0.69204-0.78435-0.65000.h5\n",
      "Epoch 3/50\n",
      "17/17 [==============================] - 16s 956ms/step - loss: 0.7167 - categorical_accuracy: 0.7266 - val_loss: 1.0998 - val_categorical_accuracy: 0.5833\n",
      "\n",
      "Epoch 00003: saving model to model_init_2019-12-2217_21_14.883121/model-00003-0.71671-0.72664-1.09982-0.58333.h5\n",
      "Epoch 4/50\n",
      "17/17 [==============================] - 16s 934ms/step - loss: 0.5715 - categorical_accuracy: 0.7543 - val_loss: 1.0872 - val_categorical_accuracy: 0.5833\n",
      "\n",
      "Epoch 00004: saving model to model_init_2019-12-2217_21_14.883121/model-00004-0.57148-0.75433-1.08723-0.58333.h5\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 5/50\n",
      "17/17 [==============================] - 15s 908ms/step - loss: 0.5636 - categorical_accuracy: 0.7509 - val_loss: 0.6487 - val_categorical_accuracy: 0.6667\n",
      "\n",
      "Epoch 00005: saving model to model_init_2019-12-2217_21_14.883121/model-00005-0.56362-0.75087-0.64869-0.66667.h5\n",
      "Epoch 6/50\n",
      "17/17 [==============================] - 16s 960ms/step - loss: 0.3795 - categorical_accuracy: 0.8478 - val_loss: 1.0634 - val_categorical_accuracy: 0.6167\n",
      "\n",
      "Epoch 00006: saving model to model_init_2019-12-2217_21_14.883121/model-00006-0.37954-0.84775-1.06341-0.61667.h5\n",
      "Epoch 7/50\n",
      "17/17 [==============================] - 15s 902ms/step - loss: 0.4326 - categorical_accuracy: 0.8374 - val_loss: 0.7901 - val_categorical_accuracy: 0.7167\n",
      "\n",
      "Epoch 00007: saving model to model_init_2019-12-2217_21_14.883121/model-00007-0.43262-0.83737-0.79006-0.71667.h5\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 8/50\n",
      "17/17 [==============================] - 16s 934ms/step - loss: 0.2829 - categorical_accuracy: 0.8962 - val_loss: 1.0576 - val_categorical_accuracy: 0.6167\n",
      "\n",
      "Epoch 00008: saving model to model_init_2019-12-2217_21_14.883121/model-00008-0.28286-0.89619-1.05757-0.61667.h5\n",
      "Epoch 9/50\n",
      "17/17 [==============================] - 16s 962ms/step - loss: 0.2323 - categorical_accuracy: 0.9308 - val_loss: 0.7983 - val_categorical_accuracy: 0.7167\n",
      "\n",
      "Epoch 00009: saving model to model_init_2019-12-2217_21_14.883121/model-00009-0.23230-0.93080-0.79827-0.71667.h5\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 10/50\n",
      "17/17 [==============================] - 16s 920ms/step - loss: 0.2153 - categorical_accuracy: 0.9239 - val_loss: 1.0366 - val_categorical_accuracy: 0.6500\n",
      "\n",
      "Epoch 00010: saving model to model_init_2019-12-2217_21_14.883121/model-00010-0.21528-0.92388-1.03656-0.65000.h5\n",
      "Epoch 11/50\n",
      "17/17 [==============================] - 17s 984ms/step - loss: 0.1701 - categorical_accuracy: 0.9343 - val_loss: 0.8034 - val_categorical_accuracy: 0.7167\n",
      "\n",
      "Epoch 00011: saving model to model_init_2019-12-2217_21_14.883121/model-00011-0.17010-0.93426-0.80340-0.71667.h5\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 12/50\n",
      "17/17 [==============================] - 16s 912ms/step - loss: 0.1890 - categorical_accuracy: 0.9481 - val_loss: 0.9520 - val_categorical_accuracy: 0.6500\n",
      "\n",
      "Epoch 00012: saving model to model_init_2019-12-2217_21_14.883121/model-00012-0.18898-0.94810-0.95199-0.65000.h5\n",
      "Epoch 13/50\n",
      "17/17 [==============================] - 15s 911ms/step - loss: 0.1715 - categorical_accuracy: 0.9550 - val_loss: 0.9167 - val_categorical_accuracy: 0.7000\n",
      "\n",
      "Epoch 00013: saving model to model_init_2019-12-2217_21_14.883121/model-00013-0.17151-0.95502-0.91674-0.70000.h5\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 14/50\n",
      "17/17 [==============================] - 16s 929ms/step - loss: 0.1527 - categorical_accuracy: 0.9481 - val_loss: 0.9409 - val_categorical_accuracy: 0.7333\n",
      "\n",
      "Epoch 00014: saving model to model_init_2019-12-2217_21_14.883121/model-00014-0.15269-0.94810-0.94092-0.73333.h5\n",
      "Epoch 15/50\n",
      "17/17 [==============================] - 16s 956ms/step - loss: 0.1284 - categorical_accuracy: 0.9792 - val_loss: 0.6339 - val_categorical_accuracy: 0.7500\n",
      "\n",
      "Epoch 00015: saving model to model_init_2019-12-2217_21_14.883121/model-00015-0.12840-0.97924-0.63391-0.75000.h5\n",
      "Epoch 16/50\n",
      "17/17 [==============================] - 15s 896ms/step - loss: 0.1375 - categorical_accuracy: 0.9585 - val_loss: 1.0028 - val_categorical_accuracy: 0.7333\n",
      "\n",
      "Epoch 00016: saving model to model_init_2019-12-2217_21_14.883121/model-00016-0.13753-0.95848-1.00279-0.73333.h5\n",
      "Epoch 17/50\n",
      "17/17 [==============================] - 17s 992ms/step - loss: 0.1505 - categorical_accuracy: 0.9550 - val_loss: 0.8807 - val_categorical_accuracy: 0.6833\n",
      "\n",
      "Epoch 00017: saving model to model_init_2019-12-2217_21_14.883121/model-00017-0.15046-0.95502-0.88074-0.68333.h5\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 18/50\n",
      "17/17 [==============================] - 16s 938ms/step - loss: 0.1249 - categorical_accuracy: 0.9619 - val_loss: 0.9291 - val_categorical_accuracy: 0.7667\n",
      "\n",
      "Epoch 00018: saving model to model_init_2019-12-2217_21_14.883121/model-00018-0.12492-0.96194-0.92907-0.76667.h5\n",
      "Epoch 19/50\n",
      "17/17 [==============================] - 15s 874ms/step - loss: 0.1706 - categorical_accuracy: 0.9446 - val_loss: 1.0688 - val_categorical_accuracy: 0.6500\n",
      "\n",
      "Epoch 00019: saving model to model_init_2019-12-2217_21_14.883121/model-00019-0.17061-0.94464-1.06876-0.65000.h5\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "Epoch 20/50\n",
      "17/17 [==============================] - 15s 912ms/step - loss: 0.1291 - categorical_accuracy: 0.9619 - val_loss: 1.0222 - val_categorical_accuracy: 0.7667\n",
      "\n",
      "Epoch 00020: saving model to model_init_2019-12-2217_21_14.883121/model-00020-0.12906-0.96194-1.02223-0.76667.h5\n",
      "Epoch 21/50\n",
      "17/17 [==============================] - 16s 953ms/step - loss: 0.1330 - categorical_accuracy: 0.9689 - val_loss: 0.6154 - val_categorical_accuracy: 0.7333\n",
      "\n",
      "Epoch 00021: saving model to model_init_2019-12-2217_21_14.883121/model-00021-0.13298-0.96886-0.61544-0.73333.h5\n",
      "Epoch 22/50\n",
      "17/17 [==============================] - 16s 916ms/step - loss: 0.1427 - categorical_accuracy: 0.9654 - val_loss: 1.1136 - val_categorical_accuracy: 0.6667\n",
      "\n",
      "Epoch 00022: saving model to model_init_2019-12-2217_21_14.883121/model-00022-0.14268-0.96540-1.11362-0.66667.h5\n",
      "Epoch 23/50\n",
      "17/17 [==============================] - 16s 958ms/step - loss: 0.1046 - categorical_accuracy: 0.9827 - val_loss: 0.8613 - val_categorical_accuracy: 0.7167\n",
      "\n",
      "Epoch 00023: saving model to model_init_2019-12-2217_21_14.883121/model-00023-0.10456-0.98270-0.86134-0.71667.h5\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "Epoch 24/50\n",
      "17/17 [==============================] - 16s 924ms/step - loss: 0.1505 - categorical_accuracy: 0.9585 - val_loss: 0.5889 - val_categorical_accuracy: 0.7833\n",
      "\n",
      "Epoch 00024: saving model to model_init_2019-12-2217_21_14.883121/model-00024-0.15052-0.95848-0.58886-0.78333.h5\n",
      "Epoch 25/50\n",
      "17/17 [==============================] - 16s 950ms/step - loss: 0.1292 - categorical_accuracy: 0.9585 - val_loss: 1.0722 - val_categorical_accuracy: 0.6500\n",
      "\n",
      "Epoch 00025: saving model to model_init_2019-12-2217_21_14.883121/model-00025-0.12924-0.95848-1.07218-0.65000.h5\n",
      "Epoch 26/50\n",
      "17/17 [==============================] - 17s 985ms/step - loss: 0.1442 - categorical_accuracy: 0.9723 - val_loss: 0.8986 - val_categorical_accuracy: 0.7167\n",
      "\n",
      "Epoch 00026: saving model to model_init_2019-12-2217_21_14.883121/model-00026-0.14424-0.97232-0.89857-0.71667.h5\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "Epoch 27/50\n",
      "17/17 [==============================] - 16s 925ms/step - loss: 0.1174 - categorical_accuracy: 0.9723 - val_loss: 0.9230 - val_categorical_accuracy: 0.7333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00027: saving model to model_init_2019-12-2217_21_14.883121/model-00027-0.11740-0.97232-0.92296-0.73333.h5\n",
      "Epoch 28/50\n",
      "17/17 [==============================] - 15s 891ms/step - loss: 0.1168 - categorical_accuracy: 0.9689 - val_loss: 0.8552 - val_categorical_accuracy: 0.7167\n",
      "\n",
      "Epoch 00028: saving model to model_init_2019-12-2217_21_14.883121/model-00028-0.11679-0.96886-0.85520-0.71667.h5\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "Epoch 29/50\n",
      "17/17 [==============================] - 16s 962ms/step - loss: 0.1348 - categorical_accuracy: 0.9689 - val_loss: 0.9686 - val_categorical_accuracy: 0.7333\n",
      "\n",
      "Epoch 00029: saving model to model_init_2019-12-2217_21_14.883121/model-00029-0.13476-0.96886-0.96864-0.73333.h5\n",
      "Epoch 30/50\n",
      "17/17 [==============================] - 16s 921ms/step - loss: 0.1211 - categorical_accuracy: 0.9654 - val_loss: 0.7733 - val_categorical_accuracy: 0.7167\n",
      "\n",
      "Epoch 00030: saving model to model_init_2019-12-2217_21_14.883121/model-00030-0.12114-0.96540-0.77333-0.71667.h5\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "Epoch 31/50\n",
      "17/17 [==============================] - 16s 926ms/step - loss: 0.1162 - categorical_accuracy: 0.9758 - val_loss: 1.0183 - val_categorical_accuracy: 0.7000\n",
      "\n",
      "Epoch 00031: saving model to model_init_2019-12-2217_21_14.883121/model-00031-0.11622-0.97578-1.01833-0.70000.h5\n",
      "Epoch 32/50\n",
      "17/17 [==============================] - 16s 932ms/step - loss: 0.1389 - categorical_accuracy: 0.9619 - val_loss: 0.8784 - val_categorical_accuracy: 0.7167\n",
      "\n",
      "Epoch 00032: saving model to model_init_2019-12-2217_21_14.883121/model-00032-0.13887-0.96194-0.87838-0.71667.h5\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "Epoch 33/50\n",
      "17/17 [==============================] - 16s 916ms/step - loss: 0.1178 - categorical_accuracy: 0.9689 - val_loss: 0.7842 - val_categorical_accuracy: 0.7833\n",
      "\n",
      "Epoch 00033: saving model to model_init_2019-12-2217_21_14.883121/model-00033-0.11777-0.96886-0.78419-0.78333.h5\n",
      "Epoch 34/50\n",
      "17/17 [==============================] - 16s 932ms/step - loss: 0.1277 - categorical_accuracy: 0.9619 - val_loss: 1.1948 - val_categorical_accuracy: 0.6333\n",
      "\n",
      "Epoch 00034: saving model to model_init_2019-12-2217_21_14.883121/model-00034-0.12771-0.96194-1.19477-0.63333.h5\n",
      "\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "Epoch 35/50\n",
      "17/17 [==============================] - 16s 928ms/step - loss: 0.1279 - categorical_accuracy: 0.9689 - val_loss: 0.7638 - val_categorical_accuracy: 0.7333\n",
      "\n",
      "Epoch 00035: saving model to model_init_2019-12-2217_21_14.883121/model-00035-0.12789-0.96886-0.76384-0.73333.h5\n",
      "Epoch 36/50\n",
      "17/17 [==============================] - 17s 975ms/step - loss: 0.1392 - categorical_accuracy: 0.9550 - val_loss: 0.9194 - val_categorical_accuracy: 0.7333\n",
      "\n",
      "Epoch 00036: saving model to model_init_2019-12-2217_21_14.883121/model-00036-0.13917-0.95502-0.91940-0.73333.h5\n",
      "\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "Epoch 37/50\n",
      "17/17 [==============================] - 16s 927ms/step - loss: 0.1247 - categorical_accuracy: 0.9723 - val_loss: 0.8935 - val_categorical_accuracy: 0.7167\n",
      "\n",
      "Epoch 00037: saving model to model_init_2019-12-2217_21_14.883121/model-00037-0.12469-0.97232-0.89348-0.71667.h5\n",
      "Epoch 38/50\n",
      "17/17 [==============================] - 16s 932ms/step - loss: 0.1252 - categorical_accuracy: 0.9689 - val_loss: 0.7902 - val_categorical_accuracy: 0.7500\n",
      "\n",
      "Epoch 00038: saving model to model_init_2019-12-2217_21_14.883121/model-00038-0.12516-0.96886-0.79022-0.75000.h5\n",
      "\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "Epoch 39/50\n",
      "17/17 [==============================] - 15s 912ms/step - loss: 0.1126 - categorical_accuracy: 0.9723 - val_loss: 0.9739 - val_categorical_accuracy: 0.7167\n",
      "\n",
      "Epoch 00039: saving model to model_init_2019-12-2217_21_14.883121/model-00039-0.11261-0.97232-0.97391-0.71667.h5\n",
      "Epoch 40/50\n",
      "17/17 [==============================] - 16s 941ms/step - loss: 0.1536 - categorical_accuracy: 0.9585 - val_loss: 0.7068 - val_categorical_accuracy: 0.7833\n",
      "\n",
      "Epoch 00040: saving model to model_init_2019-12-2217_21_14.883121/model-00040-0.15359-0.95848-0.70681-0.78333.h5\n",
      "\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 1.525878978725359e-08.\n",
      "Epoch 41/50\n",
      "17/17 [==============================] - 16s 919ms/step - loss: 0.1319 - categorical_accuracy: 0.9619 - val_loss: 1.1765 - val_categorical_accuracy: 0.6333\n",
      "\n",
      "Epoch 00041: saving model to model_init_2019-12-2217_21_14.883121/model-00041-0.13187-0.96194-1.17650-0.63333.h5\n",
      "Epoch 42/50\n",
      "17/17 [==============================] - 16s 955ms/step - loss: 0.1186 - categorical_accuracy: 0.9689 - val_loss: 0.7971 - val_categorical_accuracy: 0.7333\n",
      "\n",
      "Epoch 00042: saving model to model_init_2019-12-2217_21_14.883121/model-00042-0.11865-0.96886-0.79708-0.73333.h5\n",
      "\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 7.629394893626795e-09.\n",
      "Epoch 43/50\n",
      "17/17 [==============================] - 15s 905ms/step - loss: 0.1107 - categorical_accuracy: 0.9723 - val_loss: 0.9134 - val_categorical_accuracy: 0.7500\n",
      "\n",
      "Epoch 00043: saving model to model_init_2019-12-2217_21_14.883121/model-00043-0.11070-0.97232-0.91342-0.75000.h5\n",
      "Epoch 44/50\n",
      "17/17 [==============================] - 16s 963ms/step - loss: 0.1416 - categorical_accuracy: 0.9619 - val_loss: 1.1013 - val_categorical_accuracy: 0.6333\n",
      "\n",
      "Epoch 00044: saving model to model_init_2019-12-2217_21_14.883121/model-00044-0.14163-0.96194-1.10131-0.63333.h5\n",
      "\n",
      "Epoch 00044: ReduceLROnPlateau reducing learning rate to 3.814697446813398e-09.\n",
      "Epoch 45/50\n",
      "17/17 [==============================] - 16s 937ms/step - loss: 0.1231 - categorical_accuracy: 0.9792 - val_loss: 0.7007 - val_categorical_accuracy: 0.7833\n",
      "\n",
      "Epoch 00045: saving model to model_init_2019-12-2217_21_14.883121/model-00045-0.12305-0.97924-0.70068-0.78333.h5\n",
      "Epoch 46/50\n",
      "17/17 [==============================] - 16s 918ms/step - loss: 0.1173 - categorical_accuracy: 0.9654 - val_loss: 1.0285 - val_categorical_accuracy: 0.7000\n",
      "\n",
      "Epoch 00046: saving model to model_init_2019-12-2217_21_14.883121/model-00046-0.11729-0.96540-1.02847-0.70000.h5\n",
      "\n",
      "Epoch 00046: ReduceLROnPlateau reducing learning rate to 1.907348723406699e-09.\n",
      "Epoch 47/50\n",
      "17/17 [==============================] - 17s 999ms/step - loss: 0.1347 - categorical_accuracy: 0.9585 - val_loss: 1.0044 - val_categorical_accuracy: 0.7667\n",
      "\n",
      "Epoch 00047: saving model to model_init_2019-12-2217_21_14.883121/model-00047-0.13465-0.95848-1.00437-0.76667.h5\n",
      "Epoch 48/50\n",
      "17/17 [==============================] - 15s 880ms/step - loss: 0.1249 - categorical_accuracy: 0.9723 - val_loss: 0.9195 - val_categorical_accuracy: 0.6167\n",
      "\n",
      "Epoch 00048: saving model to model_init_2019-12-2217_21_14.883121/model-00048-0.12489-0.97232-0.91951-0.61667.h5\n",
      "\n",
      "Epoch 00048: ReduceLROnPlateau reducing learning rate to 9.536743617033494e-10.\n",
      "Epoch 49/50\n",
      "17/17 [==============================] - 16s 949ms/step - loss: 0.1341 - categorical_accuracy: 0.9585 - val_loss: 0.7722 - val_categorical_accuracy: 0.7500\n",
      "\n",
      "Epoch 00049: saving model to model_init_2019-12-2217_21_14.883121/model-00049-0.13413-0.95848-0.77219-0.75000.h5\n",
      "Epoch 50/50\n",
      "17/17 [==============================] - 16s 922ms/step - loss: 0.1528 - categorical_accuracy: 0.9654 - val_loss: 0.8096 - val_categorical_accuracy: 0.7833\n",
      "\n",
      "Epoch 00050: saving model to model_init_2019-12-2217_21_14.883121/model-00050-0.15281-0.96540-0.80961-0.78333.h5\n",
      "\n",
      "Epoch 00050: ReduceLROnPlateau reducing learning rate to 4.768371808516747e-10.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f6be7fa30b8>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model3.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "#                     callbacks=callbacks_list, validation_data=val_generator, \n",
    "#                     validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Epoch 24/50\n",
    "17/17 [==============================] - 16s 924ms/step - loss: 0.1505 - categorical_accuracy: 0.9585 - val_loss: 0.5889 - val_categorical_accuracy: 0.7833\n",
    "\n",
    "Epoch 00024: saving model to model_init_2019-12-2217_21_14.883121/model-00024-0.15052-0.95848-0.58886-0.78333.h5\n",
    "\n",
    "\n",
    "The model seems to be clearly overfitting with training accuracy of 0.9585 and validation accuracy of 0.7844"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 4 : Introducing drop outs in CNN layers  and FC layer to reduce overfitting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def get_conv3d_model_b():\n",
    "\n",
    "# # Define model\n",
    "#     model = Sequential()\n",
    "\n",
    "#     model.add(Conv3D(16, kernel_size=(3,3,3), input_shape=input_shape,padding='same'))\n",
    "#     model.add(Activation('relu'))\n",
    "#     model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "#     model.add(Dropout(0.25))\n",
    "\n",
    "#     model.add(Conv3D(32, kernel_size=(3,3,3), padding='same'))\n",
    "#     model.add(Activation('relu'))\n",
    "#     model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "#     model.add(Dropout(0.25))\n",
    "\n",
    "#     model.add(Conv3D(64, kernel_size=(3,3,3), padding='same'))\n",
    "#     model.add(Activation('relu'))\n",
    "#     model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "#     model.add(Dropout(0.25))\n",
    "\n",
    "#     #Flatten Layers\n",
    "#     model.add(Flatten())\n",
    "#     model.add(Dense(256, activation='relu'))\n",
    "#     model.add(Dropout(0.25))\n",
    "\n",
    "#     #softmax layer\n",
    "#     model.add(Dense(5, activation='softmax'))\n",
    "\n",
    "\n",
    "#     optimiser = optimizers.Adam(lr=0.001)\n",
    "#     model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "#     print (model.summary())\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_size= 40 ,num_frames= 16 ,num_rows= 60 ,num_cols= 60 ,num_epochs= 50\n"
     ]
    }
   ],
   "source": [
    "# # Set Hyperparameters for the model\n",
    "# set_hyper_parameters(batchSize=40, numFrames=16, numRows=60, numCols=60, numEpochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steps_per_epoch= 17 validation_steps= 3\n"
     ]
    }
   ],
   "source": [
    "# set_train_validation_steps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_1 (Conv3D)            (None, 16, 60, 60, 16)    1312      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 16, 60, 60, 16)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3 (None, 8, 30, 30, 16)     0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 8, 30, 30, 16)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_2 (Conv3D)            (None, 8, 30, 30, 32)     13856     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 8, 30, 30, 32)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3 (None, 4, 15, 15, 32)     0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4, 15, 15, 32)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_3 (Conv3D)            (None, 4, 15, 15, 64)     55360     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 4, 15, 15, 64)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling3d_3 (MaxPooling3 (None, 2, 7, 7, 64)       0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 2, 7, 7, 64)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               1605888   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 1285      \n",
      "=================================================================\n",
      "Total params: 1,677,701\n",
      "Trainable params: 1,677,701\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# ## Calling the model function\n",
    "# model4 = get_conv3d_model_b()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # create generators: Let us create the `train_generator` and the `val_generator` which will be used in `.fit_generator`.\n",
    "# train_generator = generator(train_path, train_doc, batch_size)\n",
    "# val_generator = generator(val_path, val_doc, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:13: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "  del sys.path[0]\n",
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:21: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 19s 1s/step - loss: 0.5440 - categorical_accuracy: 0.7993 - val_loss: 0.6375 - val_categorical_accuracy: 0.7167\n",
      "\n",
      "Epoch 00001: saving model to model_init_2019-12-2218_27_33.746320/model-00001-0.54399-0.79931-0.63745-0.71667.h5\n",
      "Epoch 2/50\n",
      "17/17 [==============================] - 16s 950ms/step - loss: 0.4666 - categorical_accuracy: 0.8097 - val_loss: 0.6566 - val_categorical_accuracy: 0.6833\n",
      "\n",
      "Epoch 00002: saving model to model_init_2019-12-2218_27_33.746320/model-00002-0.46664-0.80969-0.65662-0.68333.h5\n",
      "Epoch 3/50\n",
      "17/17 [==============================] - 16s 919ms/step - loss: 0.5124 - categorical_accuracy: 0.7924 - val_loss: 0.6064 - val_categorical_accuracy: 0.7667\n",
      "\n",
      "Epoch 00003: saving model to model_init_2019-12-2218_27_33.746320/model-00003-0.51239-0.79239-0.60645-0.76667.h5\n",
      "Epoch 4/50\n",
      "17/17 [==============================] - 16s 915ms/step - loss: 0.5055 - categorical_accuracy: 0.8131 - val_loss: 0.6395 - val_categorical_accuracy: 0.7500\n",
      "\n",
      "Epoch 00004: saving model to model_init_2019-12-2218_27_33.746320/model-00004-0.50548-0.81315-0.63945-0.75000.h5\n",
      "Epoch 5/50\n",
      "17/17 [==============================] - 15s 876ms/step - loss: 0.5171 - categorical_accuracy: 0.7716 - val_loss: 0.7798 - val_categorical_accuracy: 0.6333\n",
      "\n",
      "Epoch 00005: saving model to model_init_2019-12-2218_27_33.746320/model-00005-0.51705-0.77163-0.77981-0.63333.h5\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "Epoch 6/50\n",
      "17/17 [==============================] - 16s 964ms/step - loss: 0.5042 - categorical_accuracy: 0.7993 - val_loss: 0.7077 - val_categorical_accuracy: 0.7000\n",
      "\n",
      "Epoch 00006: saving model to model_init_2019-12-2218_27_33.746320/model-00006-0.50422-0.79931-0.70774-0.70000.h5\n",
      "Epoch 7/50\n",
      "17/17 [==============================] - 16s 954ms/step - loss: 0.4639 - categorical_accuracy: 0.8201 - val_loss: 0.5747 - val_categorical_accuracy: 0.7333\n",
      "\n",
      "Epoch 00007: saving model to model_init_2019-12-2218_27_33.746320/model-00007-0.46392-0.82007-0.57473-0.73333.h5\n",
      "Epoch 8/50\n",
      "17/17 [==============================] - 16s 930ms/step - loss: 0.4419 - categorical_accuracy: 0.8478 - val_loss: 0.6688 - val_categorical_accuracy: 0.7333\n",
      "\n",
      "Epoch 00008: saving model to model_init_2019-12-2218_27_33.746320/model-00008-0.44190-0.84775-0.66881-0.73333.h5\n",
      "Epoch 9/50\n",
      "17/17 [==============================] - 16s 938ms/step - loss: 0.5457 - categorical_accuracy: 0.7993 - val_loss: 0.6996 - val_categorical_accuracy: 0.7000\n",
      "\n",
      "Epoch 00009: saving model to model_init_2019-12-2218_27_33.746320/model-00009-0.54572-0.79931-0.69963-0.70000.h5\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "Epoch 10/50\n",
      "17/17 [==============================] - 16s 940ms/step - loss: 0.4962 - categorical_accuracy: 0.8097 - val_loss: 0.6671 - val_categorical_accuracy: 0.6833\n",
      "\n",
      "Epoch 00010: saving model to model_init_2019-12-2218_27_33.746320/model-00010-0.49620-0.80969-0.66711-0.68333.h5\n",
      "Epoch 11/50\n",
      "17/17 [==============================] - 16s 919ms/step - loss: 0.5113 - categorical_accuracy: 0.8166 - val_loss: 0.6316 - val_categorical_accuracy: 0.7500\n",
      "\n",
      "Epoch 00011: saving model to model_init_2019-12-2218_27_33.746320/model-00011-0.51126-0.81661-0.63162-0.75000.h5\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "Epoch 12/50\n",
      "17/17 [==============================] - 17s 979ms/step - loss: 0.4421 - categorical_accuracy: 0.8408 - val_loss: 0.6330 - val_categorical_accuracy: 0.7000\n",
      "\n",
      "Epoch 00012: saving model to model_init_2019-12-2218_27_33.746320/model-00012-0.44211-0.84083-0.63298-0.70000.h5\n",
      "Epoch 13/50\n",
      "17/17 [==============================] - 16s 915ms/step - loss: 0.5089 - categorical_accuracy: 0.8166 - val_loss: 0.7753 - val_categorical_accuracy: 0.6667\n",
      "\n",
      "Epoch 00013: saving model to model_init_2019-12-2218_27_33.746320/model-00013-0.50888-0.81661-0.77527-0.66667.h5\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "Epoch 14/50\n",
      "17/17 [==============================] - 16s 922ms/step - loss: 0.5301 - categorical_accuracy: 0.7993 - val_loss: 0.5685 - val_categorical_accuracy: 0.7167\n",
      "\n",
      "Epoch 00014: saving model to model_init_2019-12-2218_27_33.746320/model-00014-0.53006-0.79931-0.56847-0.71667.h5\n",
      "Epoch 15/50\n",
      "17/17 [==============================] - 15s 890ms/step - loss: 0.4656 - categorical_accuracy: 0.8166 - val_loss: 0.7094 - val_categorical_accuracy: 0.7167\n",
      "\n",
      "Epoch 00015: saving model to model_init_2019-12-2218_27_33.746320/model-00015-0.46561-0.81661-0.70941-0.71667.h5\n",
      "Epoch 16/50\n",
      "17/17 [==============================] - 16s 924ms/step - loss: 0.4860 - categorical_accuracy: 0.7993 - val_loss: 0.7196 - val_categorical_accuracy: 0.6833\n",
      "\n",
      "Epoch 00016: saving model to model_init_2019-12-2218_27_33.746320/model-00016-0.48596-0.79931-0.71957-0.68333.h5\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "Epoch 17/50\n",
      "17/17 [==============================] - 16s 964ms/step - loss: 0.5097 - categorical_accuracy: 0.7993 - val_loss: 0.5967 - val_categorical_accuracy: 0.7667\n",
      "\n",
      "Epoch 00017: saving model to model_init_2019-12-2218_27_33.746320/model-00017-0.50970-0.79931-0.59669-0.76667.h5\n",
      "Epoch 18/50\n",
      "17/17 [==============================] - 16s 938ms/step - loss: 0.4892 - categorical_accuracy: 0.8201 - val_loss: 0.6745 - val_categorical_accuracy: 0.7000\n",
      "\n",
      "Epoch 00018: saving model to model_init_2019-12-2218_27_33.746320/model-00018-0.48923-0.82007-0.67452-0.70000.h5\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 1.525878978725359e-08.\n",
      "Epoch 19/50\n",
      "17/17 [==============================] - 16s 941ms/step - loss: 0.4714 - categorical_accuracy: 0.8201 - val_loss: 0.6930 - val_categorical_accuracy: 0.6333\n",
      "\n",
      "Epoch 00019: saving model to model_init_2019-12-2218_27_33.746320/model-00019-0.47137-0.82007-0.69300-0.63333.h5\n",
      "Epoch 20/50\n",
      "17/17 [==============================] - 15s 896ms/step - loss: 0.5238 - categorical_accuracy: 0.7924 - val_loss: 0.6337 - val_categorical_accuracy: 0.7667\n",
      "\n",
      "Epoch 00020: saving model to model_init_2019-12-2218_27_33.746320/model-00020-0.52380-0.79239-0.63374-0.76667.h5\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 7.629394893626795e-09.\n",
      "Epoch 21/50\n",
      "17/17 [==============================] - 16s 964ms/step - loss: 0.4674 - categorical_accuracy: 0.8304 - val_loss: 0.7368 - val_categorical_accuracy: 0.6667\n",
      "\n",
      "Epoch 00021: saving model to model_init_2019-12-2218_27_33.746320/model-00021-0.46740-0.83045-0.73678-0.66667.h5\n",
      "Epoch 22/50\n",
      "17/17 [==============================] - 15s 906ms/step - loss: 0.4913 - categorical_accuracy: 0.8201 - val_loss: 0.5929 - val_categorical_accuracy: 0.7833\n",
      "\n",
      "Epoch 00022: saving model to model_init_2019-12-2218_27_33.746320/model-00022-0.49131-0.82007-0.59286-0.78333.h5\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 3.814697446813398e-09.\n",
      "Epoch 23/50\n",
      "17/17 [==============================] - 17s 979ms/step - loss: 0.5115 - categorical_accuracy: 0.8166 - val_loss: 0.7170 - val_categorical_accuracy: 0.6500\n",
      "\n",
      "Epoch 00023: saving model to model_init_2019-12-2218_27_33.746320/model-00023-0.51154-0.81661-0.71696-0.65000.h5\n",
      "Epoch 24/50\n",
      "17/17 [==============================] - 16s 919ms/step - loss: 0.4724 - categorical_accuracy: 0.8201 - val_loss: 0.5447 - val_categorical_accuracy: 0.7833\n",
      "\n",
      "Epoch 00024: saving model to model_init_2019-12-2218_27_33.746320/model-00024-0.47244-0.82007-0.54474-0.78333.h5\n",
      "Epoch 25/50\n",
      "17/17 [==============================] - 15s 908ms/step - loss: 0.4838 - categorical_accuracy: 0.8097 - val_loss: 0.7262 - val_categorical_accuracy: 0.6667\n",
      "\n",
      "Epoch 00025: saving model to model_init_2019-12-2218_27_33.746320/model-00025-0.48380-0.80969-0.72617-0.66667.h5\n",
      "Epoch 26/50\n",
      "17/17 [==============================] - 16s 939ms/step - loss: 0.5430 - categorical_accuracy: 0.8028 - val_loss: 0.6982 - val_categorical_accuracy: 0.6833\n",
      "\n",
      "Epoch 00026: saving model to model_init_2019-12-2218_27_33.746320/model-00026-0.54301-0.80277-0.69820-0.68333.h5\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 1.907348723406699e-09.\n",
      "Epoch 27/50\n",
      "17/17 [==============================] - 16s 963ms/step - loss: 0.4414 - categorical_accuracy: 0.8547 - val_loss: 0.6172 - val_categorical_accuracy: 0.7500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00027: saving model to model_init_2019-12-2218_27_33.746320/model-00027-0.44142-0.85467-0.61722-0.75000.h5\n",
      "Epoch 28/50\n",
      "17/17 [==============================] - 16s 929ms/step - loss: 0.4638 - categorical_accuracy: 0.8339 - val_loss: 0.6497 - val_categorical_accuracy: 0.7000\n",
      "\n",
      "Epoch 00028: saving model to model_init_2019-12-2218_27_33.746320/model-00028-0.46385-0.83391-0.64965-0.70000.h5\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 9.536743617033494e-10.\n",
      "Epoch 29/50\n",
      "17/17 [==============================] - 17s 971ms/step - loss: 0.4980 - categorical_accuracy: 0.7958 - val_loss: 0.7417 - val_categorical_accuracy: 0.7500\n",
      "\n",
      "Epoch 00029: saving model to model_init_2019-12-2218_27_33.746320/model-00029-0.49796-0.79585-0.74165-0.75000.h5\n",
      "Epoch 30/50\n",
      "17/17 [==============================] - 15s 907ms/step - loss: 0.5134 - categorical_accuracy: 0.7855 - val_loss: 0.6108 - val_categorical_accuracy: 0.6667\n",
      "\n",
      "Epoch 00030: saving model to model_init_2019-12-2218_27_33.746320/model-00030-0.51341-0.78547-0.61078-0.66667.h5\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 4.768371808516747e-10.\n",
      "Epoch 31/50\n",
      "17/17 [==============================] - 16s 950ms/step - loss: 0.4486 - categorical_accuracy: 0.8374 - val_loss: 0.6962 - val_categorical_accuracy: 0.6833\n",
      "\n",
      "Epoch 00031: saving model to model_init_2019-12-2218_27_33.746320/model-00031-0.44863-0.83737-0.69622-0.68333.h5\n",
      "Epoch 32/50\n",
      "17/17 [==============================] - 16s 953ms/step - loss: 0.5658 - categorical_accuracy: 0.7993 - val_loss: 0.6287 - val_categorical_accuracy: 0.7333\n",
      "\n",
      "Epoch 00032: saving model to model_init_2019-12-2218_27_33.746320/model-00032-0.56584-0.79931-0.62867-0.73333.h5\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 2.3841859042583735e-10.\n",
      "Epoch 33/50\n",
      "17/17 [==============================] - 16s 936ms/step - loss: 0.5162 - categorical_accuracy: 0.7855 - val_loss: 0.6817 - val_categorical_accuracy: 0.6833\n",
      "\n",
      "Epoch 00033: saving model to model_init_2019-12-2218_27_33.746320/model-00033-0.51623-0.78547-0.68168-0.68333.h5\n",
      "Epoch 34/50\n",
      "17/17 [==============================] - 16s 943ms/step - loss: 0.5175 - categorical_accuracy: 0.8097 - val_loss: 0.6174 - val_categorical_accuracy: 0.7500\n",
      "\n",
      "Epoch 00034: saving model to model_init_2019-12-2218_27_33.746320/model-00034-0.51748-0.80969-0.61738-0.75000.h5\n",
      "\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 1.1920929521291868e-10.\n",
      "Epoch 35/50\n",
      "17/17 [==============================] - 16s 945ms/step - loss: 0.4968 - categorical_accuracy: 0.8062 - val_loss: 0.6935 - val_categorical_accuracy: 0.7000\n",
      "\n",
      "Epoch 00035: saving model to model_init_2019-12-2218_27_33.746320/model-00035-0.49675-0.80623-0.69354-0.70000.h5\n",
      "Epoch 36/50\n",
      "17/17 [==============================] - 16s 933ms/step - loss: 0.4973 - categorical_accuracy: 0.8201 - val_loss: 0.7821 - val_categorical_accuracy: 0.6333\n",
      "\n",
      "Epoch 00036: saving model to model_init_2019-12-2218_27_33.746320/model-00036-0.49734-0.82007-0.78206-0.63333.h5\n",
      "\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 5.960464760645934e-11.\n",
      "Epoch 37/50\n",
      "17/17 [==============================] - 15s 881ms/step - loss: 0.5185 - categorical_accuracy: 0.7958 - val_loss: 0.5991 - val_categorical_accuracy: 0.7500\n",
      "\n",
      "Epoch 00037: saving model to model_init_2019-12-2218_27_33.746320/model-00037-0.51854-0.79585-0.59911-0.75000.h5\n",
      "Epoch 38/50\n",
      "17/17 [==============================] - 16s 945ms/step - loss: 0.5001 - categorical_accuracy: 0.7924 - val_loss: 0.5821 - val_categorical_accuracy: 0.7500\n",
      "\n",
      "Epoch 00038: saving model to model_init_2019-12-2218_27_33.746320/model-00038-0.50012-0.79239-0.58210-0.75000.h5\n",
      "\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 2.980232380322967e-11.\n",
      "Epoch 39/50\n",
      "17/17 [==============================] - 17s 999ms/step - loss: 0.4940 - categorical_accuracy: 0.8235 - val_loss: 0.6841 - val_categorical_accuracy: 0.7000\n",
      "\n",
      "Epoch 00039: saving model to model_init_2019-12-2218_27_33.746320/model-00039-0.49399-0.82353-0.68406-0.70000.h5\n",
      "Epoch 40/50\n",
      "17/17 [==============================] - 16s 939ms/step - loss: 0.5185 - categorical_accuracy: 0.7993 - val_loss: 0.6702 - val_categorical_accuracy: 0.7167\n",
      "\n",
      "Epoch 00040: saving model to model_init_2019-12-2218_27_33.746320/model-00040-0.51848-0.79931-0.67017-0.71667.h5\n",
      "\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 1.4901161901614834e-11.\n",
      "Epoch 41/50\n",
      "17/17 [==============================] - 15s 892ms/step - loss: 0.4706 - categorical_accuracy: 0.8201 - val_loss: 0.6486 - val_categorical_accuracy: 0.7000\n",
      "\n",
      "Epoch 00041: saving model to model_init_2019-12-2218_27_33.746320/model-00041-0.47063-0.82007-0.64860-0.70000.h5\n",
      "Epoch 42/50\n",
      "17/17 [==============================] - 15s 900ms/step - loss: 0.5184 - categorical_accuracy: 0.7958 - val_loss: 0.6468 - val_categorical_accuracy: 0.7500\n",
      "\n",
      "Epoch 00042: saving model to model_init_2019-12-2218_27_33.746320/model-00042-0.51843-0.79585-0.64682-0.75000.h5\n",
      "\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 7.450580950807417e-12.\n",
      "Epoch 43/50\n",
      "17/17 [==============================] - 17s 980ms/step - loss: 0.4590 - categorical_accuracy: 0.8512 - val_loss: 0.7123 - val_categorical_accuracy: 0.6500\n",
      "\n",
      "Epoch 00043: saving model to model_init_2019-12-2218_27_33.746320/model-00043-0.45904-0.85121-0.71229-0.65000.h5\n",
      "Epoch 44/50\n",
      "17/17 [==============================] - 15s 887ms/step - loss: 0.4741 - categorical_accuracy: 0.8235 - val_loss: 0.5984 - val_categorical_accuracy: 0.7333\n",
      "\n",
      "Epoch 00044: saving model to model_init_2019-12-2218_27_33.746320/model-00044-0.47415-0.82353-0.59843-0.73333.h5\n",
      "\n",
      "Epoch 00044: ReduceLROnPlateau reducing learning rate to 3.725290475403709e-12.\n",
      "Epoch 45/50\n",
      "17/17 [==============================] - 17s 973ms/step - loss: 0.5195 - categorical_accuracy: 0.7647 - val_loss: 0.7114 - val_categorical_accuracy: 0.7167\n",
      "\n",
      "Epoch 00045: saving model to model_init_2019-12-2218_27_33.746320/model-00045-0.51953-0.76471-0.71136-0.71667.h5\n",
      "Epoch 46/50\n",
      "17/17 [==============================] - 15s 907ms/step - loss: 0.5775 - categorical_accuracy: 0.7751 - val_loss: 0.6301 - val_categorical_accuracy: 0.7500\n",
      "\n",
      "Epoch 00046: saving model to model_init_2019-12-2218_27_33.746320/model-00046-0.57754-0.77509-0.63015-0.75000.h5\n",
      "\n",
      "Epoch 00046: ReduceLROnPlateau reducing learning rate to 1.8626452377018543e-12.\n",
      "Epoch 47/50\n",
      "17/17 [==============================] - 17s 974ms/step - loss: 0.4500 - categorical_accuracy: 0.8374 - val_loss: 0.7143 - val_categorical_accuracy: 0.6667\n",
      "\n",
      "Epoch 00047: saving model to model_init_2019-12-2218_27_33.746320/model-00047-0.45000-0.83737-0.71428-0.66667.h5\n",
      "Epoch 48/50\n",
      "17/17 [==============================] - 15s 903ms/step - loss: 0.5137 - categorical_accuracy: 0.7820 - val_loss: 0.6761 - val_categorical_accuracy: 0.7333\n",
      "\n",
      "Epoch 00048: saving model to model_init_2019-12-2218_27_33.746320/model-00048-0.51366-0.78201-0.67614-0.73333.h5\n",
      "\n",
      "Epoch 00048: ReduceLROnPlateau reducing learning rate to 9.313226188509272e-13.\n",
      "Epoch 49/50\n",
      "17/17 [==============================] - 15s 884ms/step - loss: 0.4926 - categorical_accuracy: 0.7993 - val_loss: 0.8074 - val_categorical_accuracy: 0.6000\n",
      "\n",
      "Epoch 00049: saving model to model_init_2019-12-2218_27_33.746320/model-00049-0.49263-0.79931-0.80743-0.60000.h5\n",
      "Epoch 50/50\n",
      "17/17 [==============================] - 17s 986ms/step - loss: 0.5048 - categorical_accuracy: 0.8166 - val_loss: 0.4895 - val_categorical_accuracy: 0.8000\n",
      "\n",
      "Epoch 00050: saving model to model_init_2019-12-2218_27_33.746320/model-00050-0.50479-0.81661-0.48949-0.80000.h5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f47ebfdb160>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model4.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "#                     callbacks=callbacks_list, validation_data=val_generator, \n",
    "#                     validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Epoch 24/50\n",
    "17/17 [==============================] - 16s 919ms/step - loss: 0.4724 - categorical_accuracy: 0.8201 - val_loss: 0.5447 - val_categorical_accuracy: 0.7833\n",
    "\n",
    "Epoch 00024: saving model to model_init_2019-12-2218_27_33.746320/model-00024-0.47244-0.82007-0.54474-0.78333.h5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 5 : Remove dropouts from conv layers, retain dropouts in FC, use BN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def get_conv3d_model_c():\n",
    "\n",
    "# # Define model\n",
    "#     model = Sequential()\n",
    "\n",
    "#     model.add(Conv3D(16, kernel_size=(3,3,3), input_shape=input_shape,padding='same'))\n",
    "#     model.add(Activation('relu'))\n",
    "#     model.add(BatchNormalization())\n",
    "#     model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "#     model.add(Conv3D(32, kernel_size=(3,3,3), padding='same'))\n",
    "#     model.add(Activation('relu'))\n",
    "#     model.add(BatchNormalization())\n",
    "#     model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "   \n",
    "\n",
    "#     model.add(Conv3D(64, kernel_size=(3,3,3), padding='same'))\n",
    "#     model.add(Activation('relu'))\n",
    "#     model.add(BatchNormalization())\n",
    "#     model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "   \n",
    "\n",
    "#     #Flatten Layers\n",
    "#     model.add(Flatten())\n",
    "#     model.add(Dense(256, activation='relu'))\n",
    "#     model.add(Dropout(0.25))\n",
    "\n",
    "#     #softmax layer\n",
    "#     model.add(Dense(5, activation='softmax'))\n",
    "\n",
    "\n",
    "#     optimiser = optimizers.Adam(lr=0.001)\n",
    "#     model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "#     print (model.summary())\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_size= 40 ,num_frames= 16 ,num_rows= 60 ,num_cols= 60 ,num_epochs= 50\n"
     ]
    }
   ],
   "source": [
    "# # Set Hyperparameters for the model\n",
    "# set_hyper_parameters(batchSize=40, numFrames=16, numRows=60, numCols=60, numEpochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steps_per_epoch= 17 validation_steps= 3\n"
     ]
    }
   ],
   "source": [
    "# set_train_validation_steps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_10 (Conv3D)           (None, 16, 60, 60, 16)    1312      \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 16, 60, 60, 16)    0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 16, 60, 60, 16)    64        \n",
      "_________________________________________________________________\n",
      "max_pooling3d_10 (MaxPooling (None, 8, 30, 30, 16)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_11 (Conv3D)           (None, 8, 30, 30, 32)     13856     \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 8, 30, 30, 32)     0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 8, 30, 30, 32)     128       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_11 (MaxPooling (None, 4, 15, 15, 32)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_12 (Conv3D)           (None, 4, 15, 15, 64)     55360     \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 4, 15, 15, 64)     0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 4, 15, 15, 64)     256       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_12 (MaxPooling (None, 2, 7, 7, 64)       0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 256)               1605888   \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 5)                 1285      \n",
      "=================================================================\n",
      "Total params: 1,678,149\n",
      "Trainable params: 1,677,925\n",
      "Non-trainable params: 224\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# ## Calling the model function\n",
    "# model5 = get_conv3d_model_c()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # create generators: Let us create the `train_generator` and the `val_generator` which will be used in `.fit_generator`.\n",
    "# train_generator = generator(train_path, train_doc, batch_size)\n",
    "# val_generator = generator(val_path, val_doc, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source path = Source path =  Project_data/train Epoch 1/50\n",
      " Project_data/val ; batch size = 40\n",
      "; batch size = 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:13: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "  del sys.path[0]\n",
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:21: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2/17 [==>...........................] - ETA: 46s - loss: 5.8230 - categorical_accuracy: 0.1750 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:44: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:53: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 40s 2s/step - loss: 6.8811 - categorical_accuracy: 0.3191 - val_loss: 9.1456 - val_categorical_accuracy: 0.3200\n",
      "\n",
      "Epoch 00001: saving model to model_init_2019-12-2218_27_33.746320/model-00001-6.93266-0.31523-9.14557-0.32000.h5\n",
      "Epoch 2/50\n",
      "17/17 [==============================] - 21s 1s/step - loss: 5.4412 - categorical_accuracy: 0.4476 - val_loss: 7.0022 - val_categorical_accuracy: 0.4167\n",
      "\n",
      "Epoch 00002: saving model to model_init_2019-12-2218_27_33.746320/model-00002-5.44119-0.44757-7.00216-0.41667.h5\n",
      "Epoch 3/50\n",
      "17/17 [==============================] - 20s 1s/step - loss: 4.6952 - categorical_accuracy: 0.4664 - val_loss: 9.1679 - val_categorical_accuracy: 0.2000\n",
      "\n",
      "Epoch 00003: saving model to model_init_2019-12-2218_27_33.746320/model-00003-4.72082-0.46866-9.16790-0.20000.h5\n",
      "Epoch 4/50\n",
      "17/17 [==============================] - 17s 1s/step - loss: 2.3112 - categorical_accuracy: 0.4458 - val_loss: 2.4679 - val_categorical_accuracy: 0.3833\n",
      "\n",
      "Epoch 00004: saving model to model_init_2019-12-2218_27_33.746320/model-00004-2.31124-0.44582-2.46792-0.38333.h5\n",
      "Epoch 5/50\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.1984 - categorical_accuracy: 0.6175 - val_loss: 1.0692 - val_categorical_accuracy: 0.6167\n",
      "\n",
      "Epoch 00005: saving model to model_init_2019-12-2218_27_33.746320/model-00005-1.21526-0.61342-1.06919-0.61667.h5\n",
      "Epoch 6/50\n",
      "17/17 [==============================] - 17s 979ms/step - loss: 1.0178 - categorical_accuracy: 0.5882 - val_loss: 1.5135 - val_categorical_accuracy: 0.5167\n",
      "\n",
      "Epoch 00006: saving model to model_init_2019-12-2218_27_33.746320/model-00006-1.01780-0.58824-1.51346-0.51667.h5\n",
      "Epoch 7/50\n",
      "17/17 [==============================] - 16s 914ms/step - loss: 0.9783 - categorical_accuracy: 0.6609 - val_loss: 0.8584 - val_categorical_accuracy: 0.7000\n",
      "\n",
      "Epoch 00007: saving model to model_init_2019-12-2218_27_33.746320/model-00007-0.97828-0.66090-0.85838-0.70000.h5\n",
      "Epoch 8/50\n",
      "17/17 [==============================] - 16s 939ms/step - loss: 0.8427 - categorical_accuracy: 0.6782 - val_loss: 1.0605 - val_categorical_accuracy: 0.5833\n",
      "\n",
      "Epoch 00008: saving model to model_init_2019-12-2218_27_33.746320/model-00008-0.84270-0.67820-1.06047-0.58333.h5\n",
      "Epoch 9/50\n",
      "17/17 [==============================] - 16s 966ms/step - loss: 0.6230 - categorical_accuracy: 0.7612 - val_loss: 1.2945 - val_categorical_accuracy: 0.6667\n",
      "\n",
      "Epoch 00009: saving model to model_init_2019-12-2218_27_33.746320/model-00009-0.62301-0.76125-1.29445-0.66667.h5\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 10/50\n",
      "17/17 [==============================] - 15s 904ms/step - loss: 0.5745 - categorical_accuracy: 0.7889 - val_loss: 0.6636 - val_categorical_accuracy: 0.7500\n",
      "\n",
      "Epoch 00010: saving model to model_init_2019-12-2218_27_33.746320/model-00010-0.57449-0.78893-0.66360-0.75000.h5\n",
      "Epoch 11/50\n",
      "17/17 [==============================] - 16s 936ms/step - loss: 0.3910 - categorical_accuracy: 0.8651 - val_loss: 0.6345 - val_categorical_accuracy: 0.8000\n",
      "\n",
      "Epoch 00011: saving model to model_init_2019-12-2218_27_33.746320/model-00011-0.39104-0.86505-0.63449-0.80000.h5\n",
      "Epoch 12/50\n",
      "17/17 [==============================] - 17s 987ms/step - loss: 0.3561 - categorical_accuracy: 0.8547 - val_loss: 0.6011 - val_categorical_accuracy: 0.7833\n",
      "\n",
      "Epoch 00012: saving model to model_init_2019-12-2218_27_33.746320/model-00012-0.35611-0.85467-0.60114-0.78333.h5\n",
      "Epoch 13/50\n",
      "17/17 [==============================] - 16s 938ms/step - loss: 0.3283 - categorical_accuracy: 0.8824 - val_loss: 1.0839 - val_categorical_accuracy: 0.6333\n",
      "\n",
      "Epoch 00013: saving model to model_init_2019-12-2218_27_33.746320/model-00013-0.32829-0.88235-1.08389-0.63333.h5\n",
      "Epoch 14/50\n",
      "17/17 [==============================] - 16s 942ms/step - loss: 0.3749 - categorical_accuracy: 0.8478 - val_loss: 0.5986 - val_categorical_accuracy: 0.7833\n",
      "\n",
      "Epoch 00014: saving model to model_init_2019-12-2218_27_33.746320/model-00014-0.37487-0.84775-0.59856-0.78333.h5\n",
      "Epoch 15/50\n",
      "17/17 [==============================] - 16s 956ms/step - loss: 0.3149 - categorical_accuracy: 0.8754 - val_loss: 1.1314 - val_categorical_accuracy: 0.6833\n",
      "\n",
      "Epoch 00015: saving model to model_init_2019-12-2218_27_33.746320/model-00015-0.31490-0.87543-1.13144-0.68333.h5\n",
      "Epoch 16/50\n",
      "17/17 [==============================] - 16s 924ms/step - loss: 0.2898 - categorical_accuracy: 0.9031 - val_loss: 0.5863 - val_categorical_accuracy: 0.7333\n",
      "\n",
      "Epoch 00016: saving model to model_init_2019-12-2218_27_33.746320/model-00016-0.28982-0.90311-0.58631-0.73333.h5\n",
      "Epoch 17/50\n",
      "17/17 [==============================] - 16s 932ms/step - loss: 0.1942 - categorical_accuracy: 0.9412 - val_loss: 0.6580 - val_categorical_accuracy: 0.7333\n",
      "\n",
      "Epoch 00017: saving model to model_init_2019-12-2218_27_33.746320/model-00017-0.19420-0.94118-0.65805-0.73333.h5\n",
      "Epoch 18/50\n",
      "17/17 [==============================] - 16s 948ms/step - loss: 0.2242 - categorical_accuracy: 0.9170 - val_loss: 0.7123 - val_categorical_accuracy: 0.6833\n",
      "\n",
      "Epoch 00018: saving model to model_init_2019-12-2218_27_33.746320/model-00018-0.22416-0.91696-0.71231-0.68333.h5\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 19/50\n",
      "17/17 [==============================] - 16s 956ms/step - loss: 0.1921 - categorical_accuracy: 0.9273 - val_loss: 0.9291 - val_categorical_accuracy: 0.6833\n",
      "\n",
      "Epoch 00019: saving model to model_init_2019-12-2218_27_33.746320/model-00019-0.19208-0.92734-0.92913-0.68333.h5\n",
      "Epoch 20/50\n",
      "17/17 [==============================] - 16s 916ms/step - loss: 0.1342 - categorical_accuracy: 0.9516 - val_loss: 0.4315 - val_categorical_accuracy: 0.8000\n",
      "\n",
      "Epoch 00020: saving model to model_init_2019-12-2218_27_33.746320/model-00020-0.13425-0.95156-0.43153-0.80000.h5\n",
      "Epoch 21/50\n",
      "17/17 [==============================] - 17s 984ms/step - loss: 0.1196 - categorical_accuracy: 0.9758 - val_loss: 0.8883 - val_categorical_accuracy: 0.7167\n",
      "\n",
      "Epoch 00021: saving model to model_init_2019-12-2218_27_33.746320/model-00021-0.11961-0.97578-0.88830-0.71667.h5\n",
      "Epoch 22/50\n",
      "17/17 [==============================] - 16s 944ms/step - loss: 0.1019 - categorical_accuracy: 0.9689 - val_loss: 0.9942 - val_categorical_accuracy: 0.6667\n",
      "\n",
      "Epoch 00022: saving model to model_init_2019-12-2218_27_33.746320/model-00022-0.10194-0.96886-0.99422-0.66667.h5\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 23/50\n",
      "17/17 [==============================] - 16s 918ms/step - loss: 0.1172 - categorical_accuracy: 0.9619 - val_loss: 0.4453 - val_categorical_accuracy: 0.8500\n",
      "\n",
      "Epoch 00023: saving model to model_init_2019-12-2218_27_33.746320/model-00023-0.11722-0.96194-0.44531-0.85000.h5\n",
      "Epoch 24/50\n",
      "17/17 [==============================] - 16s 968ms/step - loss: 0.1158 - categorical_accuracy: 0.9619 - val_loss: 0.6757 - val_categorical_accuracy: 0.7000\n",
      "\n",
      "Epoch 00024: saving model to model_init_2019-12-2218_27_33.746320/model-00024-0.11580-0.96194-0.67570-0.70000.h5\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 25/50\n",
      "17/17 [==============================] - 16s 948ms/step - loss: 0.0745 - categorical_accuracy: 0.9862 - val_loss: 0.8404 - val_categorical_accuracy: 0.7333\n",
      "\n",
      "Epoch 00025: saving model to model_init_2019-12-2218_27_33.746320/model-00025-0.07447-0.98616-0.84042-0.73333.h5\n",
      "Epoch 26/50\n",
      "17/17 [==============================] - 15s 883ms/step - loss: 0.1165 - categorical_accuracy: 0.9585 - val_loss: 0.6746 - val_categorical_accuracy: 0.7833\n",
      "\n",
      "Epoch 00026: saving model to model_init_2019-12-2218_27_33.746320/model-00026-0.11651-0.95848-0.67462-0.78333.h5\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 27/50\n",
      "17/17 [==============================] - 16s 926ms/step - loss: 0.0896 - categorical_accuracy: 0.9827 - val_loss: 0.9042 - val_categorical_accuracy: 0.7167\n",
      "\n",
      "Epoch 00027: saving model to model_init_2019-12-2218_27_33.746320/model-00027-0.08958-0.98270-0.90424-0.71667.h5\n",
      "Epoch 28/50\n",
      "17/17 [==============================] - 16s 952ms/step - loss: 0.0889 - categorical_accuracy: 0.9827 - val_loss: 0.4277 - val_categorical_accuracy: 0.7833\n",
      "\n",
      "Epoch 00028: saving model to model_init_2019-12-2218_27_33.746320/model-00028-0.08891-0.98270-0.42768-0.78333.h5\n",
      "Epoch 29/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 17s 977ms/step - loss: 0.0862 - categorical_accuracy: 0.9827 - val_loss: 0.8910 - val_categorical_accuracy: 0.7167\n",
      "\n",
      "Epoch 00029: saving model to model_init_2019-12-2218_27_33.746320/model-00029-0.08624-0.98270-0.89104-0.71667.h5\n",
      "Epoch 30/50\n",
      "17/17 [==============================] - 16s 935ms/step - loss: 0.0728 - categorical_accuracy: 0.9896 - val_loss: 0.4333 - val_categorical_accuracy: 0.8167\n",
      "\n",
      "Epoch 00030: saving model to model_init_2019-12-2218_27_33.746320/model-00030-0.07278-0.98962-0.43332-0.81667.h5\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 31/50\n",
      "17/17 [==============================] - 15s 910ms/step - loss: 0.0887 - categorical_accuracy: 0.9758 - val_loss: 0.8118 - val_categorical_accuracy: 0.7167\n",
      "\n",
      "Epoch 00031: saving model to model_init_2019-12-2218_27_33.746320/model-00031-0.08869-0.97578-0.81185-0.71667.h5\n",
      "Epoch 32/50\n",
      "17/17 [==============================] - 17s 999ms/step - loss: 0.0907 - categorical_accuracy: 0.9758 - val_loss: 0.5149 - val_categorical_accuracy: 0.7833\n",
      "\n",
      "Epoch 00032: saving model to model_init_2019-12-2218_27_33.746320/model-00032-0.09068-0.97578-0.51491-0.78333.h5\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "Epoch 33/50\n",
      "17/17 [==============================] - 16s 933ms/step - loss: 0.0814 - categorical_accuracy: 0.9723 - val_loss: 1.0465 - val_categorical_accuracy: 0.6500\n",
      "\n",
      "Epoch 00033: saving model to model_init_2019-12-2218_27_33.746320/model-00033-0.08145-0.97232-1.04645-0.65000.h5\n",
      "Epoch 34/50\n",
      "17/17 [==============================] - 15s 905ms/step - loss: 0.0820 - categorical_accuracy: 0.9792 - val_loss: 0.5498 - val_categorical_accuracy: 0.8000\n",
      "\n",
      "Epoch 00034: saving model to model_init_2019-12-2218_27_33.746320/model-00034-0.08196-0.97924-0.54985-0.80000.h5\n",
      "\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "Epoch 35/50\n",
      "17/17 [==============================] - 17s 984ms/step - loss: 0.0836 - categorical_accuracy: 0.9862 - val_loss: 0.5584 - val_categorical_accuracy: 0.8000\n",
      "\n",
      "Epoch 00035: saving model to model_init_2019-12-2218_27_33.746320/model-00035-0.08364-0.98616-0.55844-0.80000.h5\n",
      "Epoch 36/50\n",
      "17/17 [==============================] - 16s 941ms/step - loss: 0.0759 - categorical_accuracy: 0.9862 - val_loss: 0.7173 - val_categorical_accuracy: 0.7333\n",
      "\n",
      "Epoch 00036: saving model to model_init_2019-12-2218_27_33.746320/model-00036-0.07589-0.98616-0.71733-0.73333.h5\n",
      "\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "Epoch 37/50\n",
      "17/17 [==============================] - 16s 957ms/step - loss: 0.0742 - categorical_accuracy: 0.9827 - val_loss: 0.5421 - val_categorical_accuracy: 0.8167\n",
      "\n",
      "Epoch 00037: saving model to model_init_2019-12-2218_27_33.746320/model-00037-0.07417-0.98270-0.54215-0.81667.h5\n",
      "Epoch 38/50\n",
      "17/17 [==============================] - 16s 951ms/step - loss: 0.0759 - categorical_accuracy: 0.9896 - val_loss: 0.7656 - val_categorical_accuracy: 0.7000\n",
      "\n",
      "Epoch 00038: saving model to model_init_2019-12-2218_27_33.746320/model-00038-0.07587-0.98962-0.76561-0.70000.h5\n",
      "\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "Epoch 39/50\n",
      "17/17 [==============================] - 16s 939ms/step - loss: 0.1007 - categorical_accuracy: 0.9654 - val_loss: 0.7920 - val_categorical_accuracy: 0.7000\n",
      "\n",
      "Epoch 00039: saving model to model_init_2019-12-2218_27_33.746320/model-00039-0.10071-0.96540-0.79199-0.70000.h5\n",
      "Epoch 40/50\n",
      "17/17 [==============================] - 15s 904ms/step - loss: 0.0720 - categorical_accuracy: 0.9827 - val_loss: 0.7028 - val_categorical_accuracy: 0.7667\n",
      "\n",
      "Epoch 00040: saving model to model_init_2019-12-2218_27_33.746320/model-00040-0.07201-0.98270-0.70283-0.76667.h5\n",
      "\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "Epoch 41/50\n",
      "17/17 [==============================] - 17s 986ms/step - loss: 0.0859 - categorical_accuracy: 0.9792 - val_loss: 0.5865 - val_categorical_accuracy: 0.7667\n",
      "\n",
      "Epoch 00041: saving model to model_init_2019-12-2218_27_33.746320/model-00041-0.08593-0.97924-0.58646-0.76667.h5\n",
      "Epoch 42/50\n",
      "17/17 [==============================] - 16s 930ms/step - loss: 0.0930 - categorical_accuracy: 0.9723 - val_loss: 0.6873 - val_categorical_accuracy: 0.7333\n",
      "\n",
      "Epoch 00042: saving model to model_init_2019-12-2218_27_33.746320/model-00042-0.09305-0.97232-0.68728-0.73333.h5\n",
      "\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "Epoch 43/50\n",
      "17/17 [==============================] - 15s 909ms/step - loss: 0.0624 - categorical_accuracy: 0.9862 - val_loss: 0.6888 - val_categorical_accuracy: 0.7500\n",
      "\n",
      "Epoch 00043: saving model to model_init_2019-12-2218_27_33.746320/model-00043-0.06243-0.98616-0.68883-0.75000.h5\n",
      "Epoch 44/50\n",
      "17/17 [==============================] - 16s 962ms/step - loss: 0.0805 - categorical_accuracy: 0.9862 - val_loss: 0.6491 - val_categorical_accuracy: 0.7500\n",
      "\n",
      "Epoch 00044: saving model to model_init_2019-12-2218_27_33.746320/model-00044-0.08055-0.98616-0.64911-0.75000.h5\n",
      "\n",
      "Epoch 00044: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "Epoch 45/50\n",
      "17/17 [==============================] - 16s 950ms/step - loss: 0.0663 - categorical_accuracy: 0.9862 - val_loss: 0.7474 - val_categorical_accuracy: 0.7833\n",
      "\n",
      "Epoch 00045: saving model to model_init_2019-12-2218_27_33.746320/model-00045-0.06633-0.98616-0.74739-0.78333.h5\n",
      "Epoch 46/50\n",
      "17/17 [==============================] - 16s 948ms/step - loss: 0.0999 - categorical_accuracy: 0.9827 - val_loss: 0.6266 - val_categorical_accuracy: 0.7333\n",
      "\n",
      "Epoch 00046: saving model to model_init_2019-12-2218_27_33.746320/model-00046-0.09985-0.98270-0.62665-0.73333.h5\n",
      "\n",
      "Epoch 00046: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "Epoch 47/50\n",
      "17/17 [==============================] - 16s 942ms/step - loss: 0.0975 - categorical_accuracy: 0.9689 - val_loss: 0.7311 - val_categorical_accuracy: 0.7167\n",
      "\n",
      "Epoch 00047: saving model to model_init_2019-12-2218_27_33.746320/model-00047-0.09750-0.96886-0.73114-0.71667.h5\n",
      "Epoch 48/50\n",
      "17/17 [==============================] - 16s 933ms/step - loss: 0.0649 - categorical_accuracy: 0.9862 - val_loss: 0.5576 - val_categorical_accuracy: 0.8000\n",
      "\n",
      "Epoch 00048: saving model to model_init_2019-12-2218_27_33.746320/model-00048-0.06494-0.98616-0.55756-0.80000.h5\n",
      "\n",
      "Epoch 00048: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "Epoch 49/50\n",
      "17/17 [==============================] - 16s 935ms/step - loss: 0.0687 - categorical_accuracy: 0.9723 - val_loss: 0.6916 - val_categorical_accuracy: 0.7500\n",
      "\n",
      "Epoch 00049: saving model to model_init_2019-12-2218_27_33.746320/model-00049-0.06871-0.97232-0.69161-0.75000.h5\n",
      "Epoch 50/50\n",
      "17/17 [==============================] - 16s 949ms/step - loss: 0.0763 - categorical_accuracy: 0.9862 - val_loss: 0.7409 - val_categorical_accuracy: 0.7333\n",
      "\n",
      "Epoch 00050: saving model to model_init_2019-12-2218_27_33.746320/model-00050-0.07628-0.98616-0.74086-0.73333.h5\n",
      "\n",
      "Epoch 00050: ReduceLROnPlateau reducing learning rate to 1.525878978725359e-08.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f47e01be6d8>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model5.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "#                     callbacks=callbacks_list, validation_data=val_generator, \n",
    "#                     validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Epoch 23/50\n",
    "17/17 [==============================] - 16s 918ms/step - loss: 0.1172 - categorical_accuracy: 0.9619 - val_loss: 0.4453 - val_categorical_accuracy: 0.8500\n",
    "\n",
    "Epoch 00023: saving model to model_init_2019-12-2218_27_33.746320/model-00023-0.11722-0.96194-0.44531-0.85000.h5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 6: Use dropouts after conv and FC layers, use BN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def get_conv3d_model_d():\n",
    "\n",
    "# # Define model\n",
    "#     model = Sequential()\n",
    "\n",
    "#     model.add(Conv3D(16, kernel_size=(3,3,3), input_shape=input_shape,padding='same'))\n",
    "#     model.add(Activation('relu'))\n",
    "#     model.add(BatchNormalization())\n",
    "#     model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "#     model.add(Dropout(0.25))\n",
    "\n",
    "#     model.add(Conv3D(32, kernel_size=(3,3,3), padding='same'))\n",
    "#     model.add(Activation('relu'))\n",
    "#     model.add(BatchNormalization())\n",
    "#     model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "#     model.add(Dropout(0.25))\n",
    "   \n",
    "\n",
    "#     model.add(Conv3D(64, kernel_size=(3,3,3), padding='same'))\n",
    "#     model.add(Activation('relu'))\n",
    "#     model.add(BatchNormalization())\n",
    "#     model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "#     model.add(Dropout(0.25))\n",
    "   \n",
    "\n",
    "#     #Flatten Layers\n",
    "#     model.add(Flatten())\n",
    "#     model.add(Dense(256, activation='relu'))\n",
    "#     model.add(Dropout(0.25))\n",
    "\n",
    "#     #softmax layer\n",
    "#     model.add(Dense(5, activation='softmax'))\n",
    "\n",
    "\n",
    "#     optimiser = optimizers.Adam(lr=0.001)\n",
    "#     model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "#     print (model.summary())\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_size= 40 ,num_frames= 16 ,num_rows= 60 ,num_cols= 60 ,num_epochs= 50\n"
     ]
    }
   ],
   "source": [
    "# # Set Hyperparameters for the model\n",
    "# set_hyper_parameters(batchSize=40, numFrames=16, numRows=60, numCols=60, numEpochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steps_per_epoch= 17 validation_steps= 3\n"
     ]
    }
   ],
   "source": [
    "# set_train_validation_steps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_13 (Conv3D)           (None, 16, 60, 60, 16)    1312      \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 16, 60, 60, 16)    0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 16, 60, 60, 16)    64        \n",
      "_________________________________________________________________\n",
      "max_pooling3d_13 (MaxPooling (None, 8, 30, 30, 16)     0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 8, 30, 30, 16)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_14 (Conv3D)           (None, 8, 30, 30, 32)     13856     \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 8, 30, 30, 32)     0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 8, 30, 30, 32)     128       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_14 (MaxPooling (None, 4, 15, 15, 32)     0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 4, 15, 15, 32)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_15 (Conv3D)           (None, 4, 15, 15, 64)     55360     \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 4, 15, 15, 64)     0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 4, 15, 15, 64)     256       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_15 (MaxPooling (None, 2, 7, 7, 64)       0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 2, 7, 7, 64)       0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 256)               1605888   \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 5)                 1285      \n",
      "=================================================================\n",
      "Total params: 1,678,149\n",
      "Trainable params: 1,677,925\n",
      "Non-trainable params: 224\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# ## Calling the model function\n",
    "# model6 = get_conv3d_model_d()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # create generators: Let us create the `train_generator` and the `val_generator` which will be used in `.fit_generator`.\n",
    "# train_generator = generator(train_path, train_doc, batch_size)\n",
    "# val_generator = generator(val_path, val_doc, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source path =  Project_data/val ; batch size = 40\n",
      "Source path =  Project_data/train ; batch size = 40\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:13: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "  del sys.path[0]\n",
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:21: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2/17 [==>...........................] - ETA: 41s - loss: 5.3121 - categorical_accuracy: 0.1875 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:44: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:53: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 39s 2s/step - loss: 9.5619 - categorical_accuracy: 0.3107 - val_loss: 11.1289 - val_categorical_accuracy: 0.2800\n",
      "\n",
      "Epoch 00001: saving model to model_init_2019-12-2218_27_33.746320/model-00001-9.57279-0.30769-11.12894-0.28000.h5\n",
      "Epoch 2/50\n",
      "17/17 [==============================] - 20s 1s/step - loss: 10.1282 - categorical_accuracy: 0.3529 - val_loss: 10.2308 - val_categorical_accuracy: 0.3500\n",
      "\n",
      "Epoch 00002: saving model to model_init_2019-12-2218_27_33.746320/model-00002-10.12823-0.35294-10.23085-0.35000.h5\n",
      "Epoch 3/50\n",
      "17/17 [==============================] - 20s 1s/step - loss: 10.4342 - categorical_accuracy: 0.3345 - val_loss: 10.4223 - val_categorical_accuracy: 0.3500\n",
      "\n",
      "Epoch 00003: saving model to model_init_2019-12-2218_27_33.746320/model-00003-10.42121-0.33515-10.42233-0.35000.h5\n",
      "Epoch 4/50\n",
      "17/17 [==============================] - 18s 1s/step - loss: 9.9120 - categorical_accuracy: 0.3808 - val_loss: 10.8598 - val_categorical_accuracy: 0.3167\n",
      "\n",
      "Epoch 00004: saving model to model_init_2019-12-2218_27_33.746320/model-00004-9.91202-0.38080-10.85979-0.31667.h5\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 5/50\n",
      "17/17 [==============================] - 16s 938ms/step - loss: 9.7186 - categorical_accuracy: 0.3677 - val_loss: 9.1552 - val_categorical_accuracy: 0.4167\n",
      "\n",
      "Epoch 00005: saving model to model_init_2019-12-2218_27_33.746320/model-00005-9.73147-0.36741-9.15515-0.41667.h5\n",
      "Epoch 6/50\n",
      "17/17 [==============================] - 16s 941ms/step - loss: 9.4705 - categorical_accuracy: 0.3460 - val_loss: 9.6548 - val_categorical_accuracy: 0.3833\n",
      "\n",
      "Epoch 00006: saving model to model_init_2019-12-2218_27_33.746320/model-00006-9.47052-0.34602-9.65479-0.38333.h5\n",
      "Epoch 7/50\n",
      "17/17 [==============================] - 16s 954ms/step - loss: 7.0045 - categorical_accuracy: 0.4533 - val_loss: 6.1699 - val_categorical_accuracy: 0.4833\n",
      "\n",
      "Epoch 00007: saving model to model_init_2019-12-2218_27_33.746320/model-00007-7.00445-0.45329-6.16994-0.48333.h5\n",
      "Epoch 8/50\n",
      "17/17 [==============================] - 16s 947ms/step - loss: 5.9780 - categorical_accuracy: 0.4706 - val_loss: 9.2476 - val_categorical_accuracy: 0.3667\n",
      "\n",
      "Epoch 00008: saving model to model_init_2019-12-2218_27_33.746320/model-00008-5.97797-0.47059-9.24756-0.36667.h5\n",
      "Epoch 9/50\n",
      "17/17 [==============================] - 15s 895ms/step - loss: 5.3690 - categorical_accuracy: 0.4775 - val_loss: 10.4269 - val_categorical_accuracy: 0.3167\n",
      "\n",
      "Epoch 00009: saving model to model_init_2019-12-2218_27_33.746320/model-00009-5.36898-0.47751-10.42689-0.31667.h5\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 10/50\n",
      "17/17 [==============================] - 17s 976ms/step - loss: 3.0055 - categorical_accuracy: 0.5571 - val_loss: 10.7639 - val_categorical_accuracy: 0.2167\n",
      "\n",
      "Epoch 00010: saving model to model_init_2019-12-2218_27_33.746320/model-00010-3.00547-0.55709-10.76391-0.21667.h5\n",
      "Epoch 11/50\n",
      "17/17 [==============================] - 16s 951ms/step - loss: 2.1357 - categorical_accuracy: 0.5848 - val_loss: 9.4448 - val_categorical_accuracy: 0.2833\n",
      "\n",
      "Epoch 00011: saving model to model_init_2019-12-2218_27_33.746320/model-00011-2.13570-0.58478-9.44485-0.28333.h5\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 12/50\n",
      "17/17 [==============================] - 15s 890ms/step - loss: 1.7886 - categorical_accuracy: 0.5986 - val_loss: 9.3559 - val_categorical_accuracy: 0.1833\n",
      "\n",
      "Epoch 00012: saving model to model_init_2019-12-2218_27_33.746320/model-00012-1.78862-0.59862-9.35588-0.18333.h5\n",
      "Epoch 13/50\n",
      "17/17 [==============================] - 16s 954ms/step - loss: 1.1227 - categorical_accuracy: 0.6401 - val_loss: 7.8434 - val_categorical_accuracy: 0.3167\n",
      "\n",
      "Epoch 00013: saving model to model_init_2019-12-2218_27_33.746320/model-00013-1.12271-0.64014-7.84336-0.31667.h5\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 14/50\n",
      "17/17 [==============================] - 16s 941ms/step - loss: 1.2150 - categorical_accuracy: 0.6228 - val_loss: 6.9849 - val_categorical_accuracy: 0.2833\n",
      "\n",
      "Epoch 00014: saving model to model_init_2019-12-2218_27_33.746320/model-00014-1.21498-0.62284-6.98488-0.28333.h5\n",
      "Epoch 15/50\n",
      "17/17 [==============================] - 16s 943ms/step - loss: 0.9369 - categorical_accuracy: 0.6678 - val_loss: 6.6506 - val_categorical_accuracy: 0.3333\n",
      "\n",
      "Epoch 00015: saving model to model_init_2019-12-2218_27_33.746320/model-00015-0.93686-0.66782-6.65060-0.33333.h5\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 16/50\n",
      "17/17 [==============================] - 15s 909ms/step - loss: 0.9175 - categorical_accuracy: 0.6678 - val_loss: 5.5870 - val_categorical_accuracy: 0.3000\n",
      "\n",
      "Epoch 00016: saving model to model_init_2019-12-2218_27_33.746320/model-00016-0.91755-0.66782-5.58700-0.30000.h5\n",
      "Epoch 17/50\n",
      "17/17 [==============================] - 16s 922ms/step - loss: 1.0630 - categorical_accuracy: 0.6332 - val_loss: 4.2275 - val_categorical_accuracy: 0.3833\n",
      "\n",
      "Epoch 00017: saving model to model_init_2019-12-2218_27_33.746320/model-00017-1.06296-0.63322-4.22750-0.38333.h5\n",
      "Epoch 18/50\n",
      "17/17 [==============================] - 16s 912ms/step - loss: 1.0121 - categorical_accuracy: 0.6990 - val_loss: 4.9325 - val_categorical_accuracy: 0.3500\n",
      "\n",
      "Epoch 00018: saving model to model_init_2019-12-2218_27_33.746320/model-00018-1.01211-0.69896-4.93253-0.35000.h5\n",
      "Epoch 19/50\n",
      "17/17 [==============================] - 16s 942ms/step - loss: 0.8951 - categorical_accuracy: 0.6886 - val_loss: 3.4906 - val_categorical_accuracy: 0.4333\n",
      "\n",
      "Epoch 00019: saving model to model_init_2019-12-2218_27_33.746320/model-00019-0.89509-0.68858-3.49055-0.43333.h5\n",
      "Epoch 20/50\n",
      "17/17 [==============================] - 15s 878ms/step - loss: 0.9833 - categorical_accuracy: 0.6782 - val_loss: 3.5778 - val_categorical_accuracy: 0.3667\n",
      "\n",
      "Epoch 00020: saving model to model_init_2019-12-2218_27_33.746320/model-00020-0.98333-0.67820-3.57776-0.36667.h5\n",
      "Epoch 21/50\n",
      "17/17 [==============================] - 17s 1000ms/step - loss: 0.8554 - categorical_accuracy: 0.6817 - val_loss: 3.0973 - val_categorical_accuracy: 0.4667\n",
      "\n",
      "Epoch 00021: saving model to model_init_2019-12-2218_27_33.746320/model-00021-0.85540-0.68166-3.09726-0.46667.h5\n",
      "Epoch 22/50\n",
      "17/17 [==============================] - 16s 927ms/step - loss: 0.7867 - categorical_accuracy: 0.6920 - val_loss: 3.3726 - val_categorical_accuracy: 0.4167\n",
      "\n",
      "Epoch 00022: saving model to model_init_2019-12-2218_27_33.746320/model-00022-0.78672-0.69204-3.37261-0.41667.h5\n",
      "Epoch 23/50\n",
      "17/17 [==============================] - 16s 932ms/step - loss: 0.9172 - categorical_accuracy: 0.6920 - val_loss: 1.8662 - val_categorical_accuracy: 0.5500\n",
      "\n",
      "Epoch 00023: saving model to model_init_2019-12-2218_27_33.746320/model-00023-0.91722-0.69204-1.86618-0.55000.h5\n",
      "Epoch 24/50\n",
      "17/17 [==============================] - 15s 892ms/step - loss: 0.7832 - categorical_accuracy: 0.7093 - val_loss: 1.8139 - val_categorical_accuracy: 0.6333\n",
      "\n",
      "Epoch 00024: saving model to model_init_2019-12-2218_27_33.746320/model-00024-0.78316-0.70934-1.81392-0.63333.h5\n",
      "Epoch 25/50\n",
      "17/17 [==============================] - 16s 939ms/step - loss: 0.7642 - categorical_accuracy: 0.7232 - val_loss: 2.4542 - val_categorical_accuracy: 0.5333\n",
      "\n",
      "Epoch 00025: saving model to model_init_2019-12-2218_27_33.746320/model-00025-0.76420-0.72318-2.45417-0.53333.h5\n",
      "Epoch 26/50\n",
      "17/17 [==============================] - 16s 935ms/step - loss: 0.8790 - categorical_accuracy: 0.6920 - val_loss: 2.0537 - val_categorical_accuracy: 0.6000\n",
      "\n",
      "Epoch 00026: saving model to model_init_2019-12-2218_27_33.746320/model-00026-0.87897-0.69204-2.05367-0.60000.h5\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 27/50\n",
      "17/17 [==============================] - 16s 933ms/step - loss: 0.8345 - categorical_accuracy: 0.6817 - val_loss: 2.0893 - val_categorical_accuracy: 0.4833\n",
      "\n",
      "Epoch 00027: saving model to model_init_2019-12-2218_27_33.746320/model-00027-0.83447-0.68166-2.08930-0.48333.h5\n",
      "Epoch 28/50\n",
      "17/17 [==============================] - 16s 963ms/step - loss: 0.8228 - categorical_accuracy: 0.7197 - val_loss: 1.8314 - val_categorical_accuracy: 0.6833\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00028: saving model to model_init_2019-12-2218_27_33.746320/model-00028-0.82279-0.71972-1.83140-0.68333.h5\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "Epoch 29/50\n",
      "17/17 [==============================] - 16s 955ms/step - loss: 0.7817 - categorical_accuracy: 0.7370 - val_loss: 1.6874 - val_categorical_accuracy: 0.5500\n",
      "\n",
      "Epoch 00029: saving model to model_init_2019-12-2218_27_33.746320/model-00029-0.78171-0.73702-1.68741-0.55000.h5\n",
      "Epoch 30/50\n",
      "17/17 [==============================] - 15s 884ms/step - loss: 0.8143 - categorical_accuracy: 0.7024 - val_loss: 1.5288 - val_categorical_accuracy: 0.6500\n",
      "\n",
      "Epoch 00030: saving model to model_init_2019-12-2218_27_33.746320/model-00030-0.81428-0.70242-1.52884-0.65000.h5\n",
      "Epoch 31/50\n",
      "17/17 [==============================] - 16s 921ms/step - loss: 0.7328 - categorical_accuracy: 0.7578 - val_loss: 1.7412 - val_categorical_accuracy: 0.5333\n",
      "\n",
      "Epoch 00031: saving model to model_init_2019-12-2218_27_33.746320/model-00031-0.73283-0.75779-1.74116-0.53333.h5\n",
      "Epoch 32/50\n",
      "17/17 [==============================] - 16s 929ms/step - loss: 0.8117 - categorical_accuracy: 0.6920 - val_loss: 1.4925 - val_categorical_accuracy: 0.6500\n",
      "\n",
      "Epoch 00032: saving model to model_init_2019-12-2218_27_33.746320/model-00032-0.81165-0.69204-1.49253-0.65000.h5\n",
      "Epoch 33/50\n",
      "17/17 [==============================] - 16s 930ms/step - loss: 0.9389 - categorical_accuracy: 0.7128 - val_loss: 1.9415 - val_categorical_accuracy: 0.4833\n",
      "\n",
      "Epoch 00033: saving model to model_init_2019-12-2218_27_33.746320/model-00033-0.93890-0.71280-1.94148-0.48333.h5\n",
      "Epoch 34/50\n",
      "17/17 [==============================] - 16s 965ms/step - loss: 0.6542 - categorical_accuracy: 0.7682 - val_loss: 1.4650 - val_categorical_accuracy: 0.6000\n",
      "\n",
      "Epoch 00034: saving model to model_init_2019-12-2218_27_33.746320/model-00034-0.65421-0.76817-1.46503-0.60000.h5\n",
      "Epoch 35/50\n",
      "17/17 [==============================] - 15s 910ms/step - loss: 0.8132 - categorical_accuracy: 0.7024 - val_loss: 1.5568 - val_categorical_accuracy: 0.5667\n",
      "\n",
      "Epoch 00035: saving model to model_init_2019-12-2218_27_33.746320/model-00035-0.81324-0.70242-1.55681-0.56667.h5\n",
      "Epoch 36/50\n",
      "17/17 [==============================] - 16s 945ms/step - loss: 0.7690 - categorical_accuracy: 0.6851 - val_loss: 1.6145 - val_categorical_accuracy: 0.6333\n",
      "\n",
      "Epoch 00036: saving model to model_init_2019-12-2218_27_33.746320/model-00036-0.76896-0.68512-1.61453-0.63333.h5\n",
      "\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "Epoch 37/50\n",
      "17/17 [==============================] - 16s 918ms/step - loss: 0.8466 - categorical_accuracy: 0.6955 - val_loss: 1.8674 - val_categorical_accuracy: 0.5667\n",
      "\n",
      "Epoch 00037: saving model to model_init_2019-12-2218_27_33.746320/model-00037-0.84657-0.69550-1.86739-0.56667.h5\n",
      "Epoch 38/50\n",
      "17/17 [==============================] - 16s 937ms/step - loss: 0.8601 - categorical_accuracy: 0.7197 - val_loss: 1.5111 - val_categorical_accuracy: 0.5333\n",
      "\n",
      "Epoch 00038: saving model to model_init_2019-12-2218_27_33.746320/model-00038-0.86006-0.71972-1.51113-0.53333.h5\n",
      "\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "Epoch 39/50\n",
      "17/17 [==============================] - 16s 921ms/step - loss: 0.8045 - categorical_accuracy: 0.7301 - val_loss: 1.5803 - val_categorical_accuracy: 0.6167\n",
      "\n",
      "Epoch 00039: saving model to model_init_2019-12-2218_27_33.746320/model-00039-0.80448-0.73010-1.58029-0.61667.h5\n",
      "Epoch 40/50\n",
      "17/17 [==============================] - 15s 904ms/step - loss: 0.7752 - categorical_accuracy: 0.7439 - val_loss: 1.1641 - val_categorical_accuracy: 0.6333\n",
      "\n",
      "Epoch 00040: saving model to model_init_2019-12-2218_27_33.746320/model-00040-0.77519-0.74394-1.16415-0.63333.h5\n",
      "Epoch 41/50\n",
      "17/17 [==============================] - 16s 943ms/step - loss: 0.7124 - categorical_accuracy: 0.7163 - val_loss: 1.6579 - val_categorical_accuracy: 0.5667\n",
      "\n",
      "Epoch 00041: saving model to model_init_2019-12-2218_27_33.746320/model-00041-0.71245-0.71626-1.65788-0.56667.h5\n",
      "Epoch 42/50\n",
      "17/17 [==============================] - 16s 940ms/step - loss: 0.7609 - categorical_accuracy: 0.7336 - val_loss: 1.8567 - val_categorical_accuracy: 0.5667\n",
      "\n",
      "Epoch 00042: saving model to model_init_2019-12-2218_27_33.746320/model-00042-0.76088-0.73356-1.85674-0.56667.h5\n",
      "\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "Epoch 43/50\n",
      "17/17 [==============================] - 15s 899ms/step - loss: 0.7592 - categorical_accuracy: 0.7059 - val_loss: 1.3546 - val_categorical_accuracy: 0.6333\n",
      "\n",
      "Epoch 00043: saving model to model_init_2019-12-2218_27_33.746320/model-00043-0.75922-0.70588-1.35457-0.63333.h5\n",
      "Epoch 44/50\n",
      "17/17 [==============================] - 16s 946ms/step - loss: 0.8153 - categorical_accuracy: 0.7093 - val_loss: 1.6534 - val_categorical_accuracy: 0.5500\n",
      "\n",
      "Epoch 00044: saving model to model_init_2019-12-2218_27_33.746320/model-00044-0.81535-0.70934-1.65336-0.55000.h5\n",
      "\n",
      "Epoch 00044: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "Epoch 45/50\n",
      "17/17 [==============================] - 16s 941ms/step - loss: 0.6920 - categorical_accuracy: 0.7266 - val_loss: 1.8648 - val_categorical_accuracy: 0.5833\n",
      "\n",
      "Epoch 00045: saving model to model_init_2019-12-2218_27_33.746320/model-00045-0.69198-0.72664-1.86476-0.58333.h5\n",
      "Epoch 46/50\n",
      "17/17 [==============================] - 16s 965ms/step - loss: 0.7675 - categorical_accuracy: 0.7370 - val_loss: 0.9613 - val_categorical_accuracy: 0.6667\n",
      "\n",
      "Epoch 00046: saving model to model_init_2019-12-2218_27_33.746320/model-00046-0.76755-0.73702-0.96125-0.66667.h5\n",
      "Epoch 47/50\n",
      "17/17 [==============================] - 16s 944ms/step - loss: 0.7870 - categorical_accuracy: 0.7197 - val_loss: 1.7322 - val_categorical_accuracy: 0.5667\n",
      "\n",
      "Epoch 00047: saving model to model_init_2019-12-2218_27_33.746320/model-00047-0.78697-0.71972-1.73217-0.56667.h5\n",
      "Epoch 48/50\n",
      "17/17 [==============================] - 15s 895ms/step - loss: 0.6700 - categorical_accuracy: 0.7578 - val_loss: 1.1610 - val_categorical_accuracy: 0.6667\n",
      "\n",
      "Epoch 00048: saving model to model_init_2019-12-2218_27_33.746320/model-00048-0.66999-0.75779-1.16098-0.66667.h5\n",
      "\n",
      "Epoch 00048: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "Epoch 49/50\n",
      "17/17 [==============================] - 16s 948ms/step - loss: 0.6912 - categorical_accuracy: 0.7370 - val_loss: 1.6837 - val_categorical_accuracy: 0.6167\n",
      "\n",
      "Epoch 00049: saving model to model_init_2019-12-2218_27_33.746320/model-00049-0.69124-0.73702-1.68371-0.61667.h5\n",
      "Epoch 50/50\n",
      "17/17 [==============================] - 15s 907ms/step - loss: 0.8236 - categorical_accuracy: 0.6920 - val_loss: 1.1565 - val_categorical_accuracy: 0.6667\n",
      "\n",
      "Epoch 00050: saving model to model_init_2019-12-2218_27_33.746320/model-00050-0.82363-0.69204-1.15647-0.66667.h5\n",
      "\n",
      "Epoch 00050: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f47ea27cb38>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model6.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "#                     callbacks=callbacks_list, validation_data=val_generator, \n",
    "#                     validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 7: Add a new convolutional layer to the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def get_conv3d_model_e():\n",
    "\n",
    "# # Define model\n",
    "#     model = Sequential()\n",
    "\n",
    "#     model.add(Conv3D(16, kernel_size=(3,3,3), input_shape=input_shape,padding='same'))\n",
    "#     model.add(Activation('relu'))\n",
    "#     model.add(BatchNormalization())\n",
    "#     model.add(Conv3D(16, kernel_size=(3,3,3)))\n",
    "#     model.add(Activation('relu'))\n",
    "#     model.add(BatchNormalization())\n",
    "#     model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "#     model.add(Dropout(0.25))\n",
    "\n",
    "#     model.add(Conv3D(32, kernel_size=(3,3,3), padding='same'))\n",
    "#     model.add(Activation('relu'))\n",
    "#     model.add(BatchNormalization())\n",
    "#     model.add(Conv3D(32, kernel_size=(3,3,3), padding='same'))\n",
    "#     model.add(Activation('relu'))\n",
    "#     model.add(BatchNormalization())\n",
    "#     model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "#     model.add(Dropout(0.25))\n",
    "   \n",
    "\n",
    "#     model.add(Conv3D(64, kernel_size=(3,3,3), padding='same'))\n",
    "#     model.add(Activation('relu'))\n",
    "#     model.add(BatchNormalization())\n",
    "#     model.add(Conv3D(64, kernel_size=(3,3,3), padding='same'))\n",
    "#     model.add(Activation('relu'))\n",
    "#     model.add(BatchNormalization())\n",
    "#     model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "#     model.add(Dropout(0.25))\n",
    "   \n",
    "\n",
    "#     #Flatten Layers\n",
    "#     model.add(Flatten())\n",
    "#     model.add(Dense(256, activation='relu'))\n",
    "#     model.add(Dropout(0.25))\n",
    "\n",
    "#     #softmax layer\n",
    "#     model.add(Dense(5, activation='softmax'))\n",
    "\n",
    "\n",
    "#     optimiser = optimizers.Adam(lr=0.001)\n",
    "#     model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "#     print (model.summary())\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_size= 40 ,num_frames= 16 ,num_rows= 60 ,num_cols= 60 ,num_epochs= 50\n"
     ]
    }
   ],
   "source": [
    "# # Set Hyperparameters for the model\n",
    "# set_hyper_parameters(batchSize=40, numFrames=16, numRows=60, numCols=60, numEpochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steps_per_epoch= 17 validation_steps= 3\n"
     ]
    }
   ],
   "source": [
    "# set_train_validation_steps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_16 (Conv3D)           (None, 16, 60, 60, 16)    1312      \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 16, 60, 60, 16)    0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 16, 60, 60, 16)    64        \n",
      "_________________________________________________________________\n",
      "conv3d_17 (Conv3D)           (None, 14, 58, 58, 16)    6928      \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 14, 58, 58, 16)    0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 14, 58, 58, 16)    64        \n",
      "_________________________________________________________________\n",
      "max_pooling3d_16 (MaxPooling (None, 7, 29, 29, 16)     0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 7, 29, 29, 16)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_18 (Conv3D)           (None, 7, 29, 29, 32)     13856     \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 7, 29, 29, 32)     0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 7, 29, 29, 32)     128       \n",
      "_________________________________________________________________\n",
      "conv3d_19 (Conv3D)           (None, 7, 29, 29, 32)     27680     \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 7, 29, 29, 32)     0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 7, 29, 29, 32)     128       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_17 (MaxPooling (None, 3, 14, 14, 32)     0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 3, 14, 14, 32)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_20 (Conv3D)           (None, 3, 14, 14, 64)     55360     \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 3, 14, 14, 64)     0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 3, 14, 14, 64)     256       \n",
      "_________________________________________________________________\n",
      "conv3d_21 (Conv3D)           (None, 3, 14, 14, 64)     110656    \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 3, 14, 14, 64)     0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 3, 14, 14, 64)     256       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_18 (MaxPooling (None, 1, 7, 7, 64)       0         \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 1, 7, 7, 64)       0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 256)               803072    \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 5)                 1285      \n",
      "=================================================================\n",
      "Total params: 1,021,045\n",
      "Trainable params: 1,020,597\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# ## Calling the model function\n",
    "# model7 = get_conv3d_model_e()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # create generators: Let us create the `train_generator` and the `val_generator` which will be used in `.fit_generator`.\n",
    "# train_generator = generator(train_path, train_doc, batch_size)\n",
    "# val_generator = generator(val_path, val_doc, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:13: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "  del sys.path[0]\n",
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:21: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 19s 1s/step - loss: 0.6152 - categorical_accuracy: 0.7578 - val_loss: 0.8330 - val_categorical_accuracy: 0.6500\n",
      "\n",
      "Epoch 00001: saving model to model_init_2019-12-2218_27_33.746320/model-00001-0.61520-0.75779-0.83304-0.65000.h5\n",
      "Epoch 2/50\n",
      "17/17 [==============================] - 17s 981ms/step - loss: 0.5237 - categorical_accuracy: 0.7993 - val_loss: 0.9896 - val_categorical_accuracy: 0.6667\n",
      "\n",
      "Epoch 00002: saving model to model_init_2019-12-2218_27_33.746320/model-00002-0.52370-0.79931-0.98963-0.66667.h5\n",
      "Epoch 3/50\n",
      "17/17 [==============================] - 16s 922ms/step - loss: 0.5137 - categorical_accuracy: 0.7958 - val_loss: 1.2281 - val_categorical_accuracy: 0.5167\n",
      "\n",
      "Epoch 00003: saving model to model_init_2019-12-2218_27_33.746320/model-00003-0.51375-0.79585-1.22810-0.51667.h5\n",
      "\n",
      "Epoch 00003: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 4/50\n",
      "17/17 [==============================] - 16s 962ms/step - loss: 0.4941 - categorical_accuracy: 0.7993 - val_loss: 2.2189 - val_categorical_accuracy: 0.4667\n",
      "\n",
      "Epoch 00004: saving model to model_init_2019-12-2218_27_33.746320/model-00004-0.49414-0.79931-2.21894-0.46667.h5\n",
      "Epoch 5/50\n",
      "17/17 [==============================] - 16s 919ms/step - loss: 0.4766 - categorical_accuracy: 0.7958 - val_loss: 1.2382 - val_categorical_accuracy: 0.6167\n",
      "\n",
      "Epoch 00005: saving model to model_init_2019-12-2218_27_33.746320/model-00005-0.47661-0.79585-1.23816-0.61667.h5\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 6/50\n",
      "17/17 [==============================] - 17s 995ms/step - loss: 0.4219 - categorical_accuracy: 0.8443 - val_loss: 1.6837 - val_categorical_accuracy: 0.5667\n",
      "\n",
      "Epoch 00006: saving model to model_init_2019-12-2218_27_33.746320/model-00006-0.42191-0.84429-1.68370-0.56667.h5\n",
      "Epoch 7/50\n",
      "17/17 [==============================] - 16s 962ms/step - loss: 0.3364 - categorical_accuracy: 0.8997 - val_loss: 1.6479 - val_categorical_accuracy: 0.5667\n",
      "\n",
      "Epoch 00007: saving model to model_init_2019-12-2218_27_33.746320/model-00007-0.33636-0.89965-1.64793-0.56667.h5\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 8/50\n",
      "17/17 [==============================] - 16s 953ms/step - loss: 0.3366 - categorical_accuracy: 0.8685 - val_loss: 1.3540 - val_categorical_accuracy: 0.6167\n",
      "\n",
      "Epoch 00008: saving model to model_init_2019-12-2218_27_33.746320/model-00008-0.33658-0.86851-1.35404-0.61667.h5\n",
      "Epoch 9/50\n",
      "17/17 [==============================] - 16s 942ms/step - loss: 0.3346 - categorical_accuracy: 0.8962 - val_loss: 1.2599 - val_categorical_accuracy: 0.5833\n",
      "\n",
      "Epoch 00009: saving model to model_init_2019-12-2218_27_33.746320/model-00009-0.33460-0.89619-1.25992-0.58333.h5\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 10/50\n",
      "17/17 [==============================] - 16s 937ms/step - loss: 0.3243 - categorical_accuracy: 0.8789 - val_loss: 1.2819 - val_categorical_accuracy: 0.7167\n",
      "\n",
      "Epoch 00010: saving model to model_init_2019-12-2218_27_33.746320/model-00010-0.32431-0.87889-1.28195-0.71667.h5\n",
      "Epoch 11/50\n",
      "17/17 [==============================] - 17s 987ms/step - loss: 0.2941 - categorical_accuracy: 0.8927 - val_loss: 1.2326 - val_categorical_accuracy: 0.5500\n",
      "\n",
      "Epoch 00011: saving model to model_init_2019-12-2218_27_33.746320/model-00011-0.29413-0.89273-1.23262-0.55000.h5\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 12/50\n",
      "17/17 [==============================] - 16s 949ms/step - loss: 0.3008 - categorical_accuracy: 0.8824 - val_loss: 0.7858 - val_categorical_accuracy: 0.7000\n",
      "\n",
      "Epoch 00012: saving model to model_init_2019-12-2218_27_33.746320/model-00012-0.30081-0.88235-0.78576-0.70000.h5\n",
      "Epoch 13/50\n",
      "17/17 [==============================] - 16s 931ms/step - loss: 0.3002 - categorical_accuracy: 0.8893 - val_loss: 1.7326 - val_categorical_accuracy: 0.5167\n",
      "\n",
      "Epoch 00013: saving model to model_init_2019-12-2218_27_33.746320/model-00013-0.30015-0.88927-1.73259-0.51667.h5\n",
      "Epoch 14/50\n",
      "17/17 [==============================] - 16s 936ms/step - loss: 0.2707 - categorical_accuracy: 0.9066 - val_loss: 1.0965 - val_categorical_accuracy: 0.6167\n",
      "\n",
      "Epoch 00014: saving model to model_init_2019-12-2218_27_33.746320/model-00014-0.27067-0.90657-1.09653-0.61667.h5\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "Epoch 15/50\n",
      "17/17 [==============================] - 17s 979ms/step - loss: 0.2883 - categorical_accuracy: 0.8927 - val_loss: 0.9970 - val_categorical_accuracy: 0.6833\n",
      "\n",
      "Epoch 00015: saving model to model_init_2019-12-2218_27_33.746320/model-00015-0.28828-0.89273-0.99702-0.68333.h5\n",
      "Epoch 16/50\n",
      "17/17 [==============================] - 16s 917ms/step - loss: 0.2980 - categorical_accuracy: 0.8789 - val_loss: 1.0111 - val_categorical_accuracy: 0.6833\n",
      "\n",
      "Epoch 00016: saving model to model_init_2019-12-2218_27_33.746320/model-00016-0.29804-0.87889-1.01105-0.68333.h5\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "Epoch 17/50\n",
      "17/17 [==============================] - 16s 955ms/step - loss: 0.2734 - categorical_accuracy: 0.9100 - val_loss: 1.3763 - val_categorical_accuracy: 0.6000\n",
      "\n",
      "Epoch 00017: saving model to model_init_2019-12-2218_27_33.746320/model-00017-0.27344-0.91003-1.37626-0.60000.h5\n",
      "Epoch 18/50\n",
      "17/17 [==============================] - 16s 937ms/step - loss: 0.2684 - categorical_accuracy: 0.8962 - val_loss: 0.6574 - val_categorical_accuracy: 0.7167\n",
      "\n",
      "Epoch 00018: saving model to model_init_2019-12-2218_27_33.746320/model-00018-0.26838-0.89619-0.65738-0.71667.h5\n",
      "Epoch 19/50\n",
      "17/17 [==============================] - 16s 932ms/step - loss: 0.2952 - categorical_accuracy: 0.8858 - val_loss: 1.1138 - val_categorical_accuracy: 0.7000\n",
      "\n",
      "Epoch 00019: saving model to model_init_2019-12-2218_27_33.746320/model-00019-0.29520-0.88581-1.11381-0.70000.h5\n",
      "Epoch 20/50\n",
      "17/17 [==============================] - 17s 973ms/step - loss: 0.2901 - categorical_accuracy: 0.9031 - val_loss: 0.9201 - val_categorical_accuracy: 0.6500\n",
      "\n",
      "Epoch 00020: saving model to model_init_2019-12-2218_27_33.746320/model-00020-0.29008-0.90311-0.92012-0.65000.h5\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "Epoch 21/50\n",
      "17/17 [==============================] - 15s 890ms/step - loss: 0.2717 - categorical_accuracy: 0.9100 - val_loss: 1.0472 - val_categorical_accuracy: 0.7333\n",
      "\n",
      "Epoch 00021: saving model to model_init_2019-12-2218_27_33.746320/model-00021-0.27166-0.91003-1.04718-0.73333.h5\n",
      "Epoch 22/50\n",
      "17/17 [==============================] - 17s 981ms/step - loss: 0.2637 - categorical_accuracy: 0.8927 - val_loss: 0.7964 - val_categorical_accuracy: 0.7500\n",
      "\n",
      "Epoch 00022: saving model to model_init_2019-12-2218_27_33.746320/model-00022-0.26373-0.89273-0.79635-0.75000.h5\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "Epoch 23/50\n",
      "17/17 [==============================] - 16s 960ms/step - loss: 0.3345 - categorical_accuracy: 0.8824 - val_loss: 1.2879 - val_categorical_accuracy: 0.6167\n",
      "\n",
      "Epoch 00023: saving model to model_init_2019-12-2218_27_33.746320/model-00023-0.33452-0.88235-1.28791-0.61667.h5\n",
      "Epoch 24/50\n",
      "17/17 [==============================] - 16s 941ms/step - loss: 0.2683 - categorical_accuracy: 0.9066 - val_loss: 0.9230 - val_categorical_accuracy: 0.6667\n",
      "\n",
      "Epoch 00024: saving model to model_init_2019-12-2218_27_33.746320/model-00024-0.26831-0.90657-0.92301-0.66667.h5\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "Epoch 25/50\n",
      "17/17 [==============================] - 16s 944ms/step - loss: 0.2657 - categorical_accuracy: 0.9204 - val_loss: 0.9903 - val_categorical_accuracy: 0.7333\n",
      "\n",
      "Epoch 00025: saving model to model_init_2019-12-2218_27_33.746320/model-00025-0.26566-0.92042-0.99028-0.73333.h5\n",
      "Epoch 26/50\n",
      "17/17 [==============================] - 16s 939ms/step - loss: 0.3604 - categorical_accuracy: 0.8720 - val_loss: 0.8271 - val_categorical_accuracy: 0.6833\n",
      "\n",
      "Epoch 00026: saving model to model_init_2019-12-2218_27_33.746320/model-00026-0.36035-0.87197-0.82711-0.68333.h5\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "Epoch 27/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 16s 964ms/step - loss: 0.2541 - categorical_accuracy: 0.9170 - val_loss: 1.1609 - val_categorical_accuracy: 0.6500\n",
      "\n",
      "Epoch 00027: saving model to model_init_2019-12-2218_27_33.746320/model-00027-0.25412-0.91696-1.16089-0.65000.h5\n",
      "Epoch 28/50\n",
      "17/17 [==============================] - 16s 965ms/step - loss: 0.2633 - categorical_accuracy: 0.9066 - val_loss: 0.7144 - val_categorical_accuracy: 0.7167\n",
      "\n",
      "Epoch 00028: saving model to model_init_2019-12-2218_27_33.746320/model-00028-0.26326-0.90657-0.71437-0.71667.h5\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "Epoch 29/50\n",
      "17/17 [==============================] - 17s 1000ms/step - loss: 0.3440 - categorical_accuracy: 0.8720 - val_loss: 0.9665 - val_categorical_accuracy: 0.7333\n",
      "\n",
      "Epoch 00029: saving model to model_init_2019-12-2218_27_33.746320/model-00029-0.34397-0.87197-0.96655-0.73333.h5\n",
      "Epoch 30/50\n",
      "17/17 [==============================] - 15s 888ms/step - loss: 0.2746 - categorical_accuracy: 0.8927 - val_loss: 1.0526 - val_categorical_accuracy: 0.6333\n",
      "\n",
      "Epoch 00030: saving model to model_init_2019-12-2218_27_33.746320/model-00030-0.27455-0.89273-1.05265-0.63333.h5\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "Epoch 31/50\n",
      "17/17 [==============================] - 16s 944ms/step - loss: 0.3339 - categorical_accuracy: 0.8720 - val_loss: 0.7943 - val_categorical_accuracy: 0.7667\n",
      "\n",
      "Epoch 00031: saving model to model_init_2019-12-2218_27_33.746320/model-00031-0.33387-0.87197-0.79427-0.76667.h5\n",
      "Epoch 32/50\n",
      "17/17 [==============================] - 16s 967ms/step - loss: 0.2882 - categorical_accuracy: 0.8962 - val_loss: 0.9423 - val_categorical_accuracy: 0.7500\n",
      "\n",
      "Epoch 00032: saving model to model_init_2019-12-2218_27_33.746320/model-00032-0.28816-0.89619-0.94232-0.75000.h5\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "Epoch 33/50\n",
      "17/17 [==============================] - 17s 978ms/step - loss: 0.2538 - categorical_accuracy: 0.9239 - val_loss: 0.9069 - val_categorical_accuracy: 0.7167\n",
      "\n",
      "Epoch 00033: saving model to model_init_2019-12-2218_27_33.746320/model-00033-0.25379-0.92388-0.90692-0.71667.h5\n",
      "Epoch 34/50\n",
      "17/17 [==============================] - 16s 928ms/step - loss: 0.3278 - categorical_accuracy: 0.8824 - val_loss: 1.0053 - val_categorical_accuracy: 0.6333\n",
      "\n",
      "Epoch 00034: saving model to model_init_2019-12-2218_27_33.746320/model-00034-0.32781-0.88235-1.00534-0.63333.h5\n",
      "\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 1.525878978725359e-08.\n",
      "Epoch 35/50\n",
      "17/17 [==============================] - 16s 924ms/step - loss: 0.3149 - categorical_accuracy: 0.8893 - val_loss: 1.0227 - val_categorical_accuracy: 0.6833\n",
      "\n",
      "Epoch 00035: saving model to model_init_2019-12-2218_27_33.746320/model-00035-0.31492-0.88927-1.02273-0.68333.h5\n",
      "Epoch 36/50\n",
      "17/17 [==============================] - 16s 961ms/step - loss: 0.2571 - categorical_accuracy: 0.9135 - val_loss: 0.7508 - val_categorical_accuracy: 0.7667\n",
      "\n",
      "Epoch 00036: saving model to model_init_2019-12-2218_27_33.746320/model-00036-0.25706-0.91349-0.75084-0.76667.h5\n",
      "\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 7.629394893626795e-09.\n",
      "Epoch 37/50\n",
      "17/17 [==============================] - 16s 944ms/step - loss: 0.3001 - categorical_accuracy: 0.8997 - val_loss: 1.0687 - val_categorical_accuracy: 0.6667\n",
      "\n",
      "Epoch 00037: saving model to model_init_2019-12-2218_27_33.746320/model-00037-0.30013-0.89965-1.06867-0.66667.h5\n",
      "Epoch 38/50\n",
      "17/17 [==============================] - 16s 936ms/step - loss: 0.2924 - categorical_accuracy: 0.9066 - val_loss: 0.6853 - val_categorical_accuracy: 0.7500\n",
      "\n",
      "Epoch 00038: saving model to model_init_2019-12-2218_27_33.746320/model-00038-0.29235-0.90657-0.68526-0.75000.h5\n",
      "\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 3.814697446813398e-09.\n",
      "Epoch 39/50\n",
      "17/17 [==============================] - 16s 946ms/step - loss: 0.3081 - categorical_accuracy: 0.8962 - val_loss: 1.0560 - val_categorical_accuracy: 0.7000\n",
      "\n",
      "Epoch 00039: saving model to model_init_2019-12-2218_27_33.746320/model-00039-0.30813-0.89619-1.05602-0.70000.h5\n",
      "Epoch 40/50\n",
      "17/17 [==============================] - 16s 952ms/step - loss: 0.3077 - categorical_accuracy: 0.8824 - val_loss: 0.8649 - val_categorical_accuracy: 0.7000\n",
      "\n",
      "Epoch 00040: saving model to model_init_2019-12-2218_27_33.746320/model-00040-0.30769-0.88235-0.86487-0.70000.h5\n",
      "\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 1.907348723406699e-09.\n",
      "Epoch 41/50\n",
      "17/17 [==============================] - 16s 943ms/step - loss: 0.3004 - categorical_accuracy: 0.8685 - val_loss: 0.9372 - val_categorical_accuracy: 0.7333\n",
      "\n",
      "Epoch 00041: saving model to model_init_2019-12-2218_27_33.746320/model-00041-0.30042-0.86851-0.93718-0.73333.h5\n",
      "Epoch 42/50\n",
      "17/17 [==============================] - 16s 915ms/step - loss: 0.3018 - categorical_accuracy: 0.8962 - val_loss: 0.9195 - val_categorical_accuracy: 0.7000\n",
      "\n",
      "Epoch 00042: saving model to model_init_2019-12-2218_27_33.746320/model-00042-0.30177-0.89619-0.91953-0.70000.h5\n",
      "\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 9.536743617033494e-10.\n",
      "Epoch 43/50\n",
      "17/17 [==============================] - 16s 950ms/step - loss: 0.2755 - categorical_accuracy: 0.9170 - val_loss: 0.8843 - val_categorical_accuracy: 0.7333\n",
      "\n",
      "Epoch 00043: saving model to model_init_2019-12-2218_27_33.746320/model-00043-0.27552-0.91696-0.88427-0.73333.h5\n",
      "Epoch 44/50\n",
      "17/17 [==============================] - 16s 963ms/step - loss: 0.2989 - categorical_accuracy: 0.8824 - val_loss: 0.8772 - val_categorical_accuracy: 0.7333\n",
      "\n",
      "Epoch 00044: saving model to model_init_2019-12-2218_27_33.746320/model-00044-0.29894-0.88235-0.87718-0.73333.h5\n",
      "\n",
      "Epoch 00044: ReduceLROnPlateau reducing learning rate to 4.768371808516747e-10.\n",
      "Epoch 45/50\n",
      "17/17 [==============================] - 16s 933ms/step - loss: 0.2973 - categorical_accuracy: 0.8997 - val_loss: 1.0170 - val_categorical_accuracy: 0.6667\n",
      "\n",
      "Epoch 00045: saving model to model_init_2019-12-2218_27_33.746320/model-00045-0.29726-0.89965-1.01698-0.66667.h5\n",
      "Epoch 46/50\n",
      "17/17 [==============================] - 16s 963ms/step - loss: 0.3076 - categorical_accuracy: 0.8893 - val_loss: 0.9173 - val_categorical_accuracy: 0.7167\n",
      "\n",
      "Epoch 00046: saving model to model_init_2019-12-2218_27_33.746320/model-00046-0.30762-0.88927-0.91734-0.71667.h5\n",
      "\n",
      "Epoch 00046: ReduceLROnPlateau reducing learning rate to 2.3841859042583735e-10.\n",
      "Epoch 47/50\n",
      "17/17 [==============================] - 16s 951ms/step - loss: 0.3255 - categorical_accuracy: 0.8616 - val_loss: 1.0232 - val_categorical_accuracy: 0.7167\n",
      "\n",
      "Epoch 00047: saving model to model_init_2019-12-2218_27_33.746320/model-00047-0.32552-0.86159-1.02321-0.71667.h5\n",
      "Epoch 48/50\n",
      "17/17 [==============================] - 16s 942ms/step - loss: 0.2785 - categorical_accuracy: 0.9031 - val_loss: 0.9347 - val_categorical_accuracy: 0.6667\n",
      "\n",
      "Epoch 00048: saving model to model_init_2019-12-2218_27_33.746320/model-00048-0.27851-0.90311-0.93474-0.66667.h5\n",
      "\n",
      "Epoch 00048: ReduceLROnPlateau reducing learning rate to 1.1920929521291868e-10.\n",
      "Epoch 49/50\n",
      "17/17 [==============================] - 17s 971ms/step - loss: 0.2957 - categorical_accuracy: 0.8927 - val_loss: 0.7331 - val_categorical_accuracy: 0.7333\n",
      "\n",
      "Epoch 00049: saving model to model_init_2019-12-2218_27_33.746320/model-00049-0.29567-0.89273-0.73307-0.73333.h5\n",
      "Epoch 50/50\n",
      "17/17 [==============================] - 16s 920ms/step - loss: 0.2607 - categorical_accuracy: 0.9170 - val_loss: 0.9086 - val_categorical_accuracy: 0.7333\n",
      "\n",
      "Epoch 00050: saving model to model_init_2019-12-2218_27_33.746320/model-00050-0.26069-0.91696-0.90861-0.73333.h5\n",
      "\n",
      "Epoch 00050: ReduceLROnPlateau reducing learning rate to 5.960464760645934e-11.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f47e7d2f5c0>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model7.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "#                     callbacks=callbacks_list, validation_data=val_generator, \n",
    "#                     validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Epoch 31/50\n",
    "17/17 [==============================] - 16s 944ms/step - loss: 0.3339 - categorical_accuracy: 0.8720 - val_loss: 0.7943 - val_categorical_accuracy: 0.7667\n",
    "\n",
    "Epoch 00031: saving model to model_init_2019-12-2218_27_33.746320/model-00031-0.33387-0.87197-0.79427-0.76667.h5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 8: Increase dropout ratio at the Dense layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def get_conv3d_model_f():\n",
    "\n",
    "# # Define model\n",
    "#     model = Sequential()\n",
    "\n",
    "#     model.add(Conv3D(16, kernel_size=(3,3,3), input_shape=input_shape,padding='same'))\n",
    "#     model.add(Activation('relu'))\n",
    "#     model.add(BatchNormalization())\n",
    "#     model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "#     model.add(Conv3D(32, kernel_size=(3,3,3), padding='same'))\n",
    "#     model.add(Activation('relu'))\n",
    "#     model.add(BatchNormalization())\n",
    "#     model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "   \n",
    "\n",
    "#     model.add(Conv3D(64, kernel_size=(3,3,3), padding='same'))\n",
    "#     model.add(Activation('relu'))\n",
    "#     model.add(BatchNormalization())\n",
    "#     model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "   \n",
    "\n",
    "#     #Flatten Layers\n",
    "#     model.add(Flatten())\n",
    "#     model.add(Dense(256, activation='relu'))\n",
    "#     model.add(Dropout(0.50))\n",
    "\n",
    "#     #softmax layer\n",
    "#     model.add(Dense(5, activation='softmax'))\n",
    "\n",
    "\n",
    "#     optimiser = optimizers.Adam(lr=0.001)\n",
    "#     model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "#     print (model.summary())\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_size= 40 ,num_frames= 16 ,num_rows= 60 ,num_cols= 60 ,num_epochs= 50\n"
     ]
    }
   ],
   "source": [
    "# # Set Hyperparameters for the model\n",
    "# set_hyper_parameters(batchSize=40, numFrames=16, numRows=60, numCols=60, numEpochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steps_per_epoch= 17 validation_steps= 3\n"
     ]
    }
   ],
   "source": [
    "# set_train_validation_steps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_1 (Conv3D)            (None, 16, 60, 60, 16)    1312      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 16, 60, 60, 16)    0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 16, 60, 60, 16)    64        \n",
      "_________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3 (None, 8, 30, 30, 16)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_2 (Conv3D)            (None, 8, 30, 30, 32)     13856     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 8, 30, 30, 32)     0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 8, 30, 30, 32)     128       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_2 (MaxPooling3 (None, 4, 15, 15, 32)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_3 (Conv3D)            (None, 4, 15, 15, 64)     55360     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 4, 15, 15, 64)     0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 4, 15, 15, 64)     256       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_3 (MaxPooling3 (None, 2, 7, 7, 64)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               1605888   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 1285      \n",
      "=================================================================\n",
      "Total params: 1,678,149\n",
      "Trainable params: 1,677,925\n",
      "Non-trainable params: 224\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# model8 = get_conv3d_model_f()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # create generators: Let us create the `train_generator` and the `val_generator` which will be used in `.fit_generator`.\n",
    "# train_generator = generator(train_path, train_doc, batch_size)\n",
    "# val_generator = generator(val_path, val_doc, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source path =  Project_data/val ; batch size = 40\n",
      "Source path =  Project_data/train ; batch size = 40\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:13: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "  del sys.path[0]\n",
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:21: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n",
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:44: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:53: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 135s 8s/step - loss: 6.7103 - categorical_accuracy: 0.3300 - val_loss: 7.5924 - val_categorical_accuracy: 0.4300\n",
      "\n",
      "Epoch 00001: saving model to model_init_2019-12-2222_33_48.524896/model-00001-6.77673-0.32428-7.59240-0.43000.h5\n",
      "Epoch 2/50\n",
      "17/17 [==============================] - 24s 1s/step - loss: 2.7805 - categorical_accuracy: 0.4910 - val_loss: 2.5668 - val_categorical_accuracy: 0.4500\n",
      "\n",
      "Epoch 00002: saving model to model_init_2019-12-2222_33_48.524896/model-00002-2.78046-0.49105-2.56681-0.45000.h5\n",
      "Epoch 3/50\n",
      "17/17 [==============================] - 22s 1s/step - loss: 1.6449 - categorical_accuracy: 0.5192 - val_loss: 1.7703 - val_categorical_accuracy: 0.3667\n",
      "\n",
      "Epoch 00003: saving model to model_init_2019-12-2222_33_48.524896/model-00003-1.66571-0.51771-1.77034-0.36667.h5\n",
      "Epoch 4/50\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.2436 - categorical_accuracy: 0.5387 - val_loss: 1.0854 - val_categorical_accuracy: 0.5833\n",
      "\n",
      "Epoch 00004: saving model to model_init_2019-12-2222_33_48.524896/model-00004-1.24356-0.53870-1.08539-0.58333.h5\n",
      "Epoch 5/50\n",
      "17/17 [==============================] - 17s 1s/step - loss: 1.1248 - categorical_accuracy: 0.5575 - val_loss: 1.5120 - val_categorical_accuracy: 0.4500\n",
      "\n",
      "Epoch 00005: saving model to model_init_2019-12-2222_33_48.524896/model-00005-1.13388-0.55591-1.51200-0.45000.h5\n",
      "Epoch 6/50\n",
      "17/17 [==============================] - 17s 974ms/step - loss: 1.1959 - categorical_accuracy: 0.5363 - val_loss: 1.0823 - val_categorical_accuracy: 0.5167\n",
      "\n",
      "Epoch 00006: saving model to model_init_2019-12-2222_33_48.524896/model-00006-1.19590-0.53633-1.08233-0.51667.h5\n",
      "Epoch 7/50\n",
      "17/17 [==============================] - 16s 922ms/step - loss: 0.9779 - categorical_accuracy: 0.6194 - val_loss: 1.3282 - val_categorical_accuracy: 0.4833\n",
      "\n",
      "Epoch 00007: saving model to model_init_2019-12-2222_33_48.524896/model-00007-0.97795-0.61938-1.32819-0.48333.h5\n",
      "Epoch 8/50\n",
      "17/17 [==============================] - 16s 968ms/step - loss: 0.8600 - categorical_accuracy: 0.6367 - val_loss: 1.2813 - val_categorical_accuracy: 0.5667\n",
      "\n",
      "Epoch 00008: saving model to model_init_2019-12-2222_33_48.524896/model-00008-0.85998-0.63668-1.28127-0.56667.h5\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 9/50\n",
      "17/17 [==============================] - 16s 920ms/step - loss: 0.8488 - categorical_accuracy: 0.6263 - val_loss: 0.9295 - val_categorical_accuracy: 0.6000\n",
      "\n",
      "Epoch 00009: saving model to model_init_2019-12-2222_33_48.524896/model-00009-0.84878-0.62630-0.92953-0.60000.h5\n",
      "Epoch 10/50\n",
      "17/17 [==============================] - 15s 877ms/step - loss: 0.7265 - categorical_accuracy: 0.7093 - val_loss: 0.7706 - val_categorical_accuracy: 0.7667\n",
      "\n",
      "Epoch 00010: saving model to model_init_2019-12-2222_33_48.524896/model-00010-0.72654-0.70934-0.77061-0.76667.h5\n",
      "Epoch 11/50\n",
      "17/17 [==============================] - 16s 955ms/step - loss: 0.6415 - categorical_accuracy: 0.7474 - val_loss: 0.8481 - val_categorical_accuracy: 0.6500\n",
      "\n",
      "Epoch 00011: saving model to model_init_2019-12-2222_33_48.524896/model-00011-0.64152-0.74740-0.84807-0.65000.h5\n",
      "Epoch 12/50\n",
      "17/17 [==============================] - 17s 978ms/step - loss: 0.6655 - categorical_accuracy: 0.7682 - val_loss: 0.9689 - val_categorical_accuracy: 0.6333\n",
      "\n",
      "Epoch 00012: saving model to model_init_2019-12-2222_33_48.524896/model-00012-0.66552-0.76817-0.96887-0.63333.h5\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 13/50\n",
      "17/17 [==============================] - 16s 918ms/step - loss: 0.5603 - categorical_accuracy: 0.7993 - val_loss: 0.7438 - val_categorical_accuracy: 0.6833\n",
      "\n",
      "Epoch 00013: saving model to model_init_2019-12-2222_33_48.524896/model-00013-0.56027-0.79931-0.74378-0.68333.h5\n",
      "Epoch 14/50\n",
      "17/17 [==============================] - 16s 954ms/step - loss: 0.5343 - categorical_accuracy: 0.8028 - val_loss: 0.8337 - val_categorical_accuracy: 0.6833\n",
      "\n",
      "Epoch 00014: saving model to model_init_2019-12-2222_33_48.524896/model-00014-0.53430-0.80277-0.83368-0.68333.h5\n",
      "Epoch 15/50\n",
      "17/17 [==============================] - 16s 941ms/step - loss: 0.4679 - categorical_accuracy: 0.8270 - val_loss: 0.5562 - val_categorical_accuracy: 0.8000\n",
      "\n",
      "Epoch 00015: saving model to model_init_2019-12-2222_33_48.524896/model-00015-0.46792-0.82699-0.55622-0.80000.h5\n",
      "Epoch 16/50\n",
      "17/17 [==============================] - 17s 978ms/step - loss: 0.3897 - categorical_accuracy: 0.8512 - val_loss: 0.7686 - val_categorical_accuracy: 0.7333\n",
      "\n",
      "Epoch 00016: saving model to model_init_2019-12-2222_33_48.524896/model-00016-0.38965-0.85121-0.76858-0.73333.h5\n",
      "Epoch 17/50\n",
      "17/17 [==============================] - 15s 907ms/step - loss: 0.4342 - categorical_accuracy: 0.8304 - val_loss: 0.6316 - val_categorical_accuracy: 0.7833\n",
      "\n",
      "Epoch 00017: saving model to model_init_2019-12-2222_33_48.524896/model-00017-0.43424-0.83045-0.63155-0.78333.h5\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 18/50\n",
      "17/17 [==============================] - 16s 937ms/step - loss: 0.3620 - categorical_accuracy: 0.8478 - val_loss: 0.7898 - val_categorical_accuracy: 0.7000\n",
      "\n",
      "Epoch 00018: saving model to model_init_2019-12-2222_33_48.524896/model-00018-0.36201-0.84775-0.78983-0.70000.h5\n",
      "Epoch 19/50\n",
      "17/17 [==============================] - 15s 892ms/step - loss: 0.4103 - categorical_accuracy: 0.8443 - val_loss: 0.7337 - val_categorical_accuracy: 0.6833\n",
      "\n",
      "Epoch 00019: saving model to model_init_2019-12-2222_33_48.524896/model-00019-0.41031-0.84429-0.73374-0.68333.h5\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 20/50\n",
      "17/17 [==============================] - 17s 978ms/step - loss: 0.3701 - categorical_accuracy: 0.8651 - val_loss: 0.5243 - val_categorical_accuracy: 0.8333\n",
      "\n",
      "Epoch 00020: saving model to model_init_2019-12-2222_33_48.524896/model-00020-0.37013-0.86505-0.52433-0.83333.h5\n",
      "Epoch 21/50\n",
      "17/17 [==============================] - 16s 958ms/step - loss: 0.4137 - categorical_accuracy: 0.8512 - val_loss: 0.8899 - val_categorical_accuracy: 0.6833\n",
      "\n",
      "Epoch 00021: saving model to model_init_2019-12-2222_33_48.524896/model-00021-0.41365-0.85121-0.88986-0.68333.h5\n",
      "Epoch 22/50\n",
      "17/17 [==============================] - 16s 955ms/step - loss: 0.3031 - categorical_accuracy: 0.9100 - val_loss: 0.8604 - val_categorical_accuracy: 0.6667\n",
      "\n",
      "Epoch 00022: saving model to model_init_2019-12-2222_33_48.524896/model-00022-0.30307-0.91003-0.86043-0.66667.h5\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 23/50\n",
      "17/17 [==============================] - 16s 940ms/step - loss: 0.3366 - categorical_accuracy: 0.8927 - val_loss: 0.6428 - val_categorical_accuracy: 0.8000\n",
      "\n",
      "Epoch 00023: saving model to model_init_2019-12-2222_33_48.524896/model-00023-0.33665-0.89273-0.64281-0.80000.h5\n",
      "Epoch 24/50\n",
      "17/17 [==============================] - 16s 916ms/step - loss: 0.3213 - categorical_accuracy: 0.8893 - val_loss: 0.6932 - val_categorical_accuracy: 0.7500\n",
      "\n",
      "Epoch 00024: saving model to model_init_2019-12-2222_33_48.524896/model-00024-0.32130-0.88927-0.69318-0.75000.h5\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 25/50\n",
      "17/17 [==============================] - 16s 960ms/step - loss: 0.3398 - categorical_accuracy: 0.8547 - val_loss: 0.7977 - val_categorical_accuracy: 0.7333\n",
      "\n",
      "Epoch 00025: saving model to model_init_2019-12-2222_33_48.524896/model-00025-0.33979-0.85467-0.79769-0.73333.h5\n",
      "Epoch 26/50\n",
      "17/17 [==============================] - 17s 974ms/step - loss: 0.2745 - categorical_accuracy: 0.8997 - val_loss: 0.7475 - val_categorical_accuracy: 0.7500\n",
      "\n",
      "Epoch 00026: saving model to model_init_2019-12-2222_33_48.524896/model-00026-0.27452-0.89965-0.74750-0.75000.h5\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "Epoch 27/50\n",
      "17/17 [==============================] - 16s 930ms/step - loss: 0.2857 - categorical_accuracy: 0.8997 - val_loss: 0.5870 - val_categorical_accuracy: 0.8167\n",
      "\n",
      "Epoch 00027: saving model to model_init_2019-12-2222_33_48.524896/model-00027-0.28573-0.89965-0.58704-0.81667.h5\n",
      "Epoch 28/50\n",
      "17/17 [==============================] - 16s 930ms/step - loss: 0.3327 - categorical_accuracy: 0.8547 - val_loss: 0.8346 - val_categorical_accuracy: 0.7167\n",
      "\n",
      "Epoch 00028: saving model to model_init_2019-12-2222_33_48.524896/model-00028-0.33273-0.85467-0.83461-0.71667.h5\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "Epoch 29/50\n",
      "17/17 [==============================] - 16s 952ms/step - loss: 0.3502 - categorical_accuracy: 0.8824 - val_loss: 0.7532 - val_categorical_accuracy: 0.7333\n",
      "\n",
      "Epoch 00029: saving model to model_init_2019-12-2222_33_48.524896/model-00029-0.35024-0.88235-0.75316-0.73333.h5\n",
      "Epoch 30/50\n",
      "17/17 [==============================] - 16s 919ms/step - loss: 0.3072 - categorical_accuracy: 0.8754 - val_loss: 0.9722 - val_categorical_accuracy: 0.7167\n",
      "\n",
      "Epoch 00030: saving model to model_init_2019-12-2222_33_48.524896/model-00030-0.30723-0.87543-0.97221-0.71667.h5\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "Epoch 31/50\n",
      "17/17 [==============================] - 15s 910ms/step - loss: 0.3453 - categorical_accuracy: 0.8685 - val_loss: 0.6350 - val_categorical_accuracy: 0.7667\n",
      "\n",
      "Epoch 00031: saving model to model_init_2019-12-2222_33_48.524896/model-00031-0.34527-0.86851-0.63503-0.76667.h5\n",
      "Epoch 32/50\n",
      "17/17 [==============================] - 17s 992ms/step - loss: 0.3397 - categorical_accuracy: 0.8754 - val_loss: 0.8120 - val_categorical_accuracy: 0.7667\n",
      "\n",
      "Epoch 00032: saving model to model_init_2019-12-2222_33_48.524896/model-00032-0.33971-0.87543-0.81196-0.76667.h5\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "Epoch 33/50\n",
      "17/17 [==============================] - 15s 903ms/step - loss: 0.2862 - categorical_accuracy: 0.8997 - val_loss: 0.7070 - val_categorical_accuracy: 0.7500\n",
      "\n",
      "Epoch 00033: saving model to model_init_2019-12-2222_33_48.524896/model-00033-0.28617-0.89965-0.70697-0.75000.h5\n",
      "Epoch 34/50\n",
      "17/17 [==============================] - 16s 970ms/step - loss: 0.2869 - categorical_accuracy: 0.8893 - val_loss: 0.6621 - val_categorical_accuracy: 0.7500\n",
      "\n",
      "Epoch 00034: saving model to model_init_2019-12-2222_33_48.524896/model-00034-0.28692-0.88927-0.66212-0.75000.h5\n",
      "\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "Epoch 35/50\n",
      "17/17 [==============================] - 16s 923ms/step - loss: 0.3005 - categorical_accuracy: 0.9031 - val_loss: 0.7972 - val_categorical_accuracy: 0.8000\n",
      "\n",
      "Epoch 00035: saving model to model_init_2019-12-2222_33_48.524896/model-00035-0.30052-0.90311-0.79722-0.80000.h5\n",
      "Epoch 36/50\n",
      "17/17 [==============================] - 16s 949ms/step - loss: 0.3560 - categorical_accuracy: 0.8685 - val_loss: 0.8289 - val_categorical_accuracy: 0.7000\n",
      "\n",
      "Epoch 00036: saving model to model_init_2019-12-2222_33_48.524896/model-00036-0.35601-0.86851-0.82889-0.70000.h5\n",
      "\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "Epoch 37/50\n",
      "17/17 [==============================] - 16s 969ms/step - loss: 0.3650 - categorical_accuracy: 0.8512 - val_loss: 0.6424 - val_categorical_accuracy: 0.7833\n",
      "\n",
      "Epoch 00037: saving model to model_init_2019-12-2222_33_48.524896/model-00037-0.36503-0.85121-0.64244-0.78333.h5\n",
      "Epoch 38/50\n",
      "17/17 [==============================] - 15s 892ms/step - loss: 0.2855 - categorical_accuracy: 0.9204 - val_loss: 0.8111 - val_categorical_accuracy: 0.7333\n",
      "\n",
      "Epoch 00038: saving model to model_init_2019-12-2222_33_48.524896/model-00038-0.28547-0.92042-0.81113-0.73333.h5\n",
      "\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "Epoch 39/50\n",
      "17/17 [==============================] - 16s 958ms/step - loss: 0.2806 - categorical_accuracy: 0.9100 - val_loss: 0.7633 - val_categorical_accuracy: 0.7833\n",
      "\n",
      "Epoch 00039: saving model to model_init_2019-12-2222_33_48.524896/model-00039-0.28056-0.91003-0.76330-0.78333.h5\n",
      "Epoch 40/50\n",
      "17/17 [==============================] - 16s 942ms/step - loss: 0.3149 - categorical_accuracy: 0.8824 - val_loss: 0.8314 - val_categorical_accuracy: 0.7000\n",
      "\n",
      "Epoch 00040: saving model to model_init_2019-12-2222_33_48.524896/model-00040-0.31491-0.88235-0.83141-0.70000.h5\n",
      "\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "Epoch 41/50\n",
      "17/17 [==============================] - 17s 1000ms/step - loss: 0.4014 - categorical_accuracy: 0.8374 - val_loss: 0.7788 - val_categorical_accuracy: 0.7833\n",
      "\n",
      "Epoch 00041: saving model to model_init_2019-12-2222_33_48.524896/model-00041-0.40144-0.83737-0.77879-0.78333.h5\n",
      "Epoch 42/50\n",
      "17/17 [==============================] - 15s 899ms/step - loss: 0.2980 - categorical_accuracy: 0.8824 - val_loss: 0.7002 - val_categorical_accuracy: 0.7333\n",
      "\n",
      "Epoch 00042: saving model to model_init_2019-12-2222_33_48.524896/model-00042-0.29803-0.88235-0.70018-0.73333.h5\n",
      "\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "Epoch 43/50\n",
      "17/17 [==============================] - 16s 939ms/step - loss: 0.2975 - categorical_accuracy: 0.9066 - val_loss: 0.8341 - val_categorical_accuracy: 0.7500\n",
      "\n",
      "Epoch 00043: saving model to model_init_2019-12-2222_33_48.524896/model-00043-0.29749-0.90657-0.83412-0.75000.h5\n",
      "Epoch 44/50\n",
      "17/17 [==============================] - 16s 957ms/step - loss: 0.3328 - categorical_accuracy: 0.8754 - val_loss: 0.8471 - val_categorical_accuracy: 0.7667\n",
      "\n",
      "Epoch 00044: saving model to model_init_2019-12-2222_33_48.524896/model-00044-0.33275-0.87543-0.84709-0.76667.h5\n",
      "\n",
      "Epoch 00044: ReduceLROnPlateau reducing learning rate to 1.525878978725359e-08.\n",
      "Epoch 45/50\n",
      "17/17 [==============================] - 15s 906ms/step - loss: 0.2840 - categorical_accuracy: 0.8997 - val_loss: 0.7191 - val_categorical_accuracy: 0.8000\n",
      "\n",
      "Epoch 00045: saving model to model_init_2019-12-2222_33_48.524896/model-00045-0.28402-0.89965-0.71910-0.80000.h5\n",
      "Epoch 46/50\n",
      "17/17 [==============================] - 16s 938ms/step - loss: 0.3141 - categorical_accuracy: 0.8685 - val_loss: 0.7294 - val_categorical_accuracy: 0.7500\n",
      "\n",
      "Epoch 00046: saving model to model_init_2019-12-2222_33_48.524896/model-00046-0.31406-0.86851-0.72943-0.75000.h5\n",
      "\n",
      "Epoch 00046: ReduceLROnPlateau reducing learning rate to 7.629394893626795e-09.\n",
      "Epoch 47/50\n",
      "17/17 [==============================] - 16s 955ms/step - loss: 0.3170 - categorical_accuracy: 0.8893 - val_loss: 0.6147 - val_categorical_accuracy: 0.8000\n",
      "\n",
      "Epoch 00047: saving model to model_init_2019-12-2222_33_48.524896/model-00047-0.31696-0.88927-0.61465-0.80000.h5\n",
      "Epoch 48/50\n",
      "17/17 [==============================] - 16s 915ms/step - loss: 0.2830 - categorical_accuracy: 0.8893 - val_loss: 0.9475 - val_categorical_accuracy: 0.6833\n",
      "\n",
      "Epoch 00048: saving model to model_init_2019-12-2222_33_48.524896/model-00048-0.28303-0.88927-0.94749-0.68333.h5\n",
      "\n",
      "Epoch 00048: ReduceLROnPlateau reducing learning rate to 3.814697446813398e-09.\n",
      "Epoch 49/50\n",
      "17/17 [==============================] - 15s 910ms/step - loss: 0.3284 - categorical_accuracy: 0.8789 - val_loss: 0.7706 - val_categorical_accuracy: 0.7667\n",
      "\n",
      "Epoch 00049: saving model to model_init_2019-12-2222_33_48.524896/model-00049-0.32845-0.87889-0.77060-0.76667.h5\n",
      "Epoch 50/50\n",
      "17/17 [==============================] - 16s 928ms/step - loss: 0.2727 - categorical_accuracy: 0.8997 - val_loss: 0.6746 - val_categorical_accuracy: 0.8333\n",
      "\n",
      "Epoch 00050: saving model to model_init_2019-12-2222_33_48.524896/model-00050-0.27271-0.89965-0.67464-0.83333.h5\n",
      "\n",
      "Epoch 00050: ReduceLROnPlateau reducing learning rate to 1.907348723406699e-09.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7efb6bda60b8>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model8.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "#                     callbacks=callbacks_list, validation_data=val_generator, \n",
    "#                     validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Epoch 20/50\n",
    "17/17 [==============================] - 17s 978ms/step - loss: 0.3701 - categorical_accuracy: 0.8651 - val_loss: 0.5243 - val_categorical_accuracy: 0.8333\n",
    "\n",
    "Epoch 00020: saving model to model_init_2019-12-2222_33_48.524896/model-00020-0.37013-0.86505-0.52433-0.83333.h5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 9: Continuation of model 7 by increasing drop out ratio at Dense Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def get_conv3d_model_g():\n",
    "\n",
    "# # Define model\n",
    "#     model = Sequential()\n",
    "\n",
    "#     model.add(Conv3D(16, kernel_size=(3,3,3), input_shape=input_shape,padding='same'))\n",
    "#     model.add(Activation('relu'))\n",
    "#     model.add(BatchNormalization())\n",
    "#     model.add(Conv3D(16, kernel_size=(3,3,3)))\n",
    "#     model.add(Activation('relu'))\n",
    "#     model.add(BatchNormalization())\n",
    "#     model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "#     model.add(Dropout(0.25))\n",
    "\n",
    "#     model.add(Conv3D(32, kernel_size=(3,3,3), padding='same'))\n",
    "#     model.add(Activation('relu'))\n",
    "#     model.add(BatchNormalization())\n",
    "#     model.add(Conv3D(32, kernel_size=(3,3,3), padding='same'))\n",
    "#     model.add(Activation('relu'))\n",
    "#     model.add(BatchNormalization())\n",
    "#     model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "#     model.add(Dropout(0.25))\n",
    "   \n",
    "\n",
    "#     model.add(Conv3D(64, kernel_size=(3,3,3), padding='same'))\n",
    "#     model.add(Activation('relu'))\n",
    "#     model.add(BatchNormalization())\n",
    "#     model.add(Conv3D(64, kernel_size=(3,3,3), padding='same'))\n",
    "#     model.add(Activation('relu'))\n",
    "#     model.add(BatchNormalization())\n",
    "#     model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "#     model.add(Dropout(0.25))\n",
    "   \n",
    "\n",
    "#     #Flatten Layers\n",
    "#     model.add(Flatten())\n",
    "#     model.add(Dense(256, activation='relu'))\n",
    "#     model.add(Dropout(0.50))\n",
    "\n",
    "#     #softmax layer\n",
    "#     model.add(Dense(5, activation='softmax'))\n",
    "\n",
    "\n",
    "#     optimiser = optimizers.Adam(lr=0.001)\n",
    "#     model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "#     print (model.summary())\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_size= 40 ,num_frames= 16 ,num_rows= 60 ,num_cols= 60 ,num_epochs= 50\n"
     ]
    }
   ],
   "source": [
    "# # Set Hyperparameters for the model\n",
    "# set_hyper_parameters(batchSize=40, numFrames=16, numRows=60, numCols=60, numEpochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steps_per_epoch= 17 validation_steps= 3\n"
     ]
    }
   ],
   "source": [
    "# set_train_validation_steps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_7 (Conv3D)            (None, 16, 60, 60, 16)    1312      \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 16, 60, 60, 16)    0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 16, 60, 60, 16)    64        \n",
      "_________________________________________________________________\n",
      "conv3d_8 (Conv3D)            (None, 14, 58, 58, 16)    6928      \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 14, 58, 58, 16)    0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 14, 58, 58, 16)    64        \n",
      "_________________________________________________________________\n",
      "max_pooling3d_7 (MaxPooling3 (None, 7, 29, 29, 16)     0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 7, 29, 29, 16)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_9 (Conv3D)            (None, 7, 29, 29, 32)     13856     \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 7, 29, 29, 32)     0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 7, 29, 29, 32)     128       \n",
      "_________________________________________________________________\n",
      "conv3d_10 (Conv3D)           (None, 7, 29, 29, 32)     27680     \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 7, 29, 29, 32)     0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 7, 29, 29, 32)     128       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_8 (MaxPooling3 (None, 3, 14, 14, 32)     0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 3, 14, 14, 32)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_11 (Conv3D)           (None, 3, 14, 14, 64)     55360     \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 3, 14, 14, 64)     0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 3, 14, 14, 64)     256       \n",
      "_________________________________________________________________\n",
      "conv3d_12 (Conv3D)           (None, 3, 14, 14, 64)     110656    \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 3, 14, 14, 64)     0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 3, 14, 14, 64)     256       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_9 (MaxPooling3 (None, 1, 7, 7, 64)       0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 1, 7, 7, 64)       0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 256)               803072    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 5)                 1285      \n",
      "=================================================================\n",
      "Total params: 1,021,045\n",
      "Trainable params: 1,020,597\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# model9 = get_conv3d_model_g()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # create generators: Let us create the `train_generator` and the `val_generator` which will be used in `.fit_generator`.\n",
    "# train_generator = generator(train_path, train_doc, batch_size)\n",
    "# val_generator = generator(val_path, val_doc, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source path =  Project_data/val ; batch size = Source path =  40\n",
      "Project_data/train ; batch size = 40\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:13: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "  del sys.path[0]\n",
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:21: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n",
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:44: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:53: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 42s 2s/step - loss: 4.7456 - categorical_accuracy: 0.3177 - val_loss: 2.4397 - val_categorical_accuracy: 0.3400\n",
      "\n",
      "Epoch 00001: saving model to model_init_2019-12-2222_33_48.524896/model-00001-4.83910-0.31071-2.43972-0.34000.h5\n",
      "Epoch 2/50\n",
      "17/17 [==============================] - 20s 1s/step - loss: 1.7170 - categorical_accuracy: 0.4143 - val_loss: 1.5125 - val_categorical_accuracy: 0.4000\n",
      "\n",
      "Epoch 00002: saving model to model_init_2019-12-2222_33_48.524896/model-00002-1.71699-0.41432-1.51249-0.40000.h5\n",
      "Epoch 3/50\n",
      "17/17 [==============================] - 21s 1s/step - loss: 1.2275 - categorical_accuracy: 0.5243 - val_loss: 1.4335 - val_categorical_accuracy: 0.5833\n",
      "\n",
      "Epoch 00003: saving model to model_init_2019-12-2222_33_48.524896/model-00003-1.23874-0.52044-1.43353-0.58333.h5\n",
      "Epoch 4/50\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.1348 - categorical_accuracy: 0.5449 - val_loss: 1.2171 - val_categorical_accuracy: 0.5833\n",
      "\n",
      "Epoch 00004: saving model to model_init_2019-12-2222_33_48.524896/model-00004-1.13482-0.54489-1.21709-0.58333.h5\n",
      "Epoch 5/50\n",
      "17/17 [==============================] - 17s 1s/step - loss: 0.8868 - categorical_accuracy: 0.6340 - val_loss: 1.0257 - val_categorical_accuracy: 0.6667\n",
      "\n",
      "Epoch 00005: saving model to model_init_2019-12-2222_33_48.524896/model-00005-0.88934-0.63259-1.02574-0.66667.h5\n",
      "Epoch 6/50\n",
      "17/17 [==============================] - 16s 966ms/step - loss: 0.9692 - categorical_accuracy: 0.6471 - val_loss: 1.0329 - val_categorical_accuracy: 0.6667\n",
      "\n",
      "Epoch 00006: saving model to model_init_2019-12-2222_33_48.524896/model-00006-0.96918-0.64706-1.03287-0.66667.h5\n",
      "Epoch 7/50\n",
      "17/17 [==============================] - 16s 938ms/step - loss: 0.9878 - categorical_accuracy: 0.5952 - val_loss: 1.1911 - val_categorical_accuracy: 0.6000\n",
      "\n",
      "Epoch 00007: saving model to model_init_2019-12-2222_33_48.524896/model-00007-0.98782-0.59516-1.19114-0.60000.h5\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 8/50\n",
      "17/17 [==============================] - 16s 931ms/step - loss: 0.6590 - categorical_accuracy: 0.7266 - val_loss: 0.9992 - val_categorical_accuracy: 0.6000\n",
      "\n",
      "Epoch 00008: saving model to model_init_2019-12-2222_33_48.524896/model-00008-0.65898-0.72664-0.99917-0.60000.h5\n",
      "Epoch 9/50\n",
      "17/17 [==============================] - 16s 962ms/step - loss: 0.7306 - categorical_accuracy: 0.6920 - val_loss: 1.0983 - val_categorical_accuracy: 0.5500\n",
      "\n",
      "Epoch 00009: saving model to model_init_2019-12-2222_33_48.524896/model-00009-0.73064-0.69204-1.09831-0.55000.h5\n",
      "Epoch 10/50\n",
      "17/17 [==============================] - 16s 963ms/step - loss: 0.7036 - categorical_accuracy: 0.7059 - val_loss: 0.9378 - val_categorical_accuracy: 0.7000\n",
      "\n",
      "Epoch 00010: saving model to model_init_2019-12-2222_33_48.524896/model-00010-0.70359-0.70588-0.93775-0.70000.h5\n",
      "Epoch 11/50\n",
      "17/17 [==============================] - 16s 966ms/step - loss: 0.5273 - categorical_accuracy: 0.7855 - val_loss: 0.8592 - val_categorical_accuracy: 0.6500\n",
      "\n",
      "Epoch 00011: saving model to model_init_2019-12-2222_33_48.524896/model-00011-0.52725-0.78547-0.85918-0.65000.h5\n",
      "Epoch 12/50\n",
      "17/17 [==============================] - 16s 915ms/step - loss: 0.6214 - categorical_accuracy: 0.7647 - val_loss: 0.9774 - val_categorical_accuracy: 0.6833\n",
      "\n",
      "Epoch 00012: saving model to model_init_2019-12-2222_33_48.524896/model-00012-0.62142-0.76471-0.97738-0.68333.h5\n",
      "Epoch 13/50\n",
      "17/17 [==============================] - 16s 951ms/step - loss: 0.5746 - categorical_accuracy: 0.7647 - val_loss: 0.7574 - val_categorical_accuracy: 0.7333\n",
      "\n",
      "Epoch 00013: saving model to model_init_2019-12-2222_33_48.524896/model-00013-0.57465-0.76471-0.75737-0.73333.h5\n",
      "Epoch 14/50\n",
      "17/17 [==============================] - 16s 939ms/step - loss: 0.5261 - categorical_accuracy: 0.7958 - val_loss: 0.6854 - val_categorical_accuracy: 0.7167\n",
      "\n",
      "Epoch 00014: saving model to model_init_2019-12-2222_33_48.524896/model-00014-0.52613-0.79585-0.68543-0.71667.h5\n",
      "Epoch 15/50\n",
      "17/17 [==============================] - 17s 982ms/step - loss: 0.4898 - categorical_accuracy: 0.8028 - val_loss: 0.7186 - val_categorical_accuracy: 0.7833\n",
      "\n",
      "Epoch 00015: saving model to model_init_2019-12-2222_33_48.524896/model-00015-0.48977-0.80277-0.71860-0.78333.h5\n",
      "Epoch 16/50\n",
      "17/17 [==============================] - 15s 908ms/step - loss: 0.4929 - categorical_accuracy: 0.7889 - val_loss: 0.8221 - val_categorical_accuracy: 0.7500\n",
      "\n",
      "Epoch 00016: saving model to model_init_2019-12-2222_33_48.524896/model-00016-0.49287-0.78893-0.82212-0.75000.h5\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 17/50\n",
      "17/17 [==============================] - 16s 968ms/step - loss: 0.4455 - categorical_accuracy: 0.8028 - val_loss: 1.0484 - val_categorical_accuracy: 0.6500\n",
      "\n",
      "Epoch 00017: saving model to model_init_2019-12-2222_33_48.524896/model-00017-0.44547-0.80277-1.04842-0.65000.h5\n",
      "Epoch 18/50\n",
      "17/17 [==============================] - 17s 974ms/step - loss: 0.3864 - categorical_accuracy: 0.8339 - val_loss: 0.8311 - val_categorical_accuracy: 0.7167\n",
      "\n",
      "Epoch 00018: saving model to model_init_2019-12-2222_33_48.524896/model-00018-0.38637-0.83391-0.83114-0.71667.h5\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 19/50\n",
      "17/17 [==============================] - 15s 877ms/step - loss: 0.3946 - categorical_accuracy: 0.8478 - val_loss: 0.7089 - val_categorical_accuracy: 0.7500\n",
      "\n",
      "Epoch 00019: saving model to model_init_2019-12-2222_33_48.524896/model-00019-0.39461-0.84775-0.70889-0.75000.h5\n",
      "Epoch 20/50\n",
      "17/17 [==============================] - 17s 973ms/step - loss: 0.3256 - categorical_accuracy: 0.9031 - val_loss: 0.5551 - val_categorical_accuracy: 0.7833\n",
      "\n",
      "Epoch 00020: saving model to model_init_2019-12-2222_33_48.524896/model-00020-0.32564-0.90311-0.55515-0.78333.h5\n",
      "Epoch 21/50\n",
      "17/17 [==============================] - 17s 983ms/step - loss: 0.3310 - categorical_accuracy: 0.8720 - val_loss: 1.2983 - val_categorical_accuracy: 0.6000\n",
      "\n",
      "Epoch 00021: saving model to model_init_2019-12-2222_33_48.524896/model-00021-0.33096-0.87197-1.29825-0.60000.h5\n",
      "Epoch 22/50\n",
      "17/17 [==============================] - 16s 935ms/step - loss: 0.2843 - categorical_accuracy: 0.8997 - val_loss: 1.1392 - val_categorical_accuracy: 0.6000\n",
      "\n",
      "Epoch 00022: saving model to model_init_2019-12-2222_33_48.524896/model-00022-0.28435-0.89965-1.13918-0.60000.h5\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 23/50\n",
      "17/17 [==============================] - 15s 902ms/step - loss: 0.2767 - categorical_accuracy: 0.9100 - val_loss: 0.5688 - val_categorical_accuracy: 0.7167\n",
      "\n",
      "Epoch 00023: saving model to model_init_2019-12-2222_33_48.524896/model-00023-0.27675-0.91003-0.56877-0.71667.h5\n",
      "Epoch 24/50\n",
      "17/17 [==============================] - 16s 951ms/step - loss: 0.2441 - categorical_accuracy: 0.9135 - val_loss: 0.9102 - val_categorical_accuracy: 0.6833\n",
      "\n",
      "Epoch 00024: saving model to model_init_2019-12-2222_33_48.524896/model-00024-0.24406-0.91349-0.91021-0.68333.h5\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 25/50\n",
      "17/17 [==============================] - 16s 955ms/step - loss: 0.3474 - categorical_accuracy: 0.8754 - val_loss: 0.9057 - val_categorical_accuracy: 0.6667\n",
      "\n",
      "Epoch 00025: saving model to model_init_2019-12-2222_33_48.524896/model-00025-0.34744-0.87543-0.90572-0.66667.h5\n",
      "Epoch 26/50\n",
      "17/17 [==============================] - 16s 921ms/step - loss: 0.2590 - categorical_accuracy: 0.9031 - val_loss: 0.7913 - val_categorical_accuracy: 0.7000\n",
      "\n",
      "Epoch 00026: saving model to model_init_2019-12-2222_33_48.524896/model-00026-0.25901-0.90311-0.79130-0.70000.h5\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 27/50\n",
      "17/17 [==============================] - 16s 960ms/step - loss: 0.2403 - categorical_accuracy: 0.9135 - val_loss: 0.5579 - val_categorical_accuracy: 0.7833\n",
      "\n",
      "Epoch 00027: saving model to model_init_2019-12-2222_33_48.524896/model-00027-0.24030-0.91349-0.55786-0.78333.h5\n",
      "Epoch 28/50\n",
      "17/17 [==============================] - 16s 930ms/step - loss: 0.3033 - categorical_accuracy: 0.8893 - val_loss: 0.9608 - val_categorical_accuracy: 0.6333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00028: saving model to model_init_2019-12-2222_33_48.524896/model-00028-0.30333-0.88927-0.96078-0.63333.h5\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "Epoch 29/50\n",
      "17/17 [==============================] - 17s 996ms/step - loss: 0.2536 - categorical_accuracy: 0.9066 - val_loss: 0.7171 - val_categorical_accuracy: 0.7000\n",
      "\n",
      "Epoch 00029: saving model to model_init_2019-12-2222_33_48.524896/model-00029-0.25357-0.90657-0.71714-0.70000.h5\n",
      "Epoch 30/50\n",
      "17/17 [==============================] - 16s 915ms/step - loss: 0.2241 - categorical_accuracy: 0.9170 - val_loss: 0.7684 - val_categorical_accuracy: 0.6667\n",
      "\n",
      "Epoch 00030: saving model to model_init_2019-12-2222_33_48.524896/model-00030-0.22410-0.91696-0.76840-0.66667.h5\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "Epoch 31/50\n",
      "17/17 [==============================] - 16s 942ms/step - loss: 0.2817 - categorical_accuracy: 0.8997 - val_loss: 0.9183 - val_categorical_accuracy: 0.6667\n",
      "\n",
      "Epoch 00031: saving model to model_init_2019-12-2222_33_48.524896/model-00031-0.28167-0.89965-0.91832-0.66667.h5\n",
      "Epoch 32/50\n",
      "17/17 [==============================] - 16s 943ms/step - loss: 0.2425 - categorical_accuracy: 0.9031 - val_loss: 0.7723 - val_categorical_accuracy: 0.7000\n",
      "\n",
      "Epoch 00032: saving model to model_init_2019-12-2222_33_48.524896/model-00032-0.24247-0.90311-0.77231-0.70000.h5\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "Epoch 33/50\n",
      "17/17 [==============================] - 16s 957ms/step - loss: 0.3054 - categorical_accuracy: 0.8754 - val_loss: 0.8826 - val_categorical_accuracy: 0.6667\n",
      "\n",
      "Epoch 00033: saving model to model_init_2019-12-2222_33_48.524896/model-00033-0.30543-0.87543-0.88258-0.66667.h5\n",
      "Epoch 34/50\n",
      "17/17 [==============================] - 16s 962ms/step - loss: 0.2294 - categorical_accuracy: 0.9308 - val_loss: 0.6792 - val_categorical_accuracy: 0.7167\n",
      "\n",
      "Epoch 00034: saving model to model_init_2019-12-2222_33_48.524896/model-00034-0.22937-0.93080-0.67924-0.71667.h5\n",
      "\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "Epoch 35/50\n",
      "17/17 [==============================] - 15s 890ms/step - loss: 0.2419 - categorical_accuracy: 0.9135 - val_loss: 0.9021 - val_categorical_accuracy: 0.6000\n",
      "\n",
      "Epoch 00035: saving model to model_init_2019-12-2222_33_48.524896/model-00035-0.24188-0.91349-0.90215-0.60000.h5\n",
      "Epoch 36/50\n",
      "17/17 [==============================] - 16s 929ms/step - loss: 0.2155 - categorical_accuracy: 0.9135 - val_loss: 0.6923 - val_categorical_accuracy: 0.7333\n",
      "\n",
      "Epoch 00036: saving model to model_init_2019-12-2222_33_48.524896/model-00036-0.21549-0.91349-0.69235-0.73333.h5\n",
      "\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "Epoch 37/50\n",
      "17/17 [==============================] - 17s 971ms/step - loss: 0.3263 - categorical_accuracy: 0.8685 - val_loss: 0.7808 - val_categorical_accuracy: 0.7167\n",
      "\n",
      "Epoch 00037: saving model to model_init_2019-12-2222_33_48.524896/model-00037-0.32628-0.86851-0.78079-0.71667.h5\n",
      "Epoch 38/50\n",
      "17/17 [==============================] - 16s 922ms/step - loss: 0.2774 - categorical_accuracy: 0.9031 - val_loss: 0.7942 - val_categorical_accuracy: 0.6667\n",
      "\n",
      "Epoch 00038: saving model to model_init_2019-12-2222_33_48.524896/model-00038-0.27741-0.90311-0.79422-0.66667.h5\n",
      "\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "Epoch 39/50\n",
      "17/17 [==============================] - 16s 935ms/step - loss: 0.3485 - categorical_accuracy: 0.8581 - val_loss: 0.9331 - val_categorical_accuracy: 0.6333\n",
      "\n",
      "Epoch 00039: saving model to model_init_2019-12-2222_33_48.524896/model-00039-0.34852-0.85813-0.93314-0.63333.h5\n",
      "Epoch 40/50\n",
      "17/17 [==============================] - 16s 946ms/step - loss: 0.2217 - categorical_accuracy: 0.9343 - val_loss: 0.5778 - val_categorical_accuracy: 0.7833\n",
      "\n",
      "Epoch 00040: saving model to model_init_2019-12-2222_33_48.524896/model-00040-0.22165-0.93426-0.57785-0.78333.h5\n",
      "\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "Epoch 41/50\n",
      "17/17 [==============================] - 16s 960ms/step - loss: 0.2141 - categorical_accuracy: 0.9239 - val_loss: 0.8440 - val_categorical_accuracy: 0.6500\n",
      "\n",
      "Epoch 00041: saving model to model_init_2019-12-2222_33_48.524896/model-00041-0.21406-0.92388-0.84399-0.65000.h5\n",
      "Epoch 42/50\n",
      "17/17 [==============================] - 16s 967ms/step - loss: 0.2552 - categorical_accuracy: 0.9031 - val_loss: 0.7008 - val_categorical_accuracy: 0.7000\n",
      "\n",
      "Epoch 00042: saving model to model_init_2019-12-2222_33_48.524896/model-00042-0.25524-0.90311-0.70077-0.70000.h5\n",
      "\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "Epoch 43/50\n",
      "17/17 [==============================] - 16s 952ms/step - loss: 0.2382 - categorical_accuracy: 0.9170 - val_loss: 0.8157 - val_categorical_accuracy: 0.6833\n",
      "\n",
      "Epoch 00043: saving model to model_init_2019-12-2222_33_48.524896/model-00043-0.23817-0.91696-0.81573-0.68333.h5\n",
      "Epoch 44/50\n",
      "17/17 [==============================] - 16s 931ms/step - loss: 0.2545 - categorical_accuracy: 0.8997 - val_loss: 0.8154 - val_categorical_accuracy: 0.7000\n",
      "\n",
      "Epoch 00044: saving model to model_init_2019-12-2222_33_48.524896/model-00044-0.25451-0.89965-0.81543-0.70000.h5\n",
      "\n",
      "Epoch 00044: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "Epoch 45/50\n",
      "17/17 [==============================] - 16s 916ms/step - loss: 0.2759 - categorical_accuracy: 0.8893 - val_loss: 0.8836 - val_categorical_accuracy: 0.6667\n",
      "\n",
      "Epoch 00045: saving model to model_init_2019-12-2222_33_48.524896/model-00045-0.27591-0.88927-0.88361-0.66667.h5\n",
      "Epoch 46/50\n",
      "17/17 [==============================] - 16s 967ms/step - loss: 0.3267 - categorical_accuracy: 0.8893 - val_loss: 0.6968 - val_categorical_accuracy: 0.7167\n",
      "\n",
      "Epoch 00046: saving model to model_init_2019-12-2222_33_48.524896/model-00046-0.32674-0.88927-0.69681-0.71667.h5\n",
      "\n",
      "Epoch 00046: ReduceLROnPlateau reducing learning rate to 1.525878978725359e-08.\n",
      "Epoch 47/50\n",
      "17/17 [==============================] - 16s 927ms/step - loss: 0.2546 - categorical_accuracy: 0.9135 - val_loss: 0.6800 - val_categorical_accuracy: 0.7167\n",
      "\n",
      "Epoch 00047: saving model to model_init_2019-12-2222_33_48.524896/model-00047-0.25461-0.91349-0.67998-0.71667.h5\n",
      "Epoch 48/50\n",
      "17/17 [==============================] - 16s 960ms/step - loss: 0.2382 - categorical_accuracy: 0.9135 - val_loss: 0.8126 - val_categorical_accuracy: 0.7000\n",
      "\n",
      "Epoch 00048: saving model to model_init_2019-12-2222_33_48.524896/model-00048-0.23820-0.91349-0.81259-0.70000.h5\n",
      "\n",
      "Epoch 00048: ReduceLROnPlateau reducing learning rate to 7.629394893626795e-09.\n",
      "Epoch 49/50\n",
      "17/17 [==============================] - 17s 972ms/step - loss: 0.2112 - categorical_accuracy: 0.9204 - val_loss: 0.8006 - val_categorical_accuracy: 0.7000\n",
      "\n",
      "Epoch 00049: saving model to model_init_2019-12-2222_33_48.524896/model-00049-0.21120-0.92042-0.80058-0.70000.h5\n",
      "Epoch 50/50\n",
      "17/17 [==============================] - 16s 957ms/step - loss: 0.2530 - categorical_accuracy: 0.9170 - val_loss: 0.9034 - val_categorical_accuracy: 0.6333\n",
      "\n",
      "Epoch 00050: saving model to model_init_2019-12-2222_33_48.524896/model-00050-0.25296-0.91696-0.90340-0.63333.h5\n",
      "\n",
      "Epoch 00050: ReduceLROnPlateau reducing learning rate to 3.814697446813398e-09.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7efb603d1b70>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model9.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "#                     callbacks=callbacks_list, validation_data=val_generator, \n",
    "#                     validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Epoch 15/50\n",
    "17/17 [==============================] - 17s 982ms/step - loss: 0.4898 - categorical_accuracy: 0.8028 - val_loss: 0.7186 - val_categorical_accuracy: 0.7833\n",
    "\n",
    "Epoch 00015: saving model to model_init_2019-12-2222_33_48.524896/model-00015-0.48977-0.80277-0.71860-0.78333.h5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 10: Enhancements to model 8 by adding an additional CNN layer with 128 filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_conv3d_model_h():\n",
    "\n",
    "# Define model\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv3D(16, kernel_size=(3,3,3), input_shape=input_shape,padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "    model.add(Conv3D(32, kernel_size=(3,3,3), padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "   \n",
    "\n",
    "    model.add(Conv3D(64, kernel_size=(3,3,3), padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "   \n",
    "    model.add(Conv3D(128, kernel_size=(3,3,3), padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "   \n",
    "    #Flatten Layers\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.50))\n",
    "\n",
    "    #softmax layer\n",
    "    model.add(Dense(5, activation='softmax'))\n",
    "\n",
    "\n",
    "    optimiser = optimizers.Adam(lr=0.001)\n",
    "    model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "    print (model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_size= 40 ,num_frames= 16 ,num_rows= 60 ,num_cols= 60 ,num_epochs= 50\n"
     ]
    }
   ],
   "source": [
    "# Set Hyperparameters for the model\n",
    "set_hyper_parameters(batchSize=40, numFrames=16, numRows=60, numCols=60, numEpochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steps_per_epoch= 17 validation_steps= 3\n"
     ]
    }
   ],
   "source": [
    "set_train_validation_steps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_21 (Conv3D)           (None, 16, 60, 60, 16)    1312      \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 16, 60, 60, 16)    0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 16, 60, 60, 16)    64        \n",
      "_________________________________________________________________\n",
      "max_pooling3d_18 (MaxPooling (None, 8, 30, 30, 16)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_22 (Conv3D)           (None, 8, 30, 30, 32)     13856     \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 8, 30, 30, 32)     0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_22 (Batc (None, 8, 30, 30, 32)     128       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_19 (MaxPooling (None, 4, 15, 15, 32)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_23 (Conv3D)           (None, 4, 15, 15, 64)     55360     \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 4, 15, 15, 64)     0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_23 (Batc (None, 4, 15, 15, 64)     256       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_20 (MaxPooling (None, 2, 7, 7, 64)       0         \n",
      "_________________________________________________________________\n",
      "conv3d_24 (Conv3D)           (None, 2, 7, 7, 128)      221312    \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 2, 7, 7, 128)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_24 (Batc (None, 2, 7, 7, 128)      512       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_21 (MaxPooling (None, 1, 3, 3, 128)      0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 256)               295168    \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 5)                 1285      \n",
      "=================================================================\n",
      "Total params: 589,253\n",
      "Trainable params: 588,773\n",
      "Non-trainable params: 480\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model10 = get_conv3d_model_h()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create generators: Let us create the `train_generator` and the `val_generator` which will be used in `.fit_generator`.\n",
    "train_generator = generator(train_path, train_doc, batch_size)\n",
    "val_generator = generator(val_path, val_doc, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source path = Source path =  Project_data/val Project_data/train ; batch size = 40\n",
      " Epoch 1/50; batch size = 40\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:13: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "  del sys.path[0]\n",
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:21: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/17 [>.............................] - ETA: 1:32 - loss: 3.6034 - categorical_accuracy: 0.3000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:44: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:53: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 39s 2s/step - loss: 2.1950 - categorical_accuracy: 0.3843 - val_loss: 1.2634 - val_categorical_accuracy: 0.5300\n",
      "\n",
      "Epoch 00001: saving model to model_init_2019-12-2222_33_48.524896/model-00001-2.21368-0.38311-1.26340-0.53000.h5\n",
      "Epoch 2/50\n",
      "17/17 [==============================] - 21s 1s/step - loss: 1.3038 - categorical_accuracy: 0.4859 - val_loss: 1.2827 - val_categorical_accuracy: 0.5500\n",
      "\n",
      "Epoch 00002: saving model to model_init_2019-12-2222_33_48.524896/model-00002-1.30378-0.48593-1.28269-0.55000.h5\n",
      "Epoch 3/50\n",
      "17/17 [==============================] - 21s 1s/step - loss: 1.0019 - categorical_accuracy: 0.5423 - val_loss: 0.8755 - val_categorical_accuracy: 0.6333\n",
      "\n",
      "Epoch 00003: saving model to model_init_2019-12-2222_33_48.524896/model-00003-1.01468-0.53678-0.87553-0.63333.h5\n",
      "Epoch 4/50\n",
      "17/17 [==============================] - 17s 1s/step - loss: 0.9793 - categorical_accuracy: 0.5975 - val_loss: 1.0946 - val_categorical_accuracy: 0.6167\n",
      "\n",
      "Epoch 00004: saving model to model_init_2019-12-2222_33_48.524896/model-00004-0.97930-0.59752-1.09458-0.61667.h5\n",
      "Epoch 5/50\n",
      "17/17 [==============================] - 18s 1s/step - loss: 0.9668 - categorical_accuracy: 0.5989 - val_loss: 0.8963 - val_categorical_accuracy: 0.7333\n",
      "\n",
      "Epoch 00005: saving model to model_init_2019-12-2222_33_48.524896/model-00005-0.97151-0.59744-0.89634-0.73333.h5\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 6/50\n",
      "17/17 [==============================] - 16s 929ms/step - loss: 0.8130 - categorical_accuracy: 0.6644 - val_loss: 0.7722 - val_categorical_accuracy: 0.7500\n",
      "\n",
      "Epoch 00006: saving model to model_init_2019-12-2222_33_48.524896/model-00006-0.81302-0.66436-0.77216-0.75000.h5\n",
      "Epoch 7/50\n",
      "17/17 [==============================] - 16s 943ms/step - loss: 0.7101 - categorical_accuracy: 0.7128 - val_loss: 1.0795 - val_categorical_accuracy: 0.5333\n",
      "\n",
      "Epoch 00007: saving model to model_init_2019-12-2222_33_48.524896/model-00007-0.71011-0.71280-1.07952-0.53333.h5\n",
      "Epoch 8/50\n",
      "17/17 [==============================] - 16s 967ms/step - loss: 0.6973 - categorical_accuracy: 0.7336 - val_loss: 1.1648 - val_categorical_accuracy: 0.6167\n",
      "\n",
      "Epoch 00008: saving model to model_init_2019-12-2222_33_48.524896/model-00008-0.69726-0.73356-1.16476-0.61667.h5\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 9/50\n",
      "17/17 [==============================] - 16s 952ms/step - loss: 0.5922 - categorical_accuracy: 0.7785 - val_loss: 0.6435 - val_categorical_accuracy: 0.7500\n",
      "\n",
      "Epoch 00009: saving model to model_init_2019-12-2222_33_48.524896/model-00009-0.59219-0.77855-0.64352-0.75000.h5\n",
      "Epoch 10/50\n",
      "17/17 [==============================] - 15s 877ms/step - loss: 0.5059 - categorical_accuracy: 0.8028 - val_loss: 0.8362 - val_categorical_accuracy: 0.6500\n",
      "\n",
      "Epoch 00010: saving model to model_init_2019-12-2222_33_48.524896/model-00010-0.50589-0.80277-0.83617-0.65000.h5\n",
      "Epoch 11/50\n",
      "17/17 [==============================] - 16s 960ms/step - loss: 0.4760 - categorical_accuracy: 0.8131 - val_loss: 0.6887 - val_categorical_accuracy: 0.7167\n",
      "\n",
      "Epoch 00011: saving model to model_init_2019-12-2222_33_48.524896/model-00011-0.47598-0.81315-0.68875-0.71667.h5\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 12/50\n",
      "17/17 [==============================] - 17s 986ms/step - loss: 0.3980 - categorical_accuracy: 0.8339 - val_loss: 0.6580 - val_categorical_accuracy: 0.7333\n",
      "\n",
      "Epoch 00012: saving model to model_init_2019-12-2222_33_48.524896/model-00012-0.39805-0.83391-0.65796-0.73333.h5\n",
      "Epoch 13/50\n",
      "17/17 [==============================] - 16s 956ms/step - loss: 0.3286 - categorical_accuracy: 0.8997 - val_loss: 0.5583 - val_categorical_accuracy: 0.7667\n",
      "\n",
      "Epoch 00013: saving model to model_init_2019-12-2222_33_48.524896/model-00013-0.32858-0.89965-0.55827-0.76667.h5\n",
      "Epoch 14/50\n",
      "17/17 [==============================] - 15s 903ms/step - loss: 0.3625 - categorical_accuracy: 0.8754 - val_loss: 0.6130 - val_categorical_accuracy: 0.7833\n",
      "\n",
      "Epoch 00014: saving model to model_init_2019-12-2222_33_48.524896/model-00014-0.36251-0.87543-0.61301-0.78333.h5\n",
      "Epoch 15/50\n",
      "17/17 [==============================] - 16s 957ms/step - loss: 0.3661 - categorical_accuracy: 0.8547 - val_loss: 0.7767 - val_categorical_accuracy: 0.7167\n",
      "\n",
      "Epoch 00015: saving model to model_init_2019-12-2222_33_48.524896/model-00015-0.36609-0.85467-0.77672-0.71667.h5\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 16/50\n",
      "17/17 [==============================] - 16s 924ms/step - loss: 0.2955 - categorical_accuracy: 0.8754 - val_loss: 0.5659 - val_categorical_accuracy: 0.8833\n",
      "\n",
      "Epoch 00016: saving model to model_init_2019-12-2222_33_48.524896/model-00016-0.29555-0.87543-0.56587-0.88333.h5\n",
      "Epoch 17/50\n",
      "17/17 [==============================] - 16s 945ms/step - loss: 0.3096 - categorical_accuracy: 0.8927 - val_loss: 0.6395 - val_categorical_accuracy: 0.7833\n",
      "\n",
      "Epoch 00017: saving model to model_init_2019-12-2222_33_48.524896/model-00017-0.30964-0.89273-0.63952-0.78333.h5\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 18/50\n",
      "17/17 [==============================] - 15s 895ms/step - loss: 0.2716 - categorical_accuracy: 0.9273 - val_loss: 0.4279 - val_categorical_accuracy: 0.8667\n",
      "\n",
      "Epoch 00018: saving model to model_init_2019-12-2222_33_48.524896/model-00018-0.27155-0.92734-0.42793-0.86667.h5\n",
      "Epoch 19/50\n",
      "17/17 [==============================] - 17s 989ms/step - loss: 0.2751 - categorical_accuracy: 0.9135 - val_loss: 0.5808 - val_categorical_accuracy: 0.8333\n",
      "\n",
      "Epoch 00019: saving model to model_init_2019-12-2222_33_48.524896/model-00019-0.27509-0.91349-0.58083-0.83333.h5\n",
      "Epoch 20/50\n",
      "17/17 [==============================] - 15s 896ms/step - loss: 0.2538 - categorical_accuracy: 0.9308 - val_loss: 0.5381 - val_categorical_accuracy: 0.8500\n",
      "\n",
      "Epoch 00020: saving model to model_init_2019-12-2222_33_48.524896/model-00020-0.25380-0.93080-0.53809-0.85000.h5\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 21/50\n",
      "17/17 [==============================] - 17s 976ms/step - loss: 0.3103 - categorical_accuracy: 0.8927 - val_loss: 0.5516 - val_categorical_accuracy: 0.8000\n",
      "\n",
      "Epoch 00021: saving model to model_init_2019-12-2222_33_48.524896/model-00021-0.31029-0.89273-0.55162-0.80000.h5\n",
      "Epoch 22/50\n",
      "17/17 [==============================] - 15s 900ms/step - loss: 0.2200 - categorical_accuracy: 0.9343 - val_loss: 0.3935 - val_categorical_accuracy: 0.8833\n",
      "\n",
      "Epoch 00022: saving model to model_init_2019-12-2222_33_48.524896/model-00022-0.22003-0.93426-0.39348-0.88333.h5\n",
      "Epoch 23/50\n",
      "17/17 [==============================] - 17s 985ms/step - loss: 0.2935 - categorical_accuracy: 0.8927 - val_loss: 0.6831 - val_categorical_accuracy: 0.7667\n",
      "\n",
      "Epoch 00023: saving model to model_init_2019-12-2222_33_48.524896/model-00023-0.29355-0.89273-0.68312-0.76667.h5\n",
      "Epoch 24/50\n",
      "17/17 [==============================] - 15s 905ms/step - loss: 0.2770 - categorical_accuracy: 0.8927 - val_loss: 0.5035 - val_categorical_accuracy: 0.8000\n",
      "\n",
      "Epoch 00024: saving model to model_init_2019-12-2222_33_48.524896/model-00024-0.27703-0.89273-0.50350-0.80000.h5\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "Epoch 25/50\n",
      "17/17 [==============================] - 17s 983ms/step - loss: 0.2592 - categorical_accuracy: 0.9170 - val_loss: 0.6767 - val_categorical_accuracy: 0.7667\n",
      "\n",
      "Epoch 00025: saving model to model_init_2019-12-2222_33_48.524896/model-00025-0.25922-0.91696-0.67673-0.76667.h5\n",
      "Epoch 26/50\n",
      "17/17 [==============================] - 16s 925ms/step - loss: 0.2456 - categorical_accuracy: 0.9031 - val_loss: 0.4351 - val_categorical_accuracy: 0.8333\n",
      "\n",
      "Epoch 00026: saving model to model_init_2019-12-2222_33_48.524896/model-00026-0.24557-0.90311-0.43509-0.83333.h5\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "Epoch 27/50\n",
      "17/17 [==============================] - 16s 919ms/step - loss: 0.2546 - categorical_accuracy: 0.8997 - val_loss: 0.5611 - val_categorical_accuracy: 0.7833\n",
      "\n",
      "Epoch 00027: saving model to model_init_2019-12-2222_33_48.524896/model-00027-0.25457-0.89965-0.56110-0.78333.h5\n",
      "Epoch 28/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 16s 956ms/step - loss: 0.2950 - categorical_accuracy: 0.8754 - val_loss: 0.4747 - val_categorical_accuracy: 0.8500\n",
      "\n",
      "Epoch 00028: saving model to model_init_2019-12-2222_33_48.524896/model-00028-0.29502-0.87543-0.47467-0.85000.h5\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "Epoch 29/50\n",
      "17/17 [==============================] - 16s 944ms/step - loss: 0.2686 - categorical_accuracy: 0.9031 - val_loss: 0.3631 - val_categorical_accuracy: 0.8833\n",
      "\n",
      "Epoch 00029: saving model to model_init_2019-12-2222_33_48.524896/model-00029-0.26855-0.90311-0.36314-0.88333.h5\n",
      "Epoch 30/50\n",
      "17/17 [==============================] - 16s 951ms/step - loss: 0.2390 - categorical_accuracy: 0.9412 - val_loss: 0.7397 - val_categorical_accuracy: 0.7167\n",
      "\n",
      "Epoch 00030: saving model to model_init_2019-12-2222_33_48.524896/model-00030-0.23896-0.94118-0.73965-0.71667.h5\n",
      "Epoch 31/50\n",
      "17/17 [==============================] - 16s 948ms/step - loss: 0.2478 - categorical_accuracy: 0.9170 - val_loss: 0.5032 - val_categorical_accuracy: 0.8667\n",
      "\n",
      "Epoch 00031: saving model to model_init_2019-12-2222_33_48.524896/model-00031-0.24780-0.91696-0.50323-0.86667.h5\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "Epoch 32/50\n",
      "17/17 [==============================] - 16s 941ms/step - loss: 0.2424 - categorical_accuracy: 0.9273 - val_loss: 0.4962 - val_categorical_accuracy: 0.8167\n",
      "\n",
      "Epoch 00032: saving model to model_init_2019-12-2222_33_48.524896/model-00032-0.24242-0.92734-0.49620-0.81667.h5\n",
      "Epoch 33/50\n",
      "17/17 [==============================] - 16s 934ms/step - loss: 0.2814 - categorical_accuracy: 0.9031 - val_loss: 0.5490 - val_categorical_accuracy: 0.8333\n",
      "\n",
      "Epoch 00033: saving model to model_init_2019-12-2222_33_48.524896/model-00033-0.28144-0.90311-0.54896-0.83333.h5\n",
      "\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "Epoch 34/50\n",
      "17/17 [==============================] - 16s 948ms/step - loss: 0.2676 - categorical_accuracy: 0.8997 - val_loss: 0.5489 - val_categorical_accuracy: 0.8500\n",
      "\n",
      "Epoch 00034: saving model to model_init_2019-12-2222_33_48.524896/model-00034-0.26758-0.89965-0.54894-0.85000.h5\n",
      "Epoch 35/50\n",
      "17/17 [==============================] - 16s 946ms/step - loss: 0.2477 - categorical_accuracy: 0.9100 - val_loss: 0.6725 - val_categorical_accuracy: 0.7500\n",
      "\n",
      "Epoch 00035: saving model to model_init_2019-12-2222_33_48.524896/model-00035-0.24769-0.91003-0.67249-0.75000.h5\n",
      "\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "Epoch 36/50\n",
      "17/17 [==============================] - 16s 940ms/step - loss: 0.2763 - categorical_accuracy: 0.9170 - val_loss: 0.3611 - val_categorical_accuracy: 0.8833\n",
      "\n",
      "Epoch 00036: saving model to model_init_2019-12-2222_33_48.524896/model-00036-0.27631-0.91696-0.36111-0.88333.h5\n",
      "Epoch 37/50\n",
      "17/17 [==============================] - 16s 958ms/step - loss: 0.2255 - categorical_accuracy: 0.9412 - val_loss: 0.6150 - val_categorical_accuracy: 0.8000\n",
      "\n",
      "Epoch 00037: saving model to model_init_2019-12-2222_33_48.524896/model-00037-0.22550-0.94118-0.61504-0.80000.h5\n",
      "Epoch 38/50\n",
      "17/17 [==============================] - 15s 911ms/step - loss: 0.2338 - categorical_accuracy: 0.9239 - val_loss: 0.4340 - val_categorical_accuracy: 0.8500\n",
      "\n",
      "Epoch 00038: saving model to model_init_2019-12-2222_33_48.524896/model-00038-0.23384-0.92388-0.43403-0.85000.h5\n",
      "\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "Epoch 39/50\n",
      "17/17 [==============================] - 16s 939ms/step - loss: 0.2523 - categorical_accuracy: 0.9377 - val_loss: 0.5241 - val_categorical_accuracy: 0.8333\n",
      "\n",
      "Epoch 00039: saving model to model_init_2019-12-2222_33_48.524896/model-00039-0.25232-0.93772-0.52405-0.83333.h5\n",
      "Epoch 40/50\n",
      "17/17 [==============================] - 16s 956ms/step - loss: 0.2546 - categorical_accuracy: 0.9170 - val_loss: 0.5225 - val_categorical_accuracy: 0.8667\n",
      "\n",
      "Epoch 00040: saving model to model_init_2019-12-2222_33_48.524896/model-00040-0.25458-0.91696-0.52248-0.86667.h5\n",
      "\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "Epoch 41/50\n",
      "17/17 [==============================] - 16s 917ms/step - loss: 0.2141 - categorical_accuracy: 0.9412 - val_loss: 0.5286 - val_categorical_accuracy: 0.8000\n",
      "\n",
      "Epoch 00041: saving model to model_init_2019-12-2222_33_48.524896/model-00041-0.21414-0.94118-0.52864-0.80000.h5\n",
      "Epoch 42/50\n",
      "17/17 [==============================] - 16s 923ms/step - loss: 0.2493 - categorical_accuracy: 0.9204 - val_loss: 0.3873 - val_categorical_accuracy: 0.8833\n",
      "\n",
      "Epoch 00042: saving model to model_init_2019-12-2222_33_48.524896/model-00042-0.24927-0.92042-0.38730-0.88333.h5\n",
      "\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "Epoch 43/50\n",
      "17/17 [==============================] - 16s 954ms/step - loss: 0.2484 - categorical_accuracy: 0.9273 - val_loss: 0.6482 - val_categorical_accuracy: 0.7500\n",
      "\n",
      "Epoch 00043: saving model to model_init_2019-12-2222_33_48.524896/model-00043-0.24840-0.92734-0.64820-0.75000.h5\n",
      "Epoch 44/50\n",
      "17/17 [==============================] - 16s 953ms/step - loss: 0.1906 - categorical_accuracy: 0.9516 - val_loss: 0.4747 - val_categorical_accuracy: 0.8500\n",
      "\n",
      "Epoch 00044: saving model to model_init_2019-12-2222_33_48.524896/model-00044-0.19058-0.95156-0.47472-0.85000.h5\n",
      "\n",
      "Epoch 00044: ReduceLROnPlateau reducing learning rate to 1.525878978725359e-08.\n",
      "Epoch 45/50\n",
      "17/17 [==============================] - 16s 954ms/step - loss: 0.2770 - categorical_accuracy: 0.9100 - val_loss: 0.6362 - val_categorical_accuracy: 0.8167\n",
      "\n",
      "Epoch 00045: saving model to model_init_2019-12-2222_33_48.524896/model-00045-0.27700-0.91003-0.63618-0.81667.h5\n",
      "Epoch 46/50\n",
      "17/17 [==============================] - 16s 948ms/step - loss: 0.2487 - categorical_accuracy: 0.9273 - val_loss: 0.4758 - val_categorical_accuracy: 0.8000\n",
      "\n",
      "Epoch 00046: saving model to model_init_2019-12-2222_33_48.524896/model-00046-0.24866-0.92734-0.47581-0.80000.h5\n",
      "\n",
      "Epoch 00046: ReduceLROnPlateau reducing learning rate to 7.629394893626795e-09.\n",
      "Epoch 47/50\n",
      "17/17 [==============================] - 16s 942ms/step - loss: 0.2197 - categorical_accuracy: 0.9377 - val_loss: 0.5710 - val_categorical_accuracy: 0.7667\n",
      "\n",
      "Epoch 00047: saving model to model_init_2019-12-2222_33_48.524896/model-00047-0.21974-0.93772-0.57097-0.76667.h5\n",
      "Epoch 48/50\n",
      "17/17 [==============================] - 16s 923ms/step - loss: 0.2482 - categorical_accuracy: 0.9239 - val_loss: 0.5334 - val_categorical_accuracy: 0.8333\n",
      "\n",
      "Epoch 00048: saving model to model_init_2019-12-2222_33_48.524896/model-00048-0.24817-0.92388-0.53343-0.83333.h5\n",
      "\n",
      "Epoch 00048: ReduceLROnPlateau reducing learning rate to 3.814697446813398e-09.\n",
      "Epoch 49/50\n",
      "17/17 [==============================] - 15s 908ms/step - loss: 0.2498 - categorical_accuracy: 0.9066 - val_loss: 0.5645 - val_categorical_accuracy: 0.8000\n",
      "\n",
      "Epoch 00049: saving model to model_init_2019-12-2222_33_48.524896/model-00049-0.24975-0.90657-0.56451-0.80000.h5\n",
      "Epoch 50/50\n",
      "17/17 [==============================] - 17s 1s/step - loss: 0.2594 - categorical_accuracy: 0.9273 - val_loss: 0.4452 - val_categorical_accuracy: 0.8500\n",
      "\n",
      "Epoch 00050: saving model to model_init_2019-12-2222_33_48.524896/model-00050-0.25944-0.92734-0.44525-0.85000.h5\n",
      "\n",
      "Epoch 00050: ReduceLROnPlateau reducing learning rate to 1.907348723406699e-09.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7efb61f4a7f0>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model10.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Epoch 29/50\n",
    "17/17 [==============================] - 16s 944ms/step - loss: 0.2686 - categorical_accuracy: 0.9031 - val_loss: 0.3631 - val_categorical_accuracy: 0.8833\n",
    "\n",
    "Epoch 00029: saving model to model_init_2019-12-2222_33_48.524896/model-00029-0.26855-0.90311-0.36314-0.88333.h5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 11: Increasing the no of neurons in the dense layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def get_conv3d_model_i():\n",
    "\n",
    "# # Define model\n",
    "#     model = Sequential()\n",
    "\n",
    "#     model.add(Conv3D(16, kernel_size=(3,3,3), input_shape=input_shape,padding='same'))\n",
    "#     model.add(Activation('relu'))\n",
    "#     model.add(BatchNormalization())\n",
    "#     model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "#     model.add(Conv3D(32, kernel_size=(3,3,3), padding='same'))\n",
    "#     model.add(Activation('relu'))\n",
    "#     model.add(BatchNormalization())\n",
    "#     model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "   \n",
    "\n",
    "#     model.add(Conv3D(64, kernel_size=(3,3,3), padding='same'))\n",
    "#     model.add(Activation('relu'))\n",
    "#     model.add(BatchNormalization())\n",
    "#     model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "   \n",
    "#     model.add(Conv3D(128, kernel_size=(3,3,3), padding='same'))\n",
    "#     model.add(Activation('relu'))\n",
    "#     model.add(BatchNormalization())\n",
    "#     model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "   \n",
    "#     #Flatten Layers\n",
    "#     model.add(Flatten())\n",
    "#     model.add(Dense(512, activation='relu'))\n",
    "#     model.add(Dropout(0.50))\n",
    "\n",
    "#     #softmax layer\n",
    "#     model.add(Dense(5, activation='softmax'))\n",
    "\n",
    "\n",
    "#     optimiser = optimizers.Adam(lr=0.001)\n",
    "#     model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "#     print (model.summary())\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_size= 40 ,num_frames= 16 ,num_rows= 60 ,num_cols= 60 ,num_epochs= 50\n"
     ]
    }
   ],
   "source": [
    "# # Set Hyperparameters for the model\n",
    "# set_hyper_parameters(batchSize=40, numFrames=16, numRows=60, numCols=60, numEpochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steps_per_epoch= 17 validation_steps= 3\n"
     ]
    }
   ],
   "source": [
    "# set_train_validation_steps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_29 (Conv3D)           (None, 16, 60, 60, 16)    1312      \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 16, 60, 60, 16)    0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_29 (Batc (None, 16, 60, 60, 16)    64        \n",
      "_________________________________________________________________\n",
      "max_pooling3d_26 (MaxPooling (None, 8, 30, 30, 16)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_30 (Conv3D)           (None, 8, 30, 30, 32)     13856     \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 8, 30, 30, 32)     0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_30 (Batc (None, 8, 30, 30, 32)     128       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_27 (MaxPooling (None, 4, 15, 15, 32)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_31 (Conv3D)           (None, 4, 15, 15, 64)     55360     \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 4, 15, 15, 64)     0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_31 (Batc (None, 4, 15, 15, 64)     256       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_28 (MaxPooling (None, 2, 7, 7, 64)       0         \n",
      "_________________________________________________________________\n",
      "conv3d_32 (Conv3D)           (None, 2, 7, 7, 128)      221312    \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 2, 7, 7, 128)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_32 (Batc (None, 2, 7, 7, 128)      512       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_29 (MaxPooling (None, 1, 3, 3, 128)      0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 512)               590336    \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 5)                 2565      \n",
      "=================================================================\n",
      "Total params: 885,701\n",
      "Trainable params: 885,221\n",
      "Non-trainable params: 480\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# model11 = get_conv3d_model_i()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # create generators: Let us create the `train_generator` and the `val_generator` which will be used in `.fit_generator`.\n",
    "# train_generator = generator(train_path, train_doc, batch_size)\n",
    "# val_generator = generator(val_path, val_doc, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source path =  Project_data/val Source path =  ; batch size = 40\n",
      "Project_data/train ; batch size = 40\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:13: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "  del sys.path[0]\n",
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:21: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2/17 [==>...........................] - ETA: 44s - loss: 5.2984 - categorical_accuracy: 0.2000 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:44: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:53: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 40s 2s/step - loss: 3.3401 - categorical_accuracy: 0.3594 - val_loss: 2.0814 - val_categorical_accuracy: 0.5000\n",
      "\n",
      "Epoch 00001: saving model to model_init_2019-12-2222_33_48.524896/model-00001-3.39555-0.35445-2.08136-0.50000.h5\n",
      "Epoch 2/50\n",
      "17/17 [==============================] - 21s 1s/step - loss: 1.4316 - categorical_accuracy: 0.5166 - val_loss: 1.1717 - val_categorical_accuracy: 0.6333\n",
      "\n",
      "Epoch 00002: saving model to model_init_2019-12-2222_33_48.524896/model-00002-1.43162-0.51662-1.17174-0.63333.h5\n",
      "Epoch 3/50\n",
      "17/17 [==============================] - 21s 1s/step - loss: 1.2323 - categorical_accuracy: 0.5700 - val_loss: 1.1938 - val_categorical_accuracy: 0.5667\n",
      "\n",
      "Epoch 00003: saving model to model_init_2019-12-2222_33_48.524896/model-00003-1.24640-0.56676-1.19376-0.56667.h5\n",
      "Epoch 4/50\n",
      "17/17 [==============================] - 17s 992ms/step - loss: 0.9407 - categorical_accuracy: 0.6563 - val_loss: 0.9811 - val_categorical_accuracy: 0.5833\n",
      "\n",
      "Epoch 00004: saving model to model_init_2019-12-2222_33_48.524896/model-00004-0.94070-0.65635-0.98109-0.58333.h5\n",
      "Epoch 5/50\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.0072 - categorical_accuracy: 0.6378 - val_loss: 1.0535 - val_categorical_accuracy: 0.6000\n",
      "\n",
      "Epoch 00005: saving model to model_init_2019-12-2222_33_48.524896/model-00005-1.01141-0.63578-1.05347-0.60000.h5\n",
      "Epoch 6/50\n",
      "17/17 [==============================] - 16s 932ms/step - loss: 0.8592 - categorical_accuracy: 0.6920 - val_loss: 1.0605 - val_categorical_accuracy: 0.5333\n",
      "\n",
      "Epoch 00006: saving model to model_init_2019-12-2222_33_48.524896/model-00006-0.85915-0.69204-1.06051-0.53333.h5\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 7/50\n",
      "17/17 [==============================] - 16s 921ms/step - loss: 0.7106 - categorical_accuracy: 0.7163 - val_loss: 1.1734 - val_categorical_accuracy: 0.5333\n",
      "\n",
      "Epoch 00007: saving model to model_init_2019-12-2222_33_48.524896/model-00007-0.71057-0.71626-1.17342-0.53333.h5\n",
      "Epoch 8/50\n",
      "17/17 [==============================] - 15s 910ms/step - loss: 0.6411 - categorical_accuracy: 0.7647 - val_loss: 0.5806 - val_categorical_accuracy: 0.7833\n",
      "\n",
      "Epoch 00008: saving model to model_init_2019-12-2222_33_48.524896/model-00008-0.64113-0.76471-0.58064-0.78333.h5\n",
      "Epoch 9/50\n",
      "17/17 [==============================] - 16s 936ms/step - loss: 0.5737 - categorical_accuracy: 0.7543 - val_loss: 1.1016 - val_categorical_accuracy: 0.6333\n",
      "\n",
      "Epoch 00009: saving model to model_init_2019-12-2222_33_48.524896/model-00009-0.57374-0.75433-1.10162-0.63333.h5\n",
      "Epoch 10/50\n",
      "17/17 [==============================] - 16s 969ms/step - loss: 0.4835 - categorical_accuracy: 0.8339 - val_loss: 0.8263 - val_categorical_accuracy: 0.6833\n",
      "\n",
      "Epoch 00010: saving model to model_init_2019-12-2222_33_48.524896/model-00010-0.48351-0.83391-0.82630-0.68333.h5\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 11/50\n",
      "17/17 [==============================] - 16s 936ms/step - loss: 0.3790 - categorical_accuracy: 0.8616 - val_loss: 0.8278 - val_categorical_accuracy: 0.7000\n",
      "\n",
      "Epoch 00011: saving model to model_init_2019-12-2222_33_48.524896/model-00011-0.37900-0.86159-0.82784-0.70000.h5\n",
      "Epoch 12/50\n",
      "17/17 [==============================] - 16s 939ms/step - loss: 0.3796 - categorical_accuracy: 0.8512 - val_loss: 0.7802 - val_categorical_accuracy: 0.7167\n",
      "\n",
      "Epoch 00012: saving model to model_init_2019-12-2222_33_48.524896/model-00012-0.37963-0.85121-0.78025-0.71667.h5\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 13/50\n",
      "17/17 [==============================] - 16s 946ms/step - loss: 0.2687 - categorical_accuracy: 0.9066 - val_loss: 0.5955 - val_categorical_accuracy: 0.7667\n",
      "\n",
      "Epoch 00013: saving model to model_init_2019-12-2222_33_48.524896/model-00013-0.26874-0.90657-0.59550-0.76667.h5\n",
      "Epoch 14/50\n",
      "17/17 [==============================] - 15s 906ms/step - loss: 0.2667 - categorical_accuracy: 0.9170 - val_loss: 0.6407 - val_categorical_accuracy: 0.7833\n",
      "\n",
      "Epoch 00014: saving model to model_init_2019-12-2222_33_48.524896/model-00014-0.26675-0.91696-0.64072-0.78333.h5\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 15/50\n",
      "17/17 [==============================] - 16s 938ms/step - loss: 0.2292 - categorical_accuracy: 0.9308 - val_loss: 0.6564 - val_categorical_accuracy: 0.8167\n",
      "\n",
      "Epoch 00015: saving model to model_init_2019-12-2222_33_48.524896/model-00015-0.22916-0.93080-0.65638-0.81667.h5\n",
      "Epoch 16/50\n",
      "17/17 [==============================] - 16s 947ms/step - loss: 0.2035 - categorical_accuracy: 0.9377 - val_loss: 0.6793 - val_categorical_accuracy: 0.8167\n",
      "\n",
      "Epoch 00016: saving model to model_init_2019-12-2222_33_48.524896/model-00016-0.20350-0.93772-0.67933-0.81667.h5\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 17/50\n",
      "17/17 [==============================] - 16s 915ms/step - loss: 0.2064 - categorical_accuracy: 0.9239 - val_loss: 0.6642 - val_categorical_accuracy: 0.8167\n",
      "\n",
      "Epoch 00017: saving model to model_init_2019-12-2222_33_48.524896/model-00017-0.20639-0.92388-0.66417-0.81667.h5\n",
      "Epoch 18/50\n",
      "17/17 [==============================] - 16s 935ms/step - loss: 0.2145 - categorical_accuracy: 0.9239 - val_loss: 0.6320 - val_categorical_accuracy: 0.8500\n",
      "\n",
      "Epoch 00018: saving model to model_init_2019-12-2222_33_48.524896/model-00018-0.21447-0.92388-0.63199-0.85000.h5\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 19/50\n",
      "17/17 [==============================] - 15s 901ms/step - loss: 0.2356 - categorical_accuracy: 0.8962 - val_loss: 0.5951 - val_categorical_accuracy: 0.8167\n",
      "\n",
      "Epoch 00019: saving model to model_init_2019-12-2222_33_48.524896/model-00019-0.23562-0.89619-0.59505-0.81667.h5\n",
      "Epoch 20/50\n",
      "17/17 [==============================] - 16s 950ms/step - loss: 0.1948 - categorical_accuracy: 0.9377 - val_loss: 0.6769 - val_categorical_accuracy: 0.7500\n",
      "\n",
      "Epoch 00020: saving model to model_init_2019-12-2222_33_48.524896/model-00020-0.19483-0.93772-0.67687-0.75000.h5\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "Epoch 21/50\n",
      "17/17 [==============================] - 16s 958ms/step - loss: 0.2051 - categorical_accuracy: 0.9273 - val_loss: 0.4658 - val_categorical_accuracy: 0.8833\n",
      "\n",
      "Epoch 00021: saving model to model_init_2019-12-2222_33_48.524896/model-00021-0.20505-0.92734-0.46585-0.88333.h5\n",
      "Epoch 22/50\n",
      "17/17 [==============================] - 16s 923ms/step - loss: 0.2132 - categorical_accuracy: 0.9204 - val_loss: 0.7394 - val_categorical_accuracy: 0.7667\n",
      "\n",
      "Epoch 00022: saving model to model_init_2019-12-2222_33_48.524896/model-00022-0.21324-0.92042-0.73937-0.76667.h5\n",
      "Epoch 23/50\n",
      "17/17 [==============================] - 16s 945ms/step - loss: 0.1847 - categorical_accuracy: 0.9446 - val_loss: 0.3847 - val_categorical_accuracy: 0.9000\n",
      "\n",
      "Epoch 00023: saving model to model_init_2019-12-2222_33_48.524896/model-00023-0.18473-0.94464-0.38475-0.90000.h5\n",
      "Epoch 24/50\n",
      "17/17 [==============================] - 15s 901ms/step - loss: 0.1962 - categorical_accuracy: 0.9239 - val_loss: 0.6547 - val_categorical_accuracy: 0.7667\n",
      "\n",
      "Epoch 00024: saving model to model_init_2019-12-2222_33_48.524896/model-00024-0.19625-0.92388-0.65471-0.76667.h5\n",
      "Epoch 25/50\n",
      "17/17 [==============================] - 16s 970ms/step - loss: 0.1909 - categorical_accuracy: 0.9550 - val_loss: 0.5305 - val_categorical_accuracy: 0.8833\n",
      "\n",
      "Epoch 00025: saving model to model_init_2019-12-2222_33_48.524896/model-00025-0.19092-0.95502-0.53054-0.88333.h5\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "Epoch 26/50\n",
      "17/17 [==============================] - 16s 920ms/step - loss: 0.1870 - categorical_accuracy: 0.9377 - val_loss: 0.6731 - val_categorical_accuracy: 0.7833\n",
      "\n",
      "Epoch 00026: saving model to model_init_2019-12-2222_33_48.524896/model-00026-0.18698-0.93772-0.67310-0.78333.h5\n",
      "Epoch 27/50\n",
      "17/17 [==============================] - 15s 908ms/step - loss: 0.1844 - categorical_accuracy: 0.9481 - val_loss: 0.6209 - val_categorical_accuracy: 0.8000\n",
      "\n",
      "Epoch 00027: saving model to model_init_2019-12-2222_33_48.524896/model-00027-0.18436-0.94810-0.62090-0.80000.h5\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "Epoch 28/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 17s 973ms/step - loss: 0.1670 - categorical_accuracy: 0.9654 - val_loss: 0.6970 - val_categorical_accuracy: 0.8000\n",
      "\n",
      "Epoch 00028: saving model to model_init_2019-12-2222_33_48.524896/model-00028-0.16699-0.96540-0.69698-0.80000.h5\n",
      "Epoch 29/50\n",
      "17/17 [==============================] - 16s 924ms/step - loss: 0.2150 - categorical_accuracy: 0.9377 - val_loss: 0.4993 - val_categorical_accuracy: 0.8167\n",
      "\n",
      "Epoch 00029: saving model to model_init_2019-12-2222_33_48.524896/model-00029-0.21503-0.93772-0.49935-0.81667.h5\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "Epoch 30/50\n",
      "17/17 [==============================] - 16s 941ms/step - loss: 0.1743 - categorical_accuracy: 0.9481 - val_loss: 0.5082 - val_categorical_accuracy: 0.8000\n",
      "\n",
      "Epoch 00030: saving model to model_init_2019-12-2222_33_48.524896/model-00030-0.17432-0.94810-0.50818-0.80000.h5\n",
      "Epoch 31/50\n",
      "17/17 [==============================] - 16s 944ms/step - loss: 0.2066 - categorical_accuracy: 0.9481 - val_loss: 0.6682 - val_categorical_accuracy: 0.8167\n",
      "\n",
      "Epoch 00031: saving model to model_init_2019-12-2222_33_48.524896/model-00031-0.20662-0.94810-0.66818-0.81667.h5\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "Epoch 32/50\n",
      "17/17 [==============================] - 16s 940ms/step - loss: 0.1553 - categorical_accuracy: 0.9654 - val_loss: 0.5327 - val_categorical_accuracy: 0.8333\n",
      "\n",
      "Epoch 00032: saving model to model_init_2019-12-2222_33_48.524896/model-00032-0.15527-0.96540-0.53267-0.83333.h5\n",
      "Epoch 33/50\n",
      "17/17 [==============================] - 15s 874ms/step - loss: 0.1781 - categorical_accuracy: 0.9481 - val_loss: 0.6125 - val_categorical_accuracy: 0.8000\n",
      "\n",
      "Epoch 00033: saving model to model_init_2019-12-2222_33_48.524896/model-00033-0.17808-0.94810-0.61250-0.80000.h5\n",
      "\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "Epoch 34/50\n",
      "17/17 [==============================] - 17s 978ms/step - loss: 0.1718 - categorical_accuracy: 0.9446 - val_loss: 0.6737 - val_categorical_accuracy: 0.8000\n",
      "\n",
      "Epoch 00034: saving model to model_init_2019-12-2222_33_48.524896/model-00034-0.17178-0.94464-0.67372-0.80000.h5\n",
      "Epoch 35/50\n",
      "17/17 [==============================] - 16s 965ms/step - loss: 0.1804 - categorical_accuracy: 0.9446 - val_loss: 0.6128 - val_categorical_accuracy: 0.8167\n",
      "\n",
      "Epoch 00035: saving model to model_init_2019-12-2222_33_48.524896/model-00035-0.18045-0.94464-0.61277-0.81667.h5\n",
      "\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "Epoch 36/50\n",
      "17/17 [==============================] - 16s 943ms/step - loss: 0.1921 - categorical_accuracy: 0.9377 - val_loss: 0.5718 - val_categorical_accuracy: 0.7833\n",
      "\n",
      "Epoch 00036: saving model to model_init_2019-12-2222_33_48.524896/model-00036-0.19214-0.93772-0.57185-0.78333.h5\n",
      "Epoch 37/50\n",
      "17/17 [==============================] - 16s 913ms/step - loss: 0.1704 - categorical_accuracy: 0.9550 - val_loss: 0.4979 - val_categorical_accuracy: 0.8000\n",
      "\n",
      "Epoch 00037: saving model to model_init_2019-12-2222_33_48.524896/model-00037-0.17038-0.95502-0.49793-0.80000.h5\n",
      "\n",
      "Epoch 00037: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "Epoch 38/50\n",
      "17/17 [==============================] - 16s 928ms/step - loss: 0.1761 - categorical_accuracy: 0.9654 - val_loss: 0.6854 - val_categorical_accuracy: 0.8167\n",
      "\n",
      "Epoch 00038: saving model to model_init_2019-12-2222_33_48.524896/model-00038-0.17611-0.96540-0.68538-0.81667.h5\n",
      "Epoch 39/50\n",
      "17/17 [==============================] - 16s 936ms/step - loss: 0.1871 - categorical_accuracy: 0.9412 - val_loss: 0.6136 - val_categorical_accuracy: 0.8000\n",
      "\n",
      "Epoch 00039: saving model to model_init_2019-12-2222_33_48.524896/model-00039-0.18711-0.94118-0.61361-0.80000.h5\n",
      "\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "Epoch 40/50\n",
      "17/17 [==============================] - 17s 977ms/step - loss: 0.1718 - categorical_accuracy: 0.9516 - val_loss: 0.5959 - val_categorical_accuracy: 0.8000\n",
      "\n",
      "Epoch 00040: saving model to model_init_2019-12-2222_33_48.524896/model-00040-0.17184-0.95156-0.59592-0.80000.h5\n",
      "Epoch 41/50\n",
      "17/17 [==============================] - 16s 936ms/step - loss: 0.1567 - categorical_accuracy: 0.9585 - val_loss: 0.6202 - val_categorical_accuracy: 0.7833\n",
      "\n",
      "Epoch 00041: saving model to model_init_2019-12-2222_33_48.524896/model-00041-0.15672-0.95848-0.62024-0.78333.h5\n",
      "\n",
      "Epoch 00041: ReduceLROnPlateau reducing learning rate to 1.525878978725359e-08.\n",
      "Epoch 42/50\n",
      "17/17 [==============================] - 15s 904ms/step - loss: 0.2317 - categorical_accuracy: 0.9273 - val_loss: 0.7243 - val_categorical_accuracy: 0.7500\n",
      "\n",
      "Epoch 00042: saving model to model_init_2019-12-2222_33_48.524896/model-00042-0.23169-0.92734-0.72427-0.75000.h5\n",
      "Epoch 43/50\n",
      "17/17 [==============================] - 16s 946ms/step - loss: 0.2251 - categorical_accuracy: 0.9377 - val_loss: 0.5308 - val_categorical_accuracy: 0.8167\n",
      "\n",
      "Epoch 00043: saving model to model_init_2019-12-2222_33_48.524896/model-00043-0.22512-0.93772-0.53082-0.81667.h5\n",
      "\n",
      "Epoch 00043: ReduceLROnPlateau reducing learning rate to 7.629394893626795e-09.\n",
      "Epoch 44/50\n",
      "17/17 [==============================] - 16s 957ms/step - loss: 0.1833 - categorical_accuracy: 0.9446 - val_loss: 0.4858 - val_categorical_accuracy: 0.8500\n",
      "\n",
      "Epoch 00044: saving model to model_init_2019-12-2222_33_48.524896/model-00044-0.18326-0.94464-0.48575-0.85000.h5\n",
      "Epoch 45/50\n",
      "17/17 [==============================] - 15s 893ms/step - loss: 0.1794 - categorical_accuracy: 0.9377 - val_loss: 0.6089 - val_categorical_accuracy: 0.8000\n",
      "\n",
      "Epoch 00045: saving model to model_init_2019-12-2222_33_48.524896/model-00045-0.17937-0.93772-0.60890-0.80000.h5\n",
      "\n",
      "Epoch 00045: ReduceLROnPlateau reducing learning rate to 3.814697446813398e-09.\n",
      "Epoch 46/50\n",
      "17/17 [==============================] - 16s 934ms/step - loss: 0.1994 - categorical_accuracy: 0.9412 - val_loss: 0.6720 - val_categorical_accuracy: 0.7833\n",
      "\n",
      "Epoch 00046: saving model to model_init_2019-12-2222_33_48.524896/model-00046-0.19936-0.94118-0.67199-0.78333.h5\n",
      "Epoch 47/50\n",
      "17/17 [==============================] - 16s 924ms/step - loss: 0.1781 - categorical_accuracy: 0.9585 - val_loss: 0.6342 - val_categorical_accuracy: 0.7833\n",
      "\n",
      "Epoch 00047: saving model to model_init_2019-12-2222_33_48.524896/model-00047-0.17811-0.95848-0.63420-0.78333.h5\n",
      "\n",
      "Epoch 00047: ReduceLROnPlateau reducing learning rate to 1.907348723406699e-09.\n",
      "Epoch 48/50\n",
      "17/17 [==============================] - 16s 941ms/step - loss: 0.1820 - categorical_accuracy: 0.9446 - val_loss: 0.6970 - val_categorical_accuracy: 0.8000\n",
      "\n",
      "Epoch 00048: saving model to model_init_2019-12-2222_33_48.524896/model-00048-0.18195-0.94464-0.69702-0.80000.h5\n",
      "Epoch 49/50\n",
      "17/17 [==============================] - 16s 927ms/step - loss: 0.1960 - categorical_accuracy: 0.9412 - val_loss: 0.5367 - val_categorical_accuracy: 0.7667\n",
      "\n",
      "Epoch 00049: saving model to model_init_2019-12-2222_33_48.524896/model-00049-0.19604-0.94118-0.53668-0.76667.h5\n",
      "\n",
      "Epoch 00049: ReduceLROnPlateau reducing learning rate to 9.536743617033494e-10.\n",
      "Epoch 50/50\n",
      "17/17 [==============================] - 16s 950ms/step - loss: 0.1826 - categorical_accuracy: 0.9412 - val_loss: 0.6456 - val_categorical_accuracy: 0.8333\n",
      "\n",
      "Epoch 00050: saving model to model_init_2019-12-2222_33_48.524896/model-00050-0.18258-0.94118-0.64562-0.83333.h5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7efb54bf4a90>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model11.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "#                     callbacks=callbacks_list, validation_data=val_generator, \n",
    "#                     validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Epoch 23/50\n",
    "17/17 [==============================] - 16s 945ms/step - loss: 0.1847 - categorical_accuracy: 0.9446 - val_loss: 0.3847 - val_categorical_accuracy: 0.9000\n",
    "\n",
    "Epoch 00023: saving model to model_init_2019-12-2222_33_48.524896/model-00023-0.18473-0.94464-0.38475-0.90000.h5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 12: Increasing the no of parameters by increasing image size to 100X100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def get_conv3d_model_j():\n",
    "\n",
    "# # Define model\n",
    "#     model = Sequential()\n",
    "\n",
    "#     model.add(Conv3D(16, kernel_size=(3,3,3), input_shape=input_shape,padding='same'))\n",
    "#     model.add(Activation('relu'))\n",
    "#     model.add(BatchNormalization())\n",
    "#     model.add(MaxPooling3D(pool_size=(2,2,2)))\n",
    "\n",
    "#     model.add(Conv3D(32, kernel_size=(3,3,3), padding='same'))\n",
    "#     model.add(Activation('relu'))\n",
    "#     model.add(BatchNormalization())\n",
    "#     model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "   \n",
    "\n",
    "#     model.add(Conv3D(64, kernel_size=(3,3,3), padding='same'))\n",
    "#     model.add(Activation('relu'))\n",
    "#     model.add(BatchNormalization())\n",
    "#     model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "   \n",
    "#     model.add(Conv3D(128, kernel_size=(3,3,3), padding='same'))\n",
    "#     model.add(Activation('relu'))\n",
    "#     model.add(BatchNormalization())\n",
    "#     model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "   \n",
    "#     #Flatten Layers\n",
    "#     model.add(Flatten())\n",
    "#     model.add(Dense(512, activation='relu'))\n",
    "#     model.add(Dropout(0.60))\n",
    "\n",
    "#     #softmax layer\n",
    "#     model.add(Dense(5, activation='softmax'))\n",
    "\n",
    "\n",
    "#     optimiser = optimizers.Adam(lr=0.001)\n",
    "#     model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "#     print (model.summary())\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_size= 40 ,num_frames= 16 ,num_rows= 100 ,num_cols= 100 ,num_epochs= 50\n"
     ]
    }
   ],
   "source": [
    "# # Set Hyperparameters for the model\n",
    "# set_hyper_parameters(batchSize=40, numFrames=16, numRows=100, numCols=100, numEpochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steps_per_epoch= 17 validation_steps= 3\n"
     ]
    }
   ],
   "source": [
    "# set_train_validation_steps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_41 (Conv3D)           (None, 16, 100, 100, 16)  1312      \n",
      "_________________________________________________________________\n",
      "activation_41 (Activation)   (None, 16, 100, 100, 16)  0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_41 (Batc (None, 16, 100, 100, 16)  64        \n",
      "_________________________________________________________________\n",
      "max_pooling3d_38 (MaxPooling (None, 8, 50, 50, 16)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_42 (Conv3D)           (None, 8, 50, 50, 32)     13856     \n",
      "_________________________________________________________________\n",
      "activation_42 (Activation)   (None, 8, 50, 50, 32)     0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_42 (Batc (None, 8, 50, 50, 32)     128       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_39 (MaxPooling (None, 4, 25, 25, 32)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_43 (Conv3D)           (None, 4, 25, 25, 64)     55360     \n",
      "_________________________________________________________________\n",
      "activation_43 (Activation)   (None, 4, 25, 25, 64)     0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_43 (Batc (None, 4, 25, 25, 64)     256       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_40 (MaxPooling (None, 2, 12, 12, 64)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_44 (Conv3D)           (None, 2, 12, 12, 128)    221312    \n",
      "_________________________________________________________________\n",
      "activation_44 (Activation)   (None, 2, 12, 12, 128)    0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_44 (Batc (None, 2, 12, 12, 128)    512       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_41 (MaxPooling (None, 1, 6, 6, 128)      0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 512)               2359808   \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 5)                 2565      \n",
      "=================================================================\n",
      "Total params: 2,655,173\n",
      "Trainable params: 2,654,693\n",
      "Non-trainable params: 480\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# model12 = get_conv3d_model_j()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # create generators: Let us create the `train_generator` and the `val_generator` which will be used in `.fit_generator`.\n",
    "# train_generator = generator(train_path, train_doc, batch_size)\n",
    "# val_generator = generator(val_path, val_doc, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source path =  Project_data/val ; batch size = 40\n",
      "Source path =  Project_data/train ; batch size = 40\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:13: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "  del sys.path[0]\n",
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:21: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n",
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:44: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:53: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 45s 3s/step - loss: 8.0675 - categorical_accuracy: 0.2989 - val_loss: 7.8148 - val_categorical_accuracy: 0.3800\n",
      "\n",
      "Epoch 00001: saving model to model_init_2019-12-2222_33_48.524896/model-00001-8.11345-0.29563-7.81476-0.38000.h5\n",
      "Epoch 2/50\n",
      "17/17 [==============================] - 20s 1s/step - loss: 4.8926 - categorical_accuracy: 0.4041 - val_loss: 4.0570 - val_categorical_accuracy: 0.4833\n",
      "\n",
      "Epoch 00002: saving model to model_init_2019-12-2222_33_48.524896/model-00002-4.89258-0.40409-4.05696-0.48333.h5\n",
      "Epoch 3/50\n",
      "17/17 [==============================] - 22s 1s/step - loss: 4.4898 - categorical_accuracy: 0.4633 - val_loss: 4.7583 - val_categorical_accuracy: 0.5333\n",
      "\n",
      "Epoch 00003: saving model to model_init_2019-12-2222_33_48.524896/model-00003-4.50573-0.46049-4.75830-0.53333.h5\n",
      "Epoch 4/50\n",
      "17/17 [==============================] - 19s 1s/step - loss: 3.6875 - categorical_accuracy: 0.4489 - val_loss: 9.9204 - val_categorical_accuracy: 0.3000\n",
      "\n",
      "Epoch 00004: saving model to model_init_2019-12-2222_33_48.524896/model-00004-3.68749-0.44892-9.92036-0.30000.h5\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 5/50\n",
      "17/17 [==============================] - 20s 1s/step - loss: 2.5025 - categorical_accuracy: 0.5513 - val_loss: 4.0607 - val_categorical_accuracy: 0.6167\n",
      "\n",
      "Epoch 00005: saving model to model_init_2019-12-2222_33_48.524896/model-00005-2.53080-0.54633-4.06074-0.61667.h5\n",
      "Epoch 6/50\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.8435 - categorical_accuracy: 0.6055 - val_loss: 4.5819 - val_categorical_accuracy: 0.4833\n",
      "\n",
      "Epoch 00006: saving model to model_init_2019-12-2222_33_48.524896/model-00006-1.84347-0.60554-4.58187-0.48333.h5\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 7/50\n",
      "17/17 [==============================] - 18s 1s/step - loss: 2.0220 - categorical_accuracy: 0.5536 - val_loss: 5.1557 - val_categorical_accuracy: 0.5833\n",
      "\n",
      "Epoch 00007: saving model to model_init_2019-12-2222_33_48.524896/model-00007-2.02201-0.55363-5.15570-0.58333.h5\n",
      "Epoch 8/50\n",
      "17/17 [==============================] - 17s 992ms/step - loss: 1.1801 - categorical_accuracy: 0.6263 - val_loss: 1.3776 - val_categorical_accuracy: 0.5667\n",
      "\n",
      "Epoch 00008: saving model to model_init_2019-12-2222_33_48.524896/model-00008-1.18011-0.62630-1.37761-0.56667.h5\n",
      "Epoch 9/50\n",
      "17/17 [==============================] - 19s 1s/step - loss: 1.1166 - categorical_accuracy: 0.6747 - val_loss: 1.6462 - val_categorical_accuracy: 0.6167\n",
      "\n",
      "Epoch 00009: saving model to model_init_2019-12-2222_33_48.524896/model-00009-1.11657-0.67474-1.64623-0.61667.h5\n",
      "Epoch 10/50\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.1768 - categorical_accuracy: 0.7266 - val_loss: 1.8367 - val_categorical_accuracy: 0.6167\n",
      "\n",
      "Epoch 00010: saving model to model_init_2019-12-2222_33_48.524896/model-00010-1.17682-0.72664-1.83666-0.61667.h5\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 11/50\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.1897 - categorical_accuracy: 0.6851 - val_loss: 1.2934 - val_categorical_accuracy: 0.6333\n",
      "\n",
      "Epoch 00011: saving model to model_init_2019-12-2222_33_48.524896/model-00011-1.18970-0.68512-1.29343-0.63333.h5\n",
      "Epoch 12/50\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.0409 - categorical_accuracy: 0.7197 - val_loss: 0.9065 - val_categorical_accuracy: 0.7333\n",
      "\n",
      "Epoch 00012: saving model to model_init_2019-12-2222_33_48.524896/model-00012-1.04095-0.71972-0.90646-0.73333.h5\n",
      "Epoch 13/50\n",
      "17/17 [==============================] - 18s 1s/step - loss: 0.9629 - categorical_accuracy: 0.6990 - val_loss: 1.1671 - val_categorical_accuracy: 0.7333\n",
      "\n",
      "Epoch 00013: saving model to model_init_2019-12-2222_33_48.524896/model-00013-0.96289-0.69896-1.16707-0.73333.h5\n",
      "Epoch 14/50\n",
      "17/17 [==============================] - 18s 1s/step - loss: 0.9321 - categorical_accuracy: 0.7093 - val_loss: 0.6359 - val_categorical_accuracy: 0.8167\n",
      "\n",
      "Epoch 00014: saving model to model_init_2019-12-2222_33_48.524896/model-00014-0.93208-0.70934-0.63595-0.81667.h5\n",
      "Epoch 15/50\n",
      "17/17 [==============================] - 18s 1s/step - loss: 0.7766 - categorical_accuracy: 0.7820 - val_loss: 0.7315 - val_categorical_accuracy: 0.7333\n",
      "\n",
      "Epoch 00015: saving model to model_init_2019-12-2222_33_48.524896/model-00015-0.77656-0.78201-0.73148-0.73333.h5\n",
      "Epoch 16/50\n",
      "17/17 [==============================] - 18s 1s/step - loss: 0.6996 - categorical_accuracy: 0.8028 - val_loss: 0.8150 - val_categorical_accuracy: 0.7500\n",
      "\n",
      "Epoch 00016: saving model to model_init_2019-12-2222_33_48.524896/model-00016-0.69963-0.80277-0.81500-0.75000.h5\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 17/50\n",
      "17/17 [==============================] - 18s 1s/step - loss: 0.6235 - categorical_accuracy: 0.8062 - val_loss: 0.5324 - val_categorical_accuracy: 0.8167\n",
      "\n",
      "Epoch 00017: saving model to model_init_2019-12-2222_33_48.524896/model-00017-0.62354-0.80623-0.53239-0.81667.h5\n",
      "Epoch 18/50\n",
      "17/17 [==============================] - 17s 1s/step - loss: 0.6205 - categorical_accuracy: 0.7889 - val_loss: 0.9056 - val_categorical_accuracy: 0.8000\n",
      "\n",
      "Epoch 00018: saving model to model_init_2019-12-2222_33_48.524896/model-00018-0.62048-0.78893-0.90560-0.80000.h5\n",
      "Epoch 19/50\n",
      "17/17 [==============================] - 18s 1s/step - loss: 0.7362 - categorical_accuracy: 0.7855 - val_loss: 0.7968 - val_categorical_accuracy: 0.7500\n",
      "\n",
      "Epoch 00019: saving model to model_init_2019-12-2222_33_48.524896/model-00019-0.73625-0.78547-0.79680-0.75000.h5\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 20/50\n",
      "17/17 [==============================] - 18s 1s/step - loss: 0.7142 - categorical_accuracy: 0.7751 - val_loss: 0.6301 - val_categorical_accuracy: 0.8000\n",
      "\n",
      "Epoch 00020: saving model to model_init_2019-12-2222_33_48.524896/model-00020-0.71421-0.77509-0.63006-0.80000.h5\n",
      "Epoch 21/50\n",
      "17/17 [==============================] - 17s 1s/step - loss: 0.6597 - categorical_accuracy: 0.7716 - val_loss: 0.8852 - val_categorical_accuracy: 0.7833\n",
      "\n",
      "Epoch 00021: saving model to model_init_2019-12-2222_33_48.524896/model-00021-0.65972-0.77163-0.88524-0.78333.h5\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 22/50\n",
      "17/17 [==============================] - 17s 1s/step - loss: 0.7464 - categorical_accuracy: 0.7993 - val_loss: 0.6805 - val_categorical_accuracy: 0.8000\n",
      "\n",
      "Epoch 00022: saving model to model_init_2019-12-2222_33_48.524896/model-00022-0.74642-0.79931-0.68054-0.80000.h5\n",
      "Epoch 23/50\n",
      "17/17 [==============================] - 18s 1s/step - loss: 0.7020 - categorical_accuracy: 0.8062 - val_loss: 0.8561 - val_categorical_accuracy: 0.7833\n",
      "\n",
      "Epoch 00023: saving model to model_init_2019-12-2222_33_48.524896/model-00023-0.70196-0.80623-0.85605-0.78333.h5\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "Epoch 24/50\n",
      "17/17 [==============================] - 17s 1s/step - loss: 0.6078 - categorical_accuracy: 0.8062 - val_loss: 1.0480 - val_categorical_accuracy: 0.7000\n",
      "\n",
      "Epoch 00024: saving model to model_init_2019-12-2222_33_48.524896/model-00024-0.60784-0.80623-1.04803-0.70000.h5\n",
      "Epoch 25/50\n",
      "17/17 [==============================] - 19s 1s/step - loss: 0.7810 - categorical_accuracy: 0.7682 - val_loss: 0.7437 - val_categorical_accuracy: 0.7667\n",
      "\n",
      "Epoch 00025: saving model to model_init_2019-12-2222_33_48.524896/model-00025-0.78096-0.76817-0.74374-0.76667.h5\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "Epoch 26/50\n",
      "17/17 [==============================] - 19s 1s/step - loss: 0.5411 - categorical_accuracy: 0.8166 - val_loss: 0.6847 - val_categorical_accuracy: 0.8500\n",
      "\n",
      "Epoch 00026: saving model to model_init_2019-12-2222_33_48.524896/model-00026-0.54106-0.81661-0.68467-0.85000.h5\n",
      "Epoch 27/50\n",
      "17/17 [==============================] - 18s 1s/step - loss: 0.6241 - categorical_accuracy: 0.7820 - val_loss: 0.5229 - val_categorical_accuracy: 0.8167\n",
      "\n",
      "Epoch 00027: saving model to model_init_2019-12-2222_33_48.524896/model-00027-0.62406-0.78201-0.52291-0.81667.h5\n",
      "Epoch 28/50\n",
      "17/17 [==============================] - 18s 1s/step - loss: 0.6920 - categorical_accuracy: 0.7612 - val_loss: 0.9777 - val_categorical_accuracy: 0.7667\n",
      "\n",
      "Epoch 00028: saving model to model_init_2019-12-2222_33_48.524896/model-00028-0.69198-0.76125-0.97766-0.76667.h5\n",
      "Epoch 29/50\n",
      "17/17 [==============================] - 18s 1s/step - loss: 0.4494 - categorical_accuracy: 0.8339 - val_loss: 0.9602 - val_categorical_accuracy: 0.7667\n",
      "\n",
      "Epoch 00029: saving model to model_init_2019-12-2222_33_48.524896/model-00029-0.44944-0.83391-0.96016-0.76667.h5\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "Epoch 30/50\n",
      "17/17 [==============================] - 18s 1s/step - loss: 0.6314 - categorical_accuracy: 0.8270 - val_loss: 0.9191 - val_categorical_accuracy: 0.7667\n",
      "\n",
      "Epoch 00030: saving model to model_init_2019-12-2222_33_48.524896/model-00030-0.63140-0.82699-0.91911-0.76667.h5\n",
      "Epoch 31/50\n",
      "17/17 [==============================] - 18s 1s/step - loss: 0.5816 - categorical_accuracy: 0.8339 - val_loss: 0.6620 - val_categorical_accuracy: 0.7833\n",
      "\n",
      "Epoch 00031: saving model to model_init_2019-12-2222_33_48.524896/model-00031-0.58163-0.83391-0.66203-0.78333.h5\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "Epoch 32/50\n",
      "17/17 [==============================] - 18s 1s/step - loss: 0.6234 - categorical_accuracy: 0.7924 - val_loss: 0.6759 - val_categorical_accuracy: 0.8167\n",
      "\n",
      "Epoch 00032: saving model to model_init_2019-12-2222_33_48.524896/model-00032-0.62342-0.79239-0.67587-0.81667.h5\n",
      "Epoch 33/50\n",
      "17/17 [==============================] - 18s 1s/step - loss: 0.7833 - categorical_accuracy: 0.7751 - val_loss: 0.8054 - val_categorical_accuracy: 0.7667\n",
      "\n",
      "Epoch 00033: saving model to model_init_2019-12-2222_33_48.524896/model-00033-0.78328-0.77509-0.80545-0.76667.h5\n",
      "\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "Epoch 34/50\n",
      "17/17 [==============================] - 18s 1s/step - loss: 0.6569 - categorical_accuracy: 0.7958 - val_loss: 0.9031 - val_categorical_accuracy: 0.7667\n",
      "\n",
      "Epoch 00034: saving model to model_init_2019-12-2222_33_48.524896/model-00034-0.65687-0.79585-0.90314-0.76667.h5\n",
      "Epoch 35/50\n",
      "17/17 [==============================] - 18s 1s/step - loss: 0.5558 - categorical_accuracy: 0.8062 - val_loss: 1.0105 - val_categorical_accuracy: 0.7667\n",
      "\n",
      "Epoch 00035: saving model to model_init_2019-12-2222_33_48.524896/model-00035-0.55580-0.80623-1.01052-0.76667.h5\n",
      "\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "Epoch 36/50\n",
      "17/17 [==============================] - 18s 1s/step - loss: 0.6600 - categorical_accuracy: 0.7751 - val_loss: 0.6549 - val_categorical_accuracy: 0.7667\n",
      "\n",
      "Epoch 00036: saving model to model_init_2019-12-2222_33_48.524896/model-00036-0.65997-0.77509-0.65490-0.76667.h5\n",
      "Epoch 37/50\n",
      "17/17 [==============================] - 18s 1s/step - loss: 0.6121 - categorical_accuracy: 0.8166 - val_loss: 0.8468 - val_categorical_accuracy: 0.8167\n",
      "\n",
      "Epoch 00037: saving model to model_init_2019-12-2222_33_48.524896/model-00037-0.61206-0.81661-0.84676-0.81667.h5\n",
      "\n",
      "Epoch 00037: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "Epoch 38/50\n",
      "17/17 [==============================] - 18s 1s/step - loss: 0.4427 - categorical_accuracy: 0.8374 - val_loss: 0.6855 - val_categorical_accuracy: 0.7667\n",
      "\n",
      "Epoch 00038: saving model to model_init_2019-12-2222_33_48.524896/model-00038-0.44267-0.83737-0.68549-0.76667.h5\n",
      "Epoch 39/50\n",
      "17/17 [==============================] - 18s 1s/step - loss: 0.5447 - categorical_accuracy: 0.8374 - val_loss: 1.0000 - val_categorical_accuracy: 0.7333\n",
      "\n",
      "Epoch 00039: saving model to model_init_2019-12-2222_33_48.524896/model-00039-0.54471-0.83737-1.00002-0.73333.h5\n",
      "\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "Epoch 40/50\n",
      "17/17 [==============================] - 18s 1s/step - loss: 0.6211 - categorical_accuracy: 0.8235 - val_loss: 0.5359 - val_categorical_accuracy: 0.8333\n",
      "\n",
      "Epoch 00040: saving model to model_init_2019-12-2222_33_48.524896/model-00040-0.62107-0.82353-0.53591-0.83333.h5\n",
      "Epoch 41/50\n",
      "17/17 [==============================] - 18s 1s/step - loss: 0.5660 - categorical_accuracy: 0.8166 - val_loss: 0.9790 - val_categorical_accuracy: 0.7333\n",
      "\n",
      "Epoch 00041: saving model to model_init_2019-12-2222_33_48.524896/model-00041-0.56601-0.81661-0.97903-0.73333.h5\n",
      "\n",
      "Epoch 00041: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "Epoch 42/50\n",
      "17/17 [==============================] - 18s 1s/step - loss: 0.7129 - categorical_accuracy: 0.7889 - val_loss: 0.7518 - val_categorical_accuracy: 0.8333\n",
      "\n",
      "Epoch 00042: saving model to model_init_2019-12-2222_33_48.524896/model-00042-0.71288-0.78893-0.75183-0.83333.h5\n",
      "Epoch 43/50\n",
      "17/17 [==============================] - 17s 1s/step - loss: 0.6944 - categorical_accuracy: 0.7889 - val_loss: 0.9258 - val_categorical_accuracy: 0.7000\n",
      "\n",
      "Epoch 00043: saving model to model_init_2019-12-2222_33_48.524896/model-00043-0.69443-0.78893-0.92584-0.70000.h5\n",
      "\n",
      "Epoch 00043: ReduceLROnPlateau reducing learning rate to 1.525878978725359e-08.\n",
      "Epoch 44/50\n",
      "17/17 [==============================] - 18s 1s/step - loss: 0.7480 - categorical_accuracy: 0.7993 - val_loss: 0.8581 - val_categorical_accuracy: 0.8000\n",
      "\n",
      "Epoch 00044: saving model to model_init_2019-12-2222_33_48.524896/model-00044-0.74798-0.79931-0.85807-0.80000.h5\n",
      "Epoch 45/50\n",
      "17/17 [==============================] - 18s 1s/step - loss: 0.5193 - categorical_accuracy: 0.8304 - val_loss: 0.6675 - val_categorical_accuracy: 0.8000\n",
      "\n",
      "Epoch 00045: saving model to model_init_2019-12-2222_33_48.524896/model-00045-0.51930-0.83045-0.66749-0.80000.h5\n",
      "\n",
      "Epoch 00045: ReduceLROnPlateau reducing learning rate to 7.629394893626795e-09.\n",
      "Epoch 46/50\n",
      "17/17 [==============================] - 17s 1s/step - loss: 0.6796 - categorical_accuracy: 0.8166 - val_loss: 0.8514 - val_categorical_accuracy: 0.7667\n",
      "\n",
      "Epoch 00046: saving model to model_init_2019-12-2222_33_48.524896/model-00046-0.67963-0.81661-0.85142-0.76667.h5\n",
      "Epoch 47/50\n",
      "17/17 [==============================] - 18s 1s/step - loss: 0.6581 - categorical_accuracy: 0.7785 - val_loss: 0.9989 - val_categorical_accuracy: 0.7667\n",
      "\n",
      "Epoch 00047: saving model to model_init_2019-12-2222_33_48.524896/model-00047-0.65806-0.77855-0.99889-0.76667.h5\n",
      "\n",
      "Epoch 00047: ReduceLROnPlateau reducing learning rate to 3.814697446813398e-09.\n",
      "Epoch 48/50\n",
      "17/17 [==============================] - 18s 1s/step - loss: 0.6301 - categorical_accuracy: 0.7785 - val_loss: 0.6094 - val_categorical_accuracy: 0.7333\n",
      "\n",
      "Epoch 00048: saving model to model_init_2019-12-2222_33_48.524896/model-00048-0.63009-0.77855-0.60940-0.73333.h5\n",
      "Epoch 49/50\n",
      "17/17 [==============================] - 17s 990ms/step - loss: 0.5339 - categorical_accuracy: 0.7751 - val_loss: 0.9141 - val_categorical_accuracy: 0.7833\n",
      "\n",
      "Epoch 00049: saving model to model_init_2019-12-2222_33_48.524896/model-00049-0.53394-0.77509-0.91410-0.78333.h5\n",
      "\n",
      "Epoch 00049: ReduceLROnPlateau reducing learning rate to 1.907348723406699e-09.\n",
      "Epoch 50/50\n",
      "17/17 [==============================] - 18s 1s/step - loss: 0.5883 - categorical_accuracy: 0.8166 - val_loss: 0.5379 - val_categorical_accuracy: 0.8333\n",
      "\n",
      "Epoch 00050: saving model to model_init_2019-12-2222_33_48.524896/model-00050-0.58832-0.81661-0.53787-0.83333.h5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7efb57195cf8>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model12.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "#                     callbacks=callbacks_list, validation_data=val_generator, \n",
    "#                     validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Epoch 40/50\n",
    "17/17 [==============================] - 18s 1s/step - loss: 0.6211 - categorical_accuracy: 0.8235 - val_loss: 0.5359 - val_categorical_accuracy: 0.8333\n",
    "\n",
    "Epoch 00040: saving model to model_init_2019-12-2222_33_48.524896/model-00040-0.62107-0.82353-0.53591-0.83333.h5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 13 : CNN + LSTM Leveraging Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from keras.applications import mobilenet\n",
    "# base_model = mobilenet.MobileNet(input_shape=(128,128,3),weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def get_cnn_rnn_tl_model(gru_cells=64,dense_neurons=64,dropout=0.50):\n",
    "    \n",
    "#     # freeze the layers in base model\n",
    "#     for layer in base_model.layers:\n",
    "#         layer.trainable = False\n",
    "        \n",
    "#     model = Sequential()\n",
    "#     model.add(TimeDistributed(base_model, input_shape=input_shape))\n",
    "#     model.add(TimeDistributed(BatchNormalization()))\n",
    "#     model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "#     model.add(TimeDistributed(Flatten()))              \n",
    "    \n",
    "#     model.add(GRU(gru_cells))\n",
    "#     model.add(Dropout(dropout))\n",
    "        \n",
    "#     model.add(Dense(dense_neurons,activation='relu'))\n",
    "#     model.add(Dropout(dropout))\n",
    "    \n",
    "#     model.add(Dense(5, activation='softmax'))\n",
    "#     optimiser = optimizers.Adam()\n",
    "#     model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "#     print (model.summary())\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_size= 40 ,num_frames= 16 ,num_rows= 120 ,num_cols= 120 ,num_epochs= 25\n"
     ]
    }
   ],
   "source": [
    "# # Set Hyperparameters for the model\n",
    "# set_hyper_parameters(batchSize=40, numFrames=16, numRows=120, numCols=120, numEpochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 120, 120, 3)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steps_per_epoch= 17 validation_steps= 3\n"
     ]
    }
   ],
   "source": [
    "# set_train_validation_steps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "time_distributed_12 (TimeDis (None, 16, 3, 3, 1024)    3228864   \n",
      "_________________________________________________________________\n",
      "time_distributed_13 (TimeDis (None, 16, 3, 3, 1024)    4096      \n",
      "_________________________________________________________________\n",
      "time_distributed_14 (TimeDis (None, 16, 1, 1, 1024)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_15 (TimeDis (None, 16, 1024)          0         \n",
      "_________________________________________________________________\n",
      "gru_3 (GRU)                  (None, 64)                209088    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 5)                 325       \n",
      "=================================================================\n",
      "Total params: 3,446,533\n",
      "Trainable params: 215,621\n",
      "Non-trainable params: 3,230,912\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# model13 = get_cnn_rnn_tl_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # create generators: Let us create the `train_generator` and the `val_generator` which will be used in `.fit_generator`.\n",
    "# train_generator = generator(train_path, train_doc, batch_size)\n",
    "# val_generator = generator(val_path, val_doc, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source path =  Project_data/val ; batch size = 40\n",
      "Source path =  Project_data/train ; batch size = 40\n",
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:13: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "  del sys.path[0]\n",
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:21: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n",
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:44: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:53: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 47s 3s/step - loss: 1.8003 - categorical_accuracy: 0.2708 - val_loss: 1.6047 - val_categorical_accuracy: 0.2600\n",
      "\n",
      "Epoch 00001: saving model to model_init_2019-12-2303_29_20.233871/model-00001-1.80432-0.26998-1.60468-0.26000.h5\n",
      "Epoch 2/25\n",
      "17/17 [==============================] - 21s 1s/step - loss: 1.4966 - categorical_accuracy: 0.3478 - val_loss: 1.6014 - val_categorical_accuracy: 0.3333\n",
      "\n",
      "Epoch 00002: saving model to model_init_2019-12-2303_29_20.233871/model-00002-1.49660-0.34783-1.60135-0.33333.h5\n",
      "Epoch 3/25\n",
      "17/17 [==============================] - 22s 1s/step - loss: 1.3304 - categorical_accuracy: 0.4289 - val_loss: 1.2947 - val_categorical_accuracy: 0.5167\n",
      "\n",
      "Epoch 00003: saving model to model_init_2019-12-2303_29_20.233871/model-00003-1.33831-0.42507-1.29469-0.51667.h5\n",
      "Epoch 4/25\n",
      "17/17 [==============================] - 20s 1s/step - loss: 1.1578 - categorical_accuracy: 0.5449 - val_loss: 1.3918 - val_categorical_accuracy: 0.4000\n",
      "\n",
      "Epoch 00004: saving model to model_init_2019-12-2303_29_20.233871/model-00004-1.15777-0.54489-1.39179-0.40000.h5\n",
      "Epoch 5/25\n",
      "17/17 [==============================] - 20s 1s/step - loss: 1.0193 - categorical_accuracy: 0.5882 - val_loss: 1.2083 - val_categorical_accuracy: 0.5500\n",
      "\n",
      "Epoch 00005: saving model to model_init_2019-12-2303_29_20.233871/model-00005-1.02543-0.58466-1.20826-0.55000.h5\n",
      "Epoch 6/25\n",
      "17/17 [==============================] - 19s 1s/step - loss: 0.9172 - categorical_accuracy: 0.6505 - val_loss: 1.2673 - val_categorical_accuracy: 0.5500\n",
      "\n",
      "Epoch 00006: saving model to model_init_2019-12-2303_29_20.233871/model-00006-0.91719-0.65052-1.26735-0.55000.h5\n",
      "Epoch 7/25\n",
      "17/17 [==============================] - 18s 1s/step - loss: 1.0020 - categorical_accuracy: 0.6159 - val_loss: 1.2109 - val_categorical_accuracy: 0.5167\n",
      "\n",
      "Epoch 00007: saving model to model_init_2019-12-2303_29_20.233871/model-00007-1.00205-0.61592-1.21086-0.51667.h5\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 8/25\n",
      "17/17 [==============================] - 17s 1s/step - loss: 0.8224 - categorical_accuracy: 0.6747 - val_loss: 1.0840 - val_categorical_accuracy: 0.6000\n",
      "\n",
      "Epoch 00008: saving model to model_init_2019-12-2303_29_20.233871/model-00008-0.82237-0.67474-1.08396-0.60000.h5\n",
      "Epoch 9/25\n",
      "17/17 [==============================] - 18s 1s/step - loss: 0.7687 - categorical_accuracy: 0.7128 - val_loss: 1.0971 - val_categorical_accuracy: 0.6000\n",
      "\n",
      "Epoch 00009: saving model to model_init_2019-12-2303_29_20.233871/model-00009-0.76873-0.71280-1.09709-0.60000.h5\n",
      "Epoch 10/25\n",
      "17/17 [==============================] - 17s 1s/step - loss: 0.7430 - categorical_accuracy: 0.7128 - val_loss: 1.1571 - val_categorical_accuracy: 0.5667\n",
      "\n",
      "Epoch 00010: saving model to model_init_2019-12-2303_29_20.233871/model-00010-0.74301-0.71280-1.15707-0.56667.h5\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 11/25\n",
      "17/17 [==============================] - 18s 1s/step - loss: 0.6403 - categorical_accuracy: 0.7751 - val_loss: 1.0546 - val_categorical_accuracy: 0.6000\n",
      "\n",
      "Epoch 00011: saving model to model_init_2019-12-2303_29_20.233871/model-00011-0.64025-0.77509-1.05458-0.60000.h5\n",
      "Epoch 12/25\n",
      "17/17 [==============================] - 18s 1s/step - loss: 0.6967 - categorical_accuracy: 0.7232 - val_loss: 0.9585 - val_categorical_accuracy: 0.6667\n",
      "\n",
      "Epoch 00012: saving model to model_init_2019-12-2303_29_20.233871/model-00012-0.69675-0.72318-0.95851-0.66667.h5\n",
      "Epoch 13/25\n",
      "17/17 [==============================] - 19s 1s/step - loss: 0.6357 - categorical_accuracy: 0.7751 - val_loss: 1.1119 - val_categorical_accuracy: 0.5667\n",
      "\n",
      "Epoch 00013: saving model to model_init_2019-12-2303_29_20.233871/model-00013-0.63571-0.77509-1.11188-0.56667.h5\n",
      "Epoch 14/25\n",
      "17/17 [==============================] - 18s 1s/step - loss: 0.6159 - categorical_accuracy: 0.7682 - val_loss: 1.1809 - val_categorical_accuracy: 0.5500\n",
      "\n",
      "Epoch 00014: saving model to model_init_2019-12-2303_29_20.233871/model-00014-0.61593-0.76817-1.18090-0.55000.h5\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 15/25\n",
      "17/17 [==============================] - 18s 1s/step - loss: 0.6024 - categorical_accuracy: 0.8097 - val_loss: 1.0640 - val_categorical_accuracy: 0.6167\n",
      "\n",
      "Epoch 00015: saving model to model_init_2019-12-2303_29_20.233871/model-00015-0.60236-0.80969-1.06397-0.61667.h5\n",
      "Epoch 16/25\n",
      "17/17 [==============================] - 18s 1s/step - loss: 0.5790 - categorical_accuracy: 0.7924 - val_loss: 0.9697 - val_categorical_accuracy: 0.6667\n",
      "\n",
      "Epoch 00016: saving model to model_init_2019-12-2303_29_20.233871/model-00016-0.57905-0.79239-0.96968-0.66667.h5\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 17/25\n",
      "17/17 [==============================] - 18s 1s/step - loss: 0.5014 - categorical_accuracy: 0.8235 - val_loss: 1.1364 - val_categorical_accuracy: 0.6000\n",
      "\n",
      "Epoch 00017: saving model to model_init_2019-12-2303_29_20.233871/model-00017-0.50139-0.82353-1.13639-0.60000.h5\n",
      "Epoch 18/25\n",
      "17/17 [==============================] - 18s 1s/step - loss: 0.5825 - categorical_accuracy: 0.7958 - val_loss: 0.8253 - val_categorical_accuracy: 0.7000\n",
      "\n",
      "Epoch 00018: saving model to model_init_2019-12-2303_29_20.233871/model-00018-0.58248-0.79585-0.82530-0.70000.h5\n",
      "Epoch 19/25\n",
      "17/17 [==============================] - 17s 1s/step - loss: 0.4974 - categorical_accuracy: 0.7993 - val_loss: 1.1539 - val_categorical_accuracy: 0.5500\n",
      "\n",
      "Epoch 00019: saving model to model_init_2019-12-2303_29_20.233871/model-00019-0.49736-0.79931-1.15388-0.55000.h5\n",
      "Epoch 20/25\n",
      "17/17 [==============================] - 18s 1s/step - loss: 0.5852 - categorical_accuracy: 0.7993 - val_loss: 1.1335 - val_categorical_accuracy: 0.5833\n",
      "\n",
      "Epoch 00020: saving model to model_init_2019-12-2303_29_20.233871/model-00020-0.58524-0.79931-1.13350-0.58333.h5\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 21/25\n",
      "17/17 [==============================] - 18s 1s/step - loss: 0.5558 - categorical_accuracy: 0.7855 - val_loss: 1.0342 - val_categorical_accuracy: 0.6167\n",
      "\n",
      "Epoch 00021: saving model to model_init_2019-12-2303_29_20.233871/model-00021-0.55581-0.78547-1.03416-0.61667.h5\n",
      "Epoch 22/25\n",
      "17/17 [==============================] - 18s 1s/step - loss: 0.5588 - categorical_accuracy: 0.7889 - val_loss: 1.0958 - val_categorical_accuracy: 0.6167\n",
      "\n",
      "Epoch 00022: saving model to model_init_2019-12-2303_29_20.233871/model-00022-0.55883-0.78893-1.09581-0.61667.h5\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 23/25\n",
      "17/17 [==============================] - 18s 1s/step - loss: 0.5272 - categorical_accuracy: 0.8235 - val_loss: 1.0556 - val_categorical_accuracy: 0.5833\n",
      "\n",
      "Epoch 00023: saving model to model_init_2019-12-2303_29_20.233871/model-00023-0.52716-0.82353-1.05562-0.58333.h5\n",
      "Epoch 24/25\n",
      "17/17 [==============================] - 18s 1s/step - loss: 0.5089 - categorical_accuracy: 0.8166 - val_loss: 1.0276 - val_categorical_accuracy: 0.6333\n",
      "\n",
      "Epoch 00024: saving model to model_init_2019-12-2303_29_20.233871/model-00024-0.50892-0.81661-1.02758-0.63333.h5\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "Epoch 25/25\n",
      "17/17 [==============================] - 18s 1s/step - loss: 0.5827 - categorical_accuracy: 0.7855 - val_loss: 1.0330 - val_categorical_accuracy: 0.6000\n",
      "\n",
      "Epoch 00025: saving model to model_init_2019-12-2303_29_20.233871/model-00025-0.58269-0.78547-1.03304-0.60000.h5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f410068d5c0>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model13.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "#                     callbacks=callbacks_list, validation_data=val_generator, \n",
    "#                     validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Epoch 18/25\n",
    "17/17 [==============================] - 18s 1s/step - loss: 0.5825 - categorical_accuracy: 0.7958 - val_loss: 0.8253 - val_categorical_accuracy: 0.7000\n",
    "\n",
    "Epoch 00018: saving model to model_init_2019-12-2303_29_20.233871/model-00018-0.58248-0.79585-0.82530-0.70000.h5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 14 CNN+RNN Increase dense neurons to 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def get_cnn_rnn_tl_model_b(gru_cells=64,dense_neurons=256,dropout=0.50):\n",
    "    \n",
    "#     # freeze the layers in base model\n",
    "#     for layer in base_model.layers:\n",
    "#         layer.trainable = False\n",
    "        \n",
    "#     model = Sequential()\n",
    "#     model.add(TimeDistributed(base_model, input_shape=input_shape))\n",
    "#     model.add(TimeDistributed(BatchNormalization()))\n",
    "#     model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "#     model.add(TimeDistributed(Flatten()))              \n",
    "    \n",
    "#     model.add(GRU(gru_cells))\n",
    "#     model.add(Dropout(dropout))\n",
    "        \n",
    "#     model.add(Dense(dense_neurons,activation='relu'))\n",
    "#     model.add(Dropout(dropout))\n",
    "    \n",
    "#     model.add(Dense(5, activation='softmax'))\n",
    "#     optimiser = optimizers.Adam()\n",
    "#     model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "#     print (model.summary())\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_size= 40 ,num_frames= 16 ,num_rows= 120 ,num_cols= 120 ,num_epochs= 25\n"
     ]
    }
   ],
   "source": [
    "# # Set Hyperparameters for the model\n",
    "# set_hyper_parameters(batchSize=40, numFrames=16, numRows=120, numCols=120, numEpochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 120, 120, 3)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steps_per_epoch= 17 validation_steps= 3\n"
     ]
    }
   ],
   "source": [
    "# set_train_validation_steps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "time_distributed_25 (TimeDis (None, 16, 3, 3, 1024)    3228864   \n",
      "_________________________________________________________________\n",
      "time_distributed_26 (TimeDis (None, 16, 3, 3, 1024)    4096      \n",
      "_________________________________________________________________\n",
      "time_distributed_27 (TimeDis (None, 16, 1, 1, 1024)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_28 (TimeDis (None, 16, 1024)          0         \n",
      "_________________________________________________________________\n",
      "gru_4 (GRU)                  (None, 64)                209088    \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 5)                 1285      \n",
      "=================================================================\n",
      "Total params: 3,459,973\n",
      "Trainable params: 229,061\n",
      "Non-trainable params: 3,230,912\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# model14 = get_cnn_rnn_tl_model_b()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # create generators: Let us create the `train_generator` and the `val_generator` which will be used in `.fit_generator`.\n",
    "# train_generator = generator(train_path, train_doc, batch_size)\n",
    "# val_generator = generator(val_path, val_doc, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source path =  Project_data/val ; batch size = 40\n",
      "Source path =  Project_data/train ; batch size = Epoch 1/25\n",
      "40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:13: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "  del sys.path[0]\n",
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:21: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n",
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:44: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:53: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 46s 3s/step - loss: 1.7015 - categorical_accuracy: 0.2453 - val_loss: 1.4326 - val_categorical_accuracy: 0.4600\n",
      "\n",
      "Epoch 00001: saving model to model_init_2019-12-2303_29_20.233871/model-00001-1.70085-0.24284-1.43259-0.46000.h5\n",
      "Epoch 2/25\n",
      "17/17 [==============================] - 22s 1s/step - loss: 1.3676 - categorical_accuracy: 0.4425 - val_loss: 1.2943 - val_categorical_accuracy: 0.5000\n",
      "\n",
      "Epoch 00002: saving model to model_init_2019-12-2303_29_20.233871/model-00002-1.36756-0.44246-1.29426-0.50000.h5\n",
      "Epoch 3/25\n",
      "17/17 [==============================] - 23s 1s/step - loss: 1.1294 - categorical_accuracy: 0.5628 - val_loss: 1.1481 - val_categorical_accuracy: 0.5000\n",
      "\n",
      "Epoch 00003: saving model to model_init_2019-12-2303_29_20.233871/model-00003-1.13730-0.55858-1.14806-0.50000.h5\n",
      "Epoch 4/25\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.8966 - categorical_accuracy: 0.6625 - val_loss: 1.1371 - val_categorical_accuracy: 0.5000\n",
      "\n",
      "Epoch 00004: saving model to model_init_2019-12-2303_29_20.233871/model-00004-0.89660-0.66254-1.13715-0.50000.h5\n",
      "Epoch 5/25\n",
      "17/17 [==============================] - 19s 1s/step - loss: 0.8098 - categorical_accuracy: 0.6785 - val_loss: 1.1289 - val_categorical_accuracy: 0.4667\n",
      "\n",
      "Epoch 00005: saving model to model_init_2019-12-2303_29_20.233871/model-00005-0.81259-0.67732-1.12886-0.46667.h5\n",
      "Epoch 6/25\n",
      "17/17 [==============================] - 18s 1s/step - loss: 0.6544 - categorical_accuracy: 0.7163 - val_loss: 0.9815 - val_categorical_accuracy: 0.6333\n",
      "\n",
      "Epoch 00006: saving model to model_init_2019-12-2303_29_20.233871/model-00006-0.65440-0.71626-0.98146-0.63333.h5\n",
      "Epoch 7/25\n",
      "17/17 [==============================] - 19s 1s/step - loss: 0.6871 - categorical_accuracy: 0.7578 - val_loss: 1.2124 - val_categorical_accuracy: 0.5167\n",
      "\n",
      "Epoch 00007: saving model to model_init_2019-12-2303_29_20.233871/model-00007-0.68712-0.75779-1.21238-0.51667.h5\n",
      "Epoch 8/25\n",
      "17/17 [==============================] - 19s 1s/step - loss: 0.5426 - categorical_accuracy: 0.8166 - val_loss: 1.1360 - val_categorical_accuracy: 0.5667\n",
      "\n",
      "Epoch 00008: saving model to model_init_2019-12-2303_29_20.233871/model-00008-0.54256-0.81661-1.13597-0.56667.h5\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 9/25\n",
      "17/17 [==============================] - 17s 1s/step - loss: 0.4451 - categorical_accuracy: 0.8339 - val_loss: 0.9395 - val_categorical_accuracy: 0.6333\n",
      "\n",
      "Epoch 00009: saving model to model_init_2019-12-2303_29_20.233871/model-00009-0.44510-0.83391-0.93955-0.63333.h5\n",
      "Epoch 10/25\n",
      "17/17 [==============================] - 18s 1s/step - loss: 0.4069 - categorical_accuracy: 0.8754 - val_loss: 1.1310 - val_categorical_accuracy: 0.6000\n",
      "\n",
      "Epoch 00010: saving model to model_init_2019-12-2303_29_20.233871/model-00010-0.40687-0.87543-1.13101-0.60000.h5\n",
      "Epoch 11/25\n",
      "17/17 [==============================] - 18s 1s/step - loss: 0.4332 - categorical_accuracy: 0.8235 - val_loss: 0.8589 - val_categorical_accuracy: 0.6500\n",
      "\n",
      "Epoch 00011: saving model to model_init_2019-12-2303_29_20.233871/model-00011-0.43323-0.82353-0.85885-0.65000.h5\n",
      "Epoch 12/25\n",
      "17/17 [==============================] - 18s 1s/step - loss: 0.3607 - categorical_accuracy: 0.8754 - val_loss: 0.9364 - val_categorical_accuracy: 0.6667\n",
      "\n",
      "Epoch 00012: saving model to model_init_2019-12-2303_29_20.233871/model-00012-0.36067-0.87543-0.93639-0.66667.h5\n",
      "Epoch 13/25\n",
      "17/17 [==============================] - 18s 1s/step - loss: 0.3572 - categorical_accuracy: 0.9031 - val_loss: 0.8067 - val_categorical_accuracy: 0.6667\n",
      "\n",
      "Epoch 00013: saving model to model_init_2019-12-2303_29_20.233871/model-00013-0.35720-0.90311-0.80667-0.66667.h5\n",
      "Epoch 14/25\n",
      "17/17 [==============================] - 18s 1s/step - loss: 0.3005 - categorical_accuracy: 0.8997 - val_loss: 0.8786 - val_categorical_accuracy: 0.7000\n",
      "\n",
      "Epoch 00014: saving model to model_init_2019-12-2303_29_20.233871/model-00014-0.30054-0.89965-0.87862-0.70000.h5\n",
      "Epoch 15/25\n",
      "17/17 [==============================] - 18s 1s/step - loss: 0.2973 - categorical_accuracy: 0.8893 - val_loss: 0.8687 - val_categorical_accuracy: 0.7000\n",
      "\n",
      "Epoch 00015: saving model to model_init_2019-12-2303_29_20.233871/model-00015-0.29734-0.88927-0.86865-0.70000.h5\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 16/25\n",
      "17/17 [==============================] - 19s 1s/step - loss: 0.2451 - categorical_accuracy: 0.9031 - val_loss: 0.9267 - val_categorical_accuracy: 0.6000\n",
      "\n",
      "Epoch 00016: saving model to model_init_2019-12-2303_29_20.233871/model-00016-0.24514-0.90311-0.92665-0.60000.h5\n",
      "Epoch 17/25\n",
      "17/17 [==============================] - 18s 1s/step - loss: 0.2278 - categorical_accuracy: 0.9446 - val_loss: 0.9261 - val_categorical_accuracy: 0.5833\n",
      "\n",
      "Epoch 00017: saving model to model_init_2019-12-2303_29_20.233871/model-00017-0.22775-0.94464-0.92609-0.58333.h5\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 18/25\n",
      "17/17 [==============================] - 19s 1s/step - loss: 0.2517 - categorical_accuracy: 0.9135 - val_loss: 0.8140 - val_categorical_accuracy: 0.6833\n",
      "\n",
      "Epoch 00018: saving model to model_init_2019-12-2303_29_20.233871/model-00018-0.25172-0.91349-0.81399-0.68333.h5\n",
      "Epoch 19/25\n",
      "17/17 [==============================] - 18s 1s/step - loss: 0.2387 - categorical_accuracy: 0.9170 - val_loss: 1.0198 - val_categorical_accuracy: 0.6667\n",
      "\n",
      "Epoch 00019: saving model to model_init_2019-12-2303_29_20.233871/model-00019-0.23866-0.91696-1.01980-0.66667.h5\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 20/25\n",
      "17/17 [==============================] - 19s 1s/step - loss: 0.2291 - categorical_accuracy: 0.9239 - val_loss: 0.6511 - val_categorical_accuracy: 0.7333\n",
      "\n",
      "Epoch 00020: saving model to model_init_2019-12-2303_29_20.233871/model-00020-0.22908-0.92388-0.65110-0.73333.h5\n",
      "Epoch 21/25\n",
      "17/17 [==============================] - 19s 1s/step - loss: 0.2205 - categorical_accuracy: 0.9204 - val_loss: 0.9268 - val_categorical_accuracy: 0.6667\n",
      "\n",
      "Epoch 00021: saving model to model_init_2019-12-2303_29_20.233871/model-00021-0.22048-0.92042-0.92676-0.66667.h5\n",
      "Epoch 22/25\n",
      "17/17 [==============================] - 18s 1s/step - loss: 0.2370 - categorical_accuracy: 0.9239 - val_loss: 0.7245 - val_categorical_accuracy: 0.7500\n",
      "\n",
      "Epoch 00022: saving model to model_init_2019-12-2303_29_20.233871/model-00022-0.23703-0.92388-0.72450-0.75000.h5\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 23/25\n",
      "17/17 [==============================] - 19s 1s/step - loss: 0.2106 - categorical_accuracy: 0.9204 - val_loss: 1.0327 - val_categorical_accuracy: 0.6167\n",
      "\n",
      "Epoch 00023: saving model to model_init_2019-12-2303_29_20.233871/model-00023-0.21060-0.92042-1.03272-0.61667.h5\n",
      "Epoch 24/25\n",
      "17/17 [==============================] - 18s 1s/step - loss: 0.1585 - categorical_accuracy: 0.9446 - val_loss: 0.7073 - val_categorical_accuracy: 0.7000\n",
      "\n",
      "Epoch 00024: saving model to model_init_2019-12-2303_29_20.233871/model-00024-0.15855-0.94464-0.70728-0.70000.h5\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 25/25\n",
      "17/17 [==============================] - 19s 1s/step - loss: 0.2234 - categorical_accuracy: 0.9412 - val_loss: 0.9521 - val_categorical_accuracy: 0.6667\n",
      "\n",
      "Epoch 00025: saving model to model_init_2019-12-2303_29_20.233871/model-00025-0.22342-0.94118-0.95207-0.66667.h5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f412c2b3358>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model14.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "#                     callbacks=callbacks_list, validation_data=val_generator, \n",
    "#                     validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Epoch 22/25\n",
    "17/17 [==============================] - 18s 1s/step - loss: 0.2370 - categorical_accuracy: 0.9239 - val_loss: 0.7245 - val_categorical_accuracy: 0.7500\n",
    "\n",
    "Epoch 00022: saving model to model_init_2019-12-2303_29_20.233871/model-00022-0.23703-0.92388-0.72450-0.75000.h5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 15: Add drop out in the CNN layer and changed the learning rate to 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def get_cnn_rnn_tl_model_c(gru_cells=64,dense_neurons=256,dropout=0.50):\n",
    "    \n",
    "#     # freeze the layers in base model\n",
    "#     for layer in base_model.layers:\n",
    "#         layer.trainable = False\n",
    "        \n",
    "#     model = Sequential()\n",
    "#     model.add(TimeDistributed(base_model, input_shape=input_shape))\n",
    "#     model.add(TimeDistributed(BatchNormalization()))\n",
    "#     model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "#     model.add(Dropout(0.25))\n",
    "    \n",
    "#     model.add(TimeDistributed(Flatten()))              \n",
    "    \n",
    "#     model.add(GRU(gru_cells))\n",
    "#     model.add(Dropout(dropout))\n",
    "        \n",
    "#     model.add(Dense(dense_neurons,activation='relu'))\n",
    "#     model.add(Dropout(dropout))\n",
    "    \n",
    "#     model.add(Dense(5, activation='softmax'))\n",
    "#     optimiser = optimizers.Adam(lr=0.001)\n",
    "#     model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "#     print (model.summary())\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_size= 40 ,num_frames= 16 ,num_rows= 120 ,num_cols= 120 ,num_epochs= 25\n"
     ]
    }
   ],
   "source": [
    "# # Set Hyperparameters for the model\n",
    "# set_hyper_parameters(batchSize=40, numFrames=16, numRows=120, numCols=120, numEpochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steps_per_epoch= 17 validation_steps= 3\n"
     ]
    }
   ],
   "source": [
    "# set_train_validation_steps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "time_distributed_1 (TimeDist (None, 16, 3, 3, 1024)    3228864   \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 16, 3, 3, 1024)    4096      \n",
      "_________________________________________________________________\n",
      "time_distributed_3 (TimeDist (None, 16, 1, 1, 1024)    0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16, 1, 1, 1024)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_4 (TimeDist (None, 16, 1024)          0         \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (None, 64)                209088    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 1285      \n",
      "=================================================================\n",
      "Total params: 3,459,973\n",
      "Trainable params: 229,061\n",
      "Non-trainable params: 3,230,912\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# model15 = get_cnn_rnn_tl_model_c()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # create generators: Let us create the `train_generator` and the `val_generator` which will be used in `.fit_generator`.\n",
    "# train_generator = generator(train_path, train_doc, batch_size)\n",
    "# val_generator = generator(val_path, val_doc, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source path =  Project_data/val ; batch size = 40\n",
      "Source path =  Project_data/train ; batch size = 40\n",
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:13: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "  del sys.path[0]\n",
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:21: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n",
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:44: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:53: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 47s 3s/step - loss: 1.6811 - categorical_accuracy: 0.2530 - val_loss: 1.5390 - val_categorical_accuracy: 0.2700\n",
      "\n",
      "Epoch 00001: saving model to model_init_2019-12-2304_27_59.294386/model-00001-1.68666-0.25490-1.53896-0.27000.h5\n",
      "Epoch 2/25\n",
      "17/17 [==============================] - 20s 1s/step - loss: 1.4532 - categorical_accuracy: 0.3939 - val_loss: 1.3939 - val_categorical_accuracy: 0.5333\n",
      "\n",
      "Epoch 00002: saving model to model_init_2019-12-2304_27_59.294386/model-00002-1.45322-0.39386-1.39388-0.53333.h5\n",
      "Epoch 3/25\n",
      "17/17 [==============================] - 23s 1s/step - loss: 1.2277 - categorical_accuracy: 0.4715 - val_loss: 1.3898 - val_categorical_accuracy: 0.3667\n",
      "\n",
      "Epoch 00003: saving model to model_init_2019-12-2304_27_59.294386/model-00003-1.22783-0.47139-1.38984-0.36667.h5\n",
      "Epoch 4/25\n",
      "17/17 [==============================] - 20s 1s/step - loss: 1.0883 - categorical_accuracy: 0.5511 - val_loss: 1.0757 - val_categorical_accuracy: 0.5667\n",
      "\n",
      "Epoch 00004: saving model to model_init_2019-12-2304_27_59.294386/model-00004-1.08831-0.55108-1.07567-0.56667.h5\n",
      "Epoch 5/25\n",
      "17/17 [==============================] - 20s 1s/step - loss: 0.8910 - categorical_accuracy: 0.6396 - val_loss: 1.2015 - val_categorical_accuracy: 0.4667\n",
      "\n",
      "Epoch 00005: saving model to model_init_2019-12-2304_27_59.294386/model-00005-0.89313-0.63898-1.20147-0.46667.h5\n",
      "Epoch 6/25\n",
      "17/17 [==============================] - 19s 1s/step - loss: 0.8293 - categorical_accuracy: 0.6678 - val_loss: 1.1780 - val_categorical_accuracy: 0.5167\n",
      "\n",
      "Epoch 00006: saving model to model_init_2019-12-2304_27_59.294386/model-00006-0.82932-0.66782-1.17800-0.51667.h5\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 7/25\n",
      "17/17 [==============================] - 17s 1s/step - loss: 0.7119 - categorical_accuracy: 0.7405 - val_loss: 0.8585 - val_categorical_accuracy: 0.7000\n",
      "\n",
      "Epoch 00007: saving model to model_init_2019-12-2304_27_59.294386/model-00007-0.71189-0.74048-0.85849-0.70000.h5\n",
      "Epoch 8/25\n",
      "17/17 [==============================] - 19s 1s/step - loss: 0.6958 - categorical_accuracy: 0.7197 - val_loss: 1.1618 - val_categorical_accuracy: 0.4833\n",
      "\n",
      "Epoch 00008: saving model to model_init_2019-12-2304_27_59.294386/model-00008-0.69582-0.71972-1.16180-0.48333.h5\n",
      "Epoch 9/25\n",
      "17/17 [==============================] - 17s 1s/step - loss: 0.5207 - categorical_accuracy: 0.7855 - val_loss: 0.9234 - val_categorical_accuracy: 0.5833\n",
      "\n",
      "Epoch 00009: saving model to model_init_2019-12-2304_27_59.294386/model-00009-0.52071-0.78547-0.92341-0.58333.h5\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 10/25\n",
      "17/17 [==============================] - 18s 1s/step - loss: 0.5555 - categorical_accuracy: 0.7682 - val_loss: 0.9047 - val_categorical_accuracy: 0.6333\n",
      "\n",
      "Epoch 00010: saving model to model_init_2019-12-2304_27_59.294386/model-00010-0.55546-0.76817-0.90467-0.63333.h5\n",
      "Epoch 11/25\n",
      "17/17 [==============================] - 18s 1s/step - loss: 0.4976 - categorical_accuracy: 0.8028 - val_loss: 1.1530 - val_categorical_accuracy: 0.4833\n",
      "\n",
      "Epoch 00011: saving model to model_init_2019-12-2304_27_59.294386/model-00011-0.49762-0.80277-1.15302-0.48333.h5\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 12/25\n",
      "17/17 [==============================] - 18s 1s/step - loss: 0.4972 - categorical_accuracy: 0.8201 - val_loss: 1.0531 - val_categorical_accuracy: 0.5500\n",
      "\n",
      "Epoch 00012: saving model to model_init_2019-12-2304_27_59.294386/model-00012-0.49725-0.82007-1.05306-0.55000.h5\n",
      "Epoch 13/25\n",
      "17/17 [==============================] - 18s 1s/step - loss: 0.5793 - categorical_accuracy: 0.7751 - val_loss: 0.9404 - val_categorical_accuracy: 0.6000\n",
      "\n",
      "Epoch 00013: saving model to model_init_2019-12-2304_27_59.294386/model-00013-0.57928-0.77509-0.94036-0.60000.h5\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "Epoch 14/25\n",
      "17/17 [==============================] - 19s 1s/step - loss: 0.5121 - categorical_accuracy: 0.8235 - val_loss: 0.9246 - val_categorical_accuracy: 0.6000\n",
      "\n",
      "Epoch 00014: saving model to model_init_2019-12-2304_27_59.294386/model-00014-0.51210-0.82353-0.92460-0.60000.h5\n",
      "Epoch 15/25\n",
      "17/17 [==============================] - 18s 1s/step - loss: 0.5564 - categorical_accuracy: 0.7889 - val_loss: 1.0898 - val_categorical_accuracy: 0.4833\n",
      "\n",
      "Epoch 00015: saving model to model_init_2019-12-2304_27_59.294386/model-00015-0.55640-0.78893-1.08982-0.48333.h5\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "Epoch 16/25\n",
      "17/17 [==============================] - 18s 1s/step - loss: 0.5314 - categorical_accuracy: 0.7924 - val_loss: 0.9108 - val_categorical_accuracy: 0.6000\n",
      "\n",
      "Epoch 00016: saving model to model_init_2019-12-2304_27_59.294386/model-00016-0.53144-0.79239-0.91080-0.60000.h5\n",
      "Epoch 17/25\n",
      "17/17 [==============================] - 18s 1s/step - loss: 0.5628 - categorical_accuracy: 0.7993 - val_loss: 0.8793 - val_categorical_accuracy: 0.5833\n",
      "\n",
      "Epoch 00017: saving model to model_init_2019-12-2304_27_59.294386/model-00017-0.56284-0.79931-0.87925-0.58333.h5\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "Epoch 18/25\n",
      "17/17 [==============================] - 19s 1s/step - loss: 0.5191 - categorical_accuracy: 0.7820 - val_loss: 1.1265 - val_categorical_accuracy: 0.5333\n",
      "\n",
      "Epoch 00018: saving model to model_init_2019-12-2304_27_59.294386/model-00018-0.51907-0.78201-1.12655-0.53333.h5\n",
      "Epoch 19/25\n",
      "17/17 [==============================] - 18s 1s/step - loss: 0.5694 - categorical_accuracy: 0.7924 - val_loss: 1.0014 - val_categorical_accuracy: 0.5500\n",
      "\n",
      "Epoch 00019: saving model to model_init_2019-12-2304_27_59.294386/model-00019-0.56939-0.79239-1.00143-0.55000.h5\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "Epoch 20/25\n",
      "17/17 [==============================] - 19s 1s/step - loss: 0.5031 - categorical_accuracy: 0.7993 - val_loss: 0.9259 - val_categorical_accuracy: 0.6333\n",
      "\n",
      "Epoch 00020: saving model to model_init_2019-12-2304_27_59.294386/model-00020-0.50313-0.79931-0.92592-0.63333.h5\n",
      "Epoch 21/25\n",
      "17/17 [==============================] - 17s 1s/step - loss: 0.5031 - categorical_accuracy: 0.8304 - val_loss: 1.0006 - val_categorical_accuracy: 0.5500\n",
      "\n",
      "Epoch 00021: saving model to model_init_2019-12-2304_27_59.294386/model-00021-0.50312-0.83045-1.00064-0.55000.h5\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "Epoch 22/25\n",
      "17/17 [==============================] - 18s 1s/step - loss: 0.5037 - categorical_accuracy: 0.7958 - val_loss: 0.8852 - val_categorical_accuracy: 0.5833\n",
      "\n",
      "Epoch 00022: saving model to model_init_2019-12-2304_27_59.294386/model-00022-0.50370-0.79585-0.88518-0.58333.h5\n",
      "Epoch 23/25\n",
      "17/17 [==============================] - 19s 1s/step - loss: 0.5503 - categorical_accuracy: 0.8028 - val_loss: 1.0976 - val_categorical_accuracy: 0.5500\n",
      "\n",
      "Epoch 00023: saving model to model_init_2019-12-2304_27_59.294386/model-00023-0.55029-0.80277-1.09760-0.55000.h5\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "Epoch 24/25\n",
      "17/17 [==============================] - 19s 1s/step - loss: 0.4878 - categorical_accuracy: 0.8201 - val_loss: 0.9293 - val_categorical_accuracy: 0.5833\n",
      "\n",
      "Epoch 00024: saving model to model_init_2019-12-2304_27_59.294386/model-00024-0.48784-0.82007-0.92930-0.58333.h5\n",
      "Epoch 25/25\n",
      "17/17 [==============================] - 19s 1s/step - loss: 0.5428 - categorical_accuracy: 0.7993 - val_loss: 1.1120 - val_categorical_accuracy: 0.5000\n",
      "\n",
      "Epoch 00025: saving model to model_init_2019-12-2304_27_59.294386/model-00025-0.54276-0.79931-1.11204-0.50000.h5\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f78b484ea90>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model15.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "#                     callbacks=callbacks_list, validation_data=val_generator, \n",
    "#                     validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Epoch 7/25\n",
    "17/17 [==============================] - 17s 1s/step - loss: 0.7119 - categorical_accuracy: 0.7405 - val_loss: 0.8585 - val_categorical_accuracy: 0.7000\n",
    "\n",
    "Epoch 00007: saving model to model_init_2019-12-2304_27_59.294386/model-00007-0.71189-0.74048-0.85849-0.70000.h5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
